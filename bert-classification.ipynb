{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePVSga5E_a-e"
   },
   "source": [
    "# Clasificación de secuencias de texto con BERT y Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_pqv14cAvww"
   },
   "source": [
    "> Objetivos:\n",
    "\n",
    "\n",
    "\n",
    "*   Procesar una base de datos de texto y adapatarla a lightning.\n",
    "*   Importar modelo BERT pre-entrenado.\n",
    "*   Hacer finetuning de BERT para detección de comentarios negativos o tóxicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6M5FAipmhUBw"
   },
   "source": [
    "## Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade kagglehub\n",
    "# !pip install --upgrade polars\n",
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3736,
     "status": "ok",
     "timestamp": 1721169622374,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "y5mj8cpdM_O3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, RichProgressBar\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from torchmetrics import AUROC, Accuracy\n",
    "\n",
    "#nuevas librerias\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1721169622486,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "3vBmTBBIhn-Z",
    "outputId": "c173fa77-03b0-402a-8acf-8c9cf3d5000c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parametros para gráficos\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 8,6\n",
    "\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btZjckeJs5j7"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "El dataset IMDB contiene 50,000 reseñas de películas etiquetadas como positivas o negativas. Fue descargado desde Kaggle usando el repositorio [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12133,
     "status": "ok",
     "timestamp": 1721169634852,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "zpT48Rwl94aP",
    "outputId": "72e390c1-bf65-4fc6-d9be-af85ce939991"
   },
   "outputs": [],
   "source": [
    "# Descargar la base de datos\n",
    "#!gdown --id 1VuQ-U7TtggShMeuRSA_hzC8qGDl2LRkr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEQ-aGlT5yTU"
   },
   "source": [
    "Dado que son solo 68.8M de datos, los cargamos en memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n",
      "Using CSV: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1/IMDB Dataset.csv\n",
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d2a6a9f3-d148-4a68-b929-df6cf9f41aea\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2a6a9f3-d148-4a68-b929-df6cf9f41aea')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d2a6a9f3-d148-4a68-b929-df6cf9f41aea button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d2a6a9f3-d148-4a68-b929-df6cf9f41aea');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEFORE importing kagglehub\n",
    "from google.colab import userdata\n",
    "\n",
    "# Mock userdata.get to return None immediately\n",
    "_original_get = userdata.get\n",
    "userdata.get = lambda key: None  # Skip all secret prompts\n",
    "\n",
    "# Descargar la última versión\n",
    "dataset_path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "print(\"Dataset path:\", dataset_path)\n",
    "\n",
    "# Si es un ZIP, extraer a directorio temporal\n",
    "if os.path.isfile(dataset_path) and dataset_path.lower().endswith(\".zip\"):\n",
    "    extract_dir = tempfile.mkdtemp()\n",
    "    with zipfile.ZipFile(dataset_path, \"r\") as z:\n",
    "        z.extractall(extract_dir)\n",
    "    search_dir = extract_dir\n",
    "else:\n",
    "    search_dir = dataset_path\n",
    "\n",
    "# Buscar archivos CSV\n",
    "csv_files = glob.glob(os.path.join(search_dir, \"**\", \"*.csv\"), recursive=True)\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files found under {search_dir}\")\n",
    "\n",
    "csv_file = csv_files[0]\n",
    "print(\"Using CSV:\", csv_file)\n",
    "\n",
    "# Leer con pandas (fallback de encoding si falla)\n",
    "try:\n",
    "    df = pd.read_csv(csv_file)\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(csv_file, encoding=\"latin1\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1721169635652,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "6v7DW58wrm-w",
    "outputId": "1be84c8a-1e3c-4eb5-a26c-1dbf3f3e967c"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"toxic_comments.csv\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX26ij7N6Uv_"
   },
   "source": [
    "Las reseñas de películas están en la columna `review` y las etiquetas de sentimiento en la columna `sentiment` (positive/negative). \n",
    "\n",
    "Para adaptar el código original de clasificación multi-etiqueta a clasificación binaria de sentimientos, creamos una columna `is_offensive` que mapea:\n",
    "- negative → 1 (considerado como \"ofensivo\" para el modelo)  \n",
    "- positive → 0 (considerado como \"no ofensivo\" para el modelo)\n",
    "\n",
    "<!-- Descripción original comentada:\n",
    "Las secuencias de texto están en la columna comment_text. Existen seis etiquetas que clasifican cada secuencia como tóxica, severamente tóxica, obscena, etc. Las columnas con comentarios no ofensivos tienen un 0 en todas las clases.\n",
    "\n",
    "Separamos los comentarios ofensivos de los no ofensivos:\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1721169648586,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "HWRU499BkPIe",
    "outputId": "e6158972-2467-428f-90d4-6b7e9d67ec1f"
   },
   "outputs": [],
   "source": [
    "#LABEL_COLUMNS = df.columns.tolist()[2:]\n",
    "#df_toxic = df[df[LABEL_COLUMNS].sum(axis=1) > 0]\n",
    "#df_clean = df[df[LABEL_COLUMNS].sum(axis=1) == 0]\n",
    "#print(\"Cantidad de secuencias de texto ofensivos: \", len(df_toxic))\n",
    "#print(\"Cantidad de secuencias de texto NO ofensivos: \", len(df_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de reseñas negativas (tratadas como ofensivas):  25000\n",
      "Cantidad de reseñas positivas (tratadas como no ofensivas):  25000\n",
      "Distribución de sentimientos:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convertir el dataset IMDB para clasificación binaria\n",
    "# Mapea 'negative' a 1 (ofensivo) y 'positive' a 0 (no ofensivo)\n",
    "df['is_offensive'] = df['sentiment'].map({'negative': 1, 'positive': 0})\n",
    "\n",
    "# Renombrar columnas para compatibilidad con el código existente\n",
    "df = df.rename(columns={'review': 'comment_text'})\n",
    "\n",
    "# Crear columna de etiquetas numéricas para el modelo\n",
    "df['label'] = df['is_offensive']\n",
    "\n",
    "# Filtra por sentimiento\n",
    "df_origin = df[df['is_offensive'] == 1]  # Negativos (tratados como ofensivos)\n",
    "df_clean = df[df['is_offensive'] == 0]   # Positivos (tratados como no ofensivos)\n",
    "\n",
    "print(\"Cantidad de reseñas negativas (tratadas como ofensivas): \", len(df_origin))\n",
    "print(\"Cantidad de reseñas positivas (tratadas como no ofensivas): \", len(df_clean))\n",
    "print(\"Distribución de sentimientos:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy2jD4ntkqIx"
   },
   "source": [
    "El dataset IMDB ya está balanceado (25,000 reseñas positivas y 25,000 negativas), pero para mantener la compatibilidad con el código original, ajustamos el tamaño si es necesario.\n",
    "\n",
    "<!-- Comentario original:\n",
    "Debido al desbalance de datos, tomamos un número reducido de secuencias no ofensivas para evitar bias en el modelo.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1721169650229,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "NHydMQQ2lCTS",
    "outputId": "1fda53f9-e601-466b-c115-c38095bcf39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset filtrado: (50000, 4)\n",
      "Distribución final:\n",
      "sentiment\n",
      "negative    25000\n",
      "positive    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# El dataset IMDB ya está balanceado (25k positivas, 25k negativas)\n",
    "# Usar todo el dataset o una muestra si se requiere menos datos para pruebas rápidas\n",
    "\n",
    "# Para mantener compatibilidad con el código original:\n",
    "filter_df = pd.concat([\n",
    "    df_origin,      # Todas las reseñas negativas (25,000)\n",
    "    df_clean        # Todas las reseñas positivas (25,000)\n",
    "])\n",
    "\n",
    "# Si quieres usar solo una muestra para pruebas más rápidas, descomenta:\n",
    "# filter_df = pd.concat([\n",
    "#     df_origin.sample(5000, random_state=42),\n",
    "#     df_clean.sample(5000, random_state=42)\n",
    "# ])\n",
    "\n",
    "print(f\"Tamaño del dataset filtrado: {filter_df.shape}\")\n",
    "print(\"Distribución final:\")\n",
    "print(filter_df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1721169650990,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "EtdEvIaPmdRi",
    "outputId": "cda6b360-063c-4912-c363-d6516d8a2faa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame:\n",
      " 35000\n",
      "Validation DataFrame:\n",
      " 7500\n",
      "Test DataFrame:\n",
      " 7500\n"
     ]
    }
   ],
   "source": [
    "train_frac, val_frac, test_frac = 0.7, 0.15, 0.15\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "filter_df = filter_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calcular los indices para separar los subsets\n",
    "train_end = int(train_frac * len(filter_df))\n",
    "val_end = train_end + int(val_frac * len(filter_df))\n",
    "\n",
    "# Split the DataFrame\n",
    "train_df = filter_df[:train_end]\n",
    "val_df = filter_df[train_end:val_end]\n",
    "test_df = filter_df[val_end:]\n",
    "\n",
    "print(\"Train DataFrame:\\n\", len(train_df))\n",
    "print(\"Validation DataFrame:\\n\", len(val_df))\n",
    "print(\"Test DataFrame:\\n\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1721169659688,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "MjPnsRP6nGJP",
    "outputId": "ee04309e-e04a-41be-c622-524ea4d38d87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e8bf8e76-186b-4172-b239-ebf097584e37\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, I was wondering if anyone has a copy of...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My Caddy Limo was destroyed!!! Well, I had one...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A truly muddled incomprehensible mess. Most th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My friends and I rented this for \"Bad Movie Ni...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This was the very first kung fu movie that I h...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8bf8e76-186b-4172-b239-ebf097584e37')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e8bf8e76-186b-4172-b239-ebf097584e37 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e8bf8e76-186b-4172-b239-ebf097584e37');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                        comment_text sentiment  is_offensive  \\\n",
       "0  Hello, I was wondering if anyone has a copy of...  positive             0   \n",
       "1  My Caddy Limo was destroyed!!! Well, I had one...  negative             1   \n",
       "2  A truly muddled incomprehensible mess. Most th...  negative             1   \n",
       "3  My friends and I rented this for \"Bad Movie Ni...  negative             1   \n",
       "4  This was the very first kung fu movie that I h...  positive             0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU9fW3KD7V0V"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "\n",
    "### Tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwBpI_G0FjwO"
   },
   "source": [
    "\n",
    "Convertir texto en una lista de tokens. usamos BertTokenizer pre-entrenado.\n",
    "\n",
    "BertTokenizer: Pretrained model on English language using a masked language modeling (MLM) objective. This model is case-sensitive: it makes a difference between english and English.\n",
    "The texts are tokenized using WordPiece and a vocabulary size of 30,000.\n",
    "\n",
    "Más información en: https://huggingface.co/google-bert/bert-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2327,
     "status": "ok",
     "timestamp": 1721169670726,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "fU8CYzKonYft",
    "outputId": "4fc97edb-ec7e-43b8-e05a-9e402f5a0a8d"
   },
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1721169671951,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "FzQ5MpcQpp4v",
    "outputId": "451d0ac7-8322-4bdc-f32f-3aee1401cf72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb6VLAmGHeEA"
   },
   "source": [
    "Tokenizando una secuencia de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1721169675106,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "e_URTylSXar1",
    "outputId": "d0581398-18d8-470a-f505-37a7c2132212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    Despite some negative comments this film has g...\n",
       "sentiment                                                positive\n",
       "is_offensive                                                    0\n",
       "label                                                           0\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row = train_df.iloc[5]\n",
    "sample_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1721169676238,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "3kDTQ5_6RnkI",
    "outputId": "961adc9e-f977-4eb3-bab5-cfa1355535bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimiento: positive\n",
      "Reseña: Despite some negative comments this film has garnered in the IMDb pages, it's still worth a look as this is a story about survival and camaraderie between two different men with different mentalities ...\n",
      "Etiqueta is_offensive: 0\n",
      "Etiqueta numérica (label): 0\n"
     ]
    }
   ],
   "source": [
    "sample_sentiment = sample_row.sentiment\n",
    "print(\"Sentimiento:\", sample_sentiment)\n",
    "\n",
    "sample_comment = sample_row.comment_text\n",
    "print(\"Reseña:\", sample_comment[:200] + \"...\" if len(sample_comment) > 200 else sample_comment)\n",
    "\n",
    "print(\"Etiqueta is_offensive:\", sample_row.is_offensive)\n",
    "print(\"Etiqueta numérica (label):\", sample_row.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1721169678834,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "DjLOQUgzUexM",
    "outputId": "0c2acd3a-1f9a-4f4d-9b4e-db2a1d454ae2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView({'input_ids': tensor([[  101,  2711,  1199,  4366,  7640,  1142,  1273,  1144, 13331,  1107,\n",
       "          1103,   146, 18219,  1830,  5097,   117,  1122,   112,   188,  1253,\n",
       "          3869,   170,  1440,  1112,  1142,  1110,   170,  1642,  1164,  8115,\n",
       "          1105, 11019, 20377,  2692,  1663,  1206,  1160,  1472,  1441,  1114,\n",
       "          1472,  4910,  4233,  1229,  1107,   170,  2846,  2862,  1107,  1103,\n",
       "          8392, 11091, 11800,   119,   133,  9304,   120,   135,   133,  9304,\n",
       "           120,   135, 16289,  1900,  6132,   149,  8867,  1161,  2274,  1366,\n",
       "          1373,  1106,  2824,  1142, 11826,  1383,  1107,  8392,   119,  1109,\n",
       "          1273,  1144,  1199,  1363,  4899,  1112, 22562,   117,  1103,  8230,\n",
       "          5243,   117,  2274,   170,  3599,  2474,  1299,   117,  3055,  1850,\n",
       "          1106,  2222,  1106, 11125,   170, 14140,  3850, 12411,  1883,  1246,\n",
       "          1105,  1103, 14644,  2306,  1704,  1150,  1547,  1129,  1103,  1397,\n",
       "          2084,  1104,  1103,  1583,   119,  1109,  1178,  2463,   117,  3902,\n",
       "           117,  1144,  1185,  2541,  1107,  1184,  1119,  1144,  1151, 19469,\n",
       "          1106,  5515,   119,   133,  9304,   120,   135,   133,  9304,   120,\n",
       "           135,  3902,   117,  1103, 17346,  3599,  2474,  1299,  1106,  1103,\n",
       "         11800,  1105,  1106,  1103, 18850,  9405,  1206,  1103,  1764,  1105,\n",
       "          3850, 17499,  1222,  1103,  1107,  8702,  6066,  5894,  1237,  4810,\n",
       "          1441,   117, 10123,   170,  7468, 11788,  1121, 22562,   119,  1327,\n",
       "          2736,  1363,  1107,  2749,   117,  1110, 25707,  1107,  1103, 11800,\n",
       "           119,   133,  9304,   120,   135,   133,  9304,   120,   135,  2545,\n",
       "          4108,  5123,  2895,   117,  1110,  1126,  2811,  1150,  2144,   112,\n",
       "           189,  8077,  1277,   117,  1112,  1119, 17617,  1107,  1142,  2523,\n",
       "           117,  1133,  1107,  1103,  5618,  1104,  1103,  2523,   117,  1119,\n",
       "          1110,  1268,  1112,   170,  1299,  1104,   170,  1374,  1734,   119,\n",
       "          4224,  6359,  1773,  3902,  1674,  1184,  1119,  1169,  1114,   170,\n",
       "          1648,  1115,  2144,   112,   189,  8658,  1140,  1251, 12887,  1235,\n",
       "          1103, 10268,  1322,   119,   133,  9304,   120,   135,   133,  9304,\n",
       "           120,   135,  1370, 12977,  1104,  2168,  1273,   117,   107,   156,\n",
       "          2605,  3365,   107,  3272,  1126, 11150,  1904,  1104,  2168,  1115,\n",
       "          1114,   170,  2113,  1104, 13373,  5031,  1156,  1138,  1189,   170,\n",
       "          1167, 18330,  2523,   119,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_sample = tokenizer.encode_plus(\n",
    "  sample_comment,  # Usar sample_comment en lugar de sample_comment\n",
    "  add_special_tokens=True,\n",
    "  max_length=512,\n",
    "  return_token_type_ids=False,\n",
    "  padding=\"max_length\",\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "\n",
    "encoding_sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1721169680157,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "V0e_EWTzX0FD",
    "outputId": "4a1d945f-2769-4e13-ca50-d498c254d1f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2711,  1199,  4366,  7640,  1142,  1273,  1144, 13331,  1107,\n",
       "          1103,   146, 18219,  1830,  5097,   117,  1122,   112,   188,  1253,\n",
       "          3869,   170,  1440,  1112,  1142,  1110,   170,  1642,  1164,  8115,\n",
       "          1105, 11019, 20377,  2692,  1663,  1206,  1160,  1472,  1441,  1114,\n",
       "          1472,  4910,  4233,  1229,  1107,   170,  2846,  2862,  1107,  1103,\n",
       "          8392, 11091, 11800,   119,   133,  9304,   120,   135,   133,  9304,\n",
       "           120,   135, 16289,  1900,  6132,   149,  8867,  1161,  2274,  1366,\n",
       "          1373,  1106,  2824,  1142, 11826,  1383,  1107,  8392,   119,  1109,\n",
       "          1273,  1144,  1199,  1363,  4899,  1112, 22562,   117,  1103,  8230,\n",
       "          5243,   117,  2274,   170,  3599,  2474,  1299,   117,  3055,  1850,\n",
       "          1106,  2222,  1106, 11125,   170, 14140,  3850, 12411,  1883,  1246,\n",
       "          1105,  1103, 14644,  2306,  1704,  1150,  1547,  1129,  1103,  1397,\n",
       "          2084,  1104,  1103,  1583,   119,  1109,  1178,  2463,   117,  3902,\n",
       "           117,  1144,  1185,  2541,  1107,  1184,  1119,  1144,  1151, 19469,\n",
       "          1106,  5515,   119,   133,  9304,   120,   135,   133,  9304,   120,\n",
       "           135,  3902,   117,  1103, 17346,  3599,  2474,  1299,  1106,  1103,\n",
       "         11800,  1105,  1106,  1103, 18850,  9405,  1206,  1103,  1764,  1105,\n",
       "          3850, 17499,  1222,  1103,  1107,  8702,  6066,  5894,  1237,  4810,\n",
       "          1441,   117, 10123,   170,  7468, 11788,  1121, 22562,   119,  1327,\n",
       "          2736,  1363,  1107,  2749,   117,  1110, 25707,  1107,  1103, 11800,\n",
       "           119,   133,  9304,   120,   135,   133,  9304,   120,   135,  2545,\n",
       "          4108,  5123,  2895,   117,  1110,  1126,  2811,  1150,  2144,   112,\n",
       "           189,  8077,  1277,   117,  1112,  1119, 17617,  1107,  1142,  2523,\n",
       "           117,  1133,  1107,  1103,  5618,  1104,  1103,  2523,   117,  1119,\n",
       "          1110,  1268,  1112,   170,  1299,  1104,   170,  1374,  1734,   119,\n",
       "          4224,  6359,  1773,  3902,  1674,  1184,  1119,  1169,  1114,   170,\n",
       "          1648,  1115,  2144,   112,   189,  8658,  1140,  1251, 12887,  1235,\n",
       "          1103, 10268,  1322,   119,   133,  9304,   120,   135,   133,  9304,\n",
       "           120,   135,  1370, 12977,  1104,  2168,  1273,   117,   107,   156,\n",
       "          2605,  3365,   107,  3272,  1126, 11150,  1904,  1104,  2168,  1115,\n",
       "          1114,   170,  2113,  1104, 13373,  5031,  1156,  1138,  1189,   170,\n",
       "          1167, 18330,  2523,   119,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_sample.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1721169684465,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "tlqeyA3FZJaz",
    "outputId": "1e765808-21db-4cb8-c3b8-4ee4a455d62c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_sample.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1721169686119,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "t2Qoj-RJU_KR",
    "outputId": "5d415e8d-ad48-4452-ee28-38f8b9ac7293"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_sample[\"input_ids\"].shape, encoding_sample[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfjz0npA3cVR"
   },
   "source": [
    "La tokenización entrega un diccionario con los IDs de los tokens en la key `input_ids` y las máscaras de atención en `attention_mask`.\n",
    "\n",
    "También podemos convertir los IDs a las subpalabras originales:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1721169689584,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "ib74R7MVsjmS",
    "outputId": "b20b9f2b-3b57-4b61-a3e5-5c407aef8888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Despite', 'some', 'negative', 'comments', 'this', 'film', 'has', 'garnered', 'in', 'the', 'I', '##MD', '##b', 'pages', ',', 'it', \"'\", 's', 'still', 'worth', 'a', 'look', 'as', 'this', 'is', 'a', 'story', 'about', 'survival', 'and', 'ca', '##mara', '##der', '##ie', 'between', 'two', 'different', 'men', 'with', 'different', 'mental', '##ities', 'while', 'in', 'a', 'difficult', 'mission', 'in', 'the', 'Panama', '##nian', 'jungle', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Peruvian', 'director', 'Luis', 'L', '##los', '##a', 'takes', 'us', 'along', 'to', 'watch', 'this', 'thriller', 'set', 'in', 'Panama', '.', 'The', 'film', 'has', 'some', 'good', 'moments', 'as', 'Beckett', ',', 'the', 'veteran', 'marine', ',', 'takes', 'a', 'newly', 'arrived', 'man', ',', 'recently', 'sent', 'to', 'try', 'to', 'eliminate', 'a', 'notorious', 'drug', 'cart', '##el', 'head', 'and', 'the', 'corrupt', 'army', 'general', 'who', 'might', 'be', 'the', 'next', 'president', 'of', 'the', 'country', '.', 'The', 'only', 'problem', ',', 'Miller', ',', 'has', 'no', 'experience', 'in', 'what', 'he', 'has', 'been', 'entrusted', 'to', 'achieve', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Miller', ',', 'the', 'arrogant', 'newly', 'arrived', 'man', 'to', 'the', 'jungle', 'and', 'to', 'the', 'guerrilla', 'warfare', 'between', 'the', 'military', 'and', 'drug', 'lords', 'against', 'the', 'in', '##fi', '##lt', '##rated', 'American', 'intelligence', 'men', ',', 'learns', 'a', 'valuable', 'lesson', 'from', 'Beckett', '.', 'What', 'looks', 'good', 'in', 'theory', ',', 'is', 'irrelevant', 'in', 'the', 'jungle', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'Tom', 'Be', '##ren', '##ger', ',', 'is', 'an', 'actor', 'who', 'doesn', \"'\", 't', 'register', 'much', ',', 'as', 'he', 'proves', 'in', 'this', 'movie', ',', 'but', 'in', 'the', 'context', 'of', 'the', 'movie', ',', 'he', 'is', 'right', 'as', 'a', 'man', 'of', 'a', 'few', 'words', '.', 'Billy', 'Zane', 'playing', 'Miller', 'does', 'what', 'he', 'can', 'with', 'a', 'role', 'that', 'doesn', \"'\", 't', 'afford', 'him', 'any', 'glory', 'until', 'the', 'crucial', 'end', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'For', 'lovers', 'of', 'action', 'film', ',', '\"', 'S', '##ni', '##per', '\"', 'offers', 'an', '112', 'minutes', 'of', 'action', 'that', 'with', 'a', 'bit', 'of', 'trim', '##ming', 'would', 'have', 'made', 'a', 'more', 'satisfying', 'movie', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoding_sample[\"input_ids\"].squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCh7o863Zcuc"
   },
   "source": [
    "[CLS] indica clasificacion, en este caso a nivel de oracion.\n",
    "\n",
    "Classify Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YALfbA2qKNp7"
   },
   "source": [
    "Especificamos el máximo número de tokens por secuencia: 512.\n",
    "\n",
    "Analizamos la longitud de las secuencias en el grupo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 6769,
     "status": "ok",
     "timestamp": 1721169725148,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "ymXBT82pIlpy"
   },
   "outputs": [],
   "source": [
    "token_counts = []\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "  token_count = len(tokenizer.encode(\n",
    "    row[\"comment_text\"],\n",
    "    max_length=1024,\n",
    "    truncation=True\n",
    "  ))\n",
    "  token_counts.append(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1721169725154,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "c4x1nEccsvaO",
    "outputId": "0edbd8e8-f415-4c79-81d6-915d7640586e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean token count: 314.1051142857143\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos la media\n",
    "mean = np.mean(token_counts)\n",
    "print(\"Mean token count:\", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1721169725837,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "Lm8tHSuhJWNM",
    "outputId": "293ac0bc-8de7-462d-8a0a-a6ee509e2ac8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 513,
       "width": 734
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(token_counts)\n",
    "plt.xlim([0, 1024]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1721169729115,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "D63Sg9SzejIZ"
   },
   "outputs": [],
   "source": [
    "# Definimos hiperparámetro de máximo número de tokens en la secuencia\n",
    "MAX_TOKEN_COUNT = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgXNPSXU77oc"
   },
   "source": [
    "### Modulo Dataset que incluya el tokenizador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1721170110929,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "CQ1YdjRlYAxF"
   },
   "outputs": [],
   "source": [
    "from utils.data import IMDBDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nyqOozs9anR"
   },
   "source": [
    "Tomando una muestra del Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1721170112102,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "M72dsvC-CDZD",
    "outputId": "1ba70f2e-6e7a-40ba-d4d6-37eb4afc2e42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['comment_text', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usar la nueva clase IMDBDataset\n",
    "train_dataset = IMDBDataset(train_df, tokenizer, max_token_len=MAX_TOKEN_COUNT)\n",
    "\n",
    "sample_item = train_dataset[0]\n",
    "sample_item.keys()\n",
    "\n",
    "# Código original comentado:\n",
    "# train_dataset = ToxicCommentsDataset(train_df, tokenizer, max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1721170117754,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "R6L8exQSiYM-",
    "outputId": "488e4d5a-daad-4ebd-d08c-5becd6dbda4b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hello, I was wondering if anyone has a copy of the movie Broken Promise?? I loved this movie growing up and watched it every time it was on. It has been YEARS since I have seen it and would love to get a copy. I have checked all of the internet and have been unable to find it. If anyone has a copy to trade or sell em please email me at NoelGypsy@Yahoo.com... Thank you and have a great night!! Christine --------- The \"broken promise\" was made to eleven-year-old Melissa Michaelsen, whose parents have deserted her and her siblings. Taken in by the County, Michaelsen has had to watch helplessly as her brothers and sisters are split up and farmed out to different families. One of the kids is even institutionalized. Juvenile court officer Chris Sarandon joins Michaelsen in her struggle to reunite her family under one roof. Broken Promise was originally offered as a \"General Foods Golden Showcase\" presentation. It was first telecast May 5, 1981.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1721170121481,
     "user": {
      "displayName": "Karen Rosero",
      "userId": "14192812651435042745"
     },
     "user_tz": 300
    },
    "id": "ncSfaKkqiaFB",
    "outputId": "ba904c37-9fda-4c54-cce5-d27022a1daa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentimentClassifier\n",
    "from utils.model import SentimentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import SentimentDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 2187\n",
      "Total training steps: 6561\n",
      "Warmup steps: 1312\n",
      "Modelo y DataModule creados exitosamente para clasificación de sentimientos IMDB\n"
     ]
    }
   ],
   "source": [
    "# Configuración de entrenamiento actualizada para clasificación binaria IMDB\n",
    "N_EPOCHS = 3  # Reducido para pruebas más rápidas\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Crear DataModule\n",
    "data_module = SentimentDataModule(\n",
    "    train_df,\n",
    "    val_df, \n",
    "    test_df,\n",
    "    tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "# Calcular pasos de entrenamiento\n",
    "steps_per_epoch = len(train_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "warmup_steps = total_training_steps // 5\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Total training steps: {total_training_steps}\")\n",
    "print(f\"Warmup steps: {warmup_steps}\")\n",
    "\n",
    "# Crear modelo\n",
    "model = SentimentClassifier(\n",
    "    n_warmup_steps=warmup_steps,\n",
    "    n_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "print(\"Modelo y DataModule creados exitosamente para clasificación de sentimientos IMDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento del modelo BERT...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 22:41:31.443174: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757198491.465944 1041782 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757198491.473067 1041782 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757198491.491039 1041782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198491.491067 1041782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198491.491070 1041782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198491.491072 1041782 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "Dataset path: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n",
      "Using CSV: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1/IMDB Dataset.csv\n",
      "(50000, 2)\n",
      "Train DataFrame:\n",
      " 35000\n",
      "Validation DataFrame:\n",
      " 7500\n",
      "Test DataFrame:\n",
      " 7500\n",
      "Steps per epoch: 1093\n",
      "Total training steps: 10930\n",
      "Warmup steps: 2186\n",
      "Modelo y DataModule creados exitosamente para clasificación de sentimientos IMDB\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Trainer configurado para clasificación de sentimientos IMDB\n",
      "Iniciando entrenamiento del modelo de clasificación de sentimientos...\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "2025-09-06 22:41:42.927533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-06 22:41:42.927530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-06 22:41:42.946469: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757198502.950444 1042133 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757198502.950934 1042134 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757198502.957633 1042133 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1757198502.958398 1042134 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757198502.969166 1042132 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1757198502.975769 1042133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.975795 1042133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.975798 1042133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.975800 1042133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "E0000 00:00:1757198502.976249 1042132 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757198502.976615 1042134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.976633 1042134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.976637 1042134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.976640 1042134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.993703 1042132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.993720 1042132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.993722 1042132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757198502.993724 1042132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "Dataset path: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n",
      "Using CSV: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1/IMDB Dataset.csv\n",
      "Dataset path: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n",
      "Using CSV: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1/IMDB Dataset.csv\n",
      "Dataset path: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n",
      "Using CSV: /home/eaguayo/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1/IMDB Dataset.csv\n",
      "(50000, 2)\n",
      "Train DataFrame:\n",
      " 35000\n",
      "Validation DataFrame:\n",
      " 7500\n",
      "Test DataFrame:\n",
      " 7500\n",
      "(50000, 2)\n",
      "Train DataFrame:\n",
      " 35000\n",
      "Validation DataFrame:\n",
      " 7500\n",
      "Test DataFrame:\n",
      " 7500\n",
      "(50000, 2)\n",
      "Train DataFrame:\n",
      " 35000\n",
      "Validation DataFrame:\n",
      " 7500\n",
      "Test DataFrame:\n",
      " 7500\n",
      "Steps per epoch: 1093\n",
      "Total training steps: 10930\n",
      "Warmup steps: 2186\n",
      "Steps per epoch: 1093\n",
      "Total training steps: 10930\n",
      "Warmup steps: 2186\n",
      "Steps per epoch: 1093\n",
      "Total training steps: 10930\n",
      "Warmup steps: 2186\n",
      "Modelo y DataModule creados exitosamente para clasificación de sentimientos IMDB\n",
      "Modelo y DataModule creados exitosamente para clasificación de sentimientos IMDB\n",
      "Trainer configurado para clasificación de sentimientos IMDB\n",
      "Iniciando entrenamiento del modelo de clasificación de sentimientos...\n",
      "Modelo y DataModule creados exitosamente para clasificación de sentimientos IMDB\n",
      "Trainer configurado para clasificación de sentimientos IMDB\n",
      "Iniciando entrenamiento del modelo de clasificación de sentimientos...\n",
      "Trainer configurado para clasificación de sentimientos IMDB\n",
      "Iniciando entrenamiento del modelo de clasificación de sentimientos...\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "/home/eaguayo/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:701: Checkpoint directory /home/eaguayo/workspace/DeepLearning/Week3/bert-classifier/sentiment_checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name           | Type              | Params | Mode\n",
      "-------------------------------------------------------------\n",
      "0 | bert           | BertModel         | 108 M  | eval\n",
      "1 | dropout        | Dropout           | 0      | train\n",
      "2 | classifier     | Linear            | 769    | train\n",
      "3 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "4 | train_auroc    | BinaryAUROC       | 0      | train\n",
      "5 | val_auroc      | BinaryAUROC       | 0      | train\n",
      "6 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "7 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
      "-------------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "433.244   Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "228       Modules in eval mode\n",
      "\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]/home/eaguayo/.local/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: TorchMetricsUserWarning: You are trying to use a metric in deterministic mode on GPU that uses `torch.cumsum`, which is currently not supported. The tensor will be copied to the CPU memory to compute it and then copied back to GPU. Expect some slowdowns.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  1.79it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  2.41it/s]\n",
      "\n",
      "\n",
      "Training: |          | 0/? [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/274 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/274 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 1/274 [00:01<04:55,  0.92it/s]\n",
      "Epoch 0:   0%|          | 1/274 [00:01<04:55,  0.92it/s, v_num=11]\n",
      "Epoch 0:   1%|          | 2/274 [00:01<03:22,  1.34it/s, v_num=11]\n",
      "Epoch 0:   1%|          | 2/274 [00:01<03:22,  1.34it/s, v_num=11]\n",
      "Epoch 0:   1%|          | 3/274 [00:02<03:35,  1.26it/s, v_num=11]\n",
      "Epoch 0:   1%|          | 3/274 [00:02<03:35,  1.26it/s, v_num=11]\n",
      "Epoch 0:   1%|▏         | 4/274 [00:03<03:41,  1.22it/s, v_num=11]\n",
      "Epoch 0:   1%|▏         | 4/274 [00:03<03:41,  1.22it/s, v_num=11]\n",
      "Epoch 0:   2%|▏         | 5/274 [00:04<03:45,  1.20it/s, v_num=11]\n",
      "Epoch 0:   2%|▏         | 5/274 [00:04<03:45,  1.20it/s, v_num=11]\n",
      "Epoch 0:   2%|▏         | 6/274 [00:05<03:46,  1.18it/s, v_num=11]\n",
      "Epoch 0:   2%|▏         | 6/274 [00:05<03:46,  1.18it/s, v_num=11]\n",
      "Epoch 0:   3%|▎         | 7/274 [00:05<03:47,  1.17it/s, v_num=11]\n",
      "Epoch 0:   3%|▎         | 7/274 [00:05<03:47,  1.17it/s, v_num=11]\n",
      "Epoch 0:   3%|▎         | 8/274 [00:06<03:48,  1.16it/s, v_num=11]\n",
      "Epoch 0:   3%|▎         | 8/274 [00:06<03:48,  1.16it/s, v_num=11]\n",
      "Epoch 0:   3%|▎         | 9/274 [00:07<03:48,  1.16it/s, v_num=11]\n",
      "Epoch 0:   3%|▎         | 9/274 [00:07<03:48,  1.16it/s, v_num=11]\n",
      "Epoch 0:   4%|▎         | 10/274 [00:08<03:48,  1.15it/s, v_num=11]\n",
      "Epoch 0:   4%|▎         | 10/274 [00:08<03:48,  1.15it/s, v_num=11]\n",
      "Epoch 0:   4%|▍         | 11/274 [00:09<03:48,  1.15it/s, v_num=11]\n",
      "Epoch 0:   4%|▍         | 11/274 [00:09<03:48,  1.15it/s, v_num=11]\n",
      "Epoch 0:   4%|▍         | 12/274 [00:10<03:48,  1.15it/s, v_num=11]\n",
      "Epoch 0:   4%|▍         | 12/274 [00:10<03:48,  1.15it/s, v_num=11]\n",
      "Epoch 0:   5%|▍         | 13/274 [00:11<03:48,  1.14it/s, v_num=11]\n",
      "Epoch 0:   5%|▍         | 13/274 [00:11<03:48,  1.14it/s, v_num=11]\n",
      "Epoch 0:   5%|▌         | 14/274 [00:12<03:47,  1.14it/s, v_num=11]\n",
      "Epoch 0:   5%|▌         | 14/274 [00:12<03:47,  1.14it/s, v_num=11]\n",
      "Epoch 0:   5%|▌         | 15/274 [00:13<03:47,  1.14it/s, v_num=11]\n",
      "Epoch 0:   5%|▌         | 15/274 [00:13<03:47,  1.14it/s, v_num=11]\n",
      "Epoch 0:   6%|▌         | 16/274 [00:14<03:46,  1.14it/s, v_num=11]\n",
      "Epoch 0:   6%|▌         | 16/274 [00:14<03:46,  1.14it/s, v_num=11]\n",
      "Epoch 0:   6%|▌         | 17/274 [00:14<03:45,  1.14it/s, v_num=11]\n",
      "Epoch 0:   6%|▌         | 17/274 [00:14<03:45,  1.14it/s, v_num=11]\n",
      "Epoch 0:   7%|▋         | 18/274 [00:15<03:45,  1.14it/s, v_num=11]\n",
      "Epoch 0:   7%|▋         | 18/274 [00:15<03:45,  1.14it/s, v_num=11]\n",
      "Epoch 0:   7%|▋         | 19/274 [00:16<03:44,  1.13it/s, v_num=11]\n",
      "Epoch 0:   7%|▋         | 19/274 [00:16<03:44,  1.13it/s, v_num=11]\n",
      "Epoch 0:   7%|▋         | 20/274 [00:17<03:43,  1.13it/s, v_num=11]\n",
      "Epoch 0:   7%|▋         | 20/274 [00:17<03:44,  1.13it/s, v_num=11]\n",
      "Epoch 0:   8%|▊         | 21/274 [00:18<03:43,  1.13it/s, v_num=11]\n",
      "Epoch 0:   8%|▊         | 21/274 [00:18<03:43,  1.13it/s, v_num=11]\n",
      "Epoch 0:   8%|▊         | 22/274 [00:19<03:42,  1.13it/s, v_num=11]\n",
      "Epoch 0:   8%|▊         | 22/274 [00:19<03:42,  1.13it/s, v_num=11]\n",
      "Epoch 0:   8%|▊         | 23/274 [00:20<03:42,  1.13it/s, v_num=11]\n",
      "Epoch 0:   8%|▊         | 23/274 [00:20<03:42,  1.13it/s, v_num=11]\n",
      "Epoch 0:   9%|▉         | 24/274 [00:21<03:41,  1.13it/s, v_num=11]\n",
      "Epoch 0:   9%|▉         | 24/274 [00:21<03:41,  1.13it/s, v_num=11]\n",
      "Epoch 0:   9%|▉         | 25/274 [00:22<03:40,  1.13it/s, v_num=11]\n",
      "Epoch 0:   9%|▉         | 25/274 [00:22<03:40,  1.13it/s, v_num=11]\n",
      "Epoch 0:   9%|▉         | 26/274 [00:23<03:39,  1.13it/s, v_num=11]\n",
      "Epoch 0:   9%|▉         | 26/274 [00:23<03:39,  1.13it/s, v_num=11]\n",
      "Epoch 0:  10%|▉         | 27/274 [00:23<03:39,  1.13it/s, v_num=11]\n",
      "Epoch 0:  10%|▉         | 27/274 [00:23<03:39,  1.13it/s, v_num=11]\n",
      "Epoch 0:  10%|█         | 28/274 [00:24<03:38,  1.13it/s, v_num=11]\n",
      "Epoch 0:  10%|█         | 28/274 [00:24<03:38,  1.13it/s, v_num=11]\n",
      "Epoch 0:  11%|█         | 29/274 [00:25<03:37,  1.13it/s, v_num=11]\n",
      "Epoch 0:  11%|█         | 29/274 [00:25<03:37,  1.13it/s, v_num=11]\n",
      "Epoch 0:  11%|█         | 30/274 [00:26<03:36,  1.13it/s, v_num=11]\n",
      "Epoch 0:  11%|█         | 30/274 [00:26<03:36,  1.13it/s, v_num=11]\n",
      "Epoch 0:  11%|█▏        | 31/274 [00:27<03:35,  1.13it/s, v_num=11]\n",
      "Epoch 0:  11%|█▏        | 31/274 [00:27<03:35,  1.13it/s, v_num=11]\n",
      "Epoch 0:  12%|█▏        | 32/274 [00:28<03:35,  1.12it/s, v_num=11]\n",
      "Epoch 0:  12%|█▏        | 32/274 [00:28<03:35,  1.12it/s, v_num=11]\n",
      "Epoch 0:  12%|█▏        | 33/274 [00:29<03:34,  1.12it/s, v_num=11]\n",
      "Epoch 0:  12%|█▏        | 33/274 [00:29<03:34,  1.12it/s, v_num=11]\n",
      "Epoch 0:  12%|█▏        | 34/274 [00:30<03:33,  1.12it/s, v_num=11]\n",
      "Epoch 0:  12%|█▏        | 34/274 [00:30<03:33,  1.12it/s, v_num=11]\n",
      "Epoch 0:  13%|█▎        | 35/274 [00:31<03:32,  1.12it/s, v_num=11]\n",
      "Epoch 0:  13%|█▎        | 35/274 [00:31<03:32,  1.12it/s, v_num=11]\n",
      "Epoch 0:  13%|█▎        | 36/274 [00:32<03:31,  1.12it/s, v_num=11]\n",
      "Epoch 0:  13%|█▎        | 36/274 [00:32<03:31,  1.12it/s, v_num=11]\n",
      "Epoch 0:  14%|█▎        | 37/274 [00:32<03:31,  1.12it/s, v_num=11]\n",
      "Epoch 0:  14%|█▎        | 37/274 [00:32<03:31,  1.12it/s, v_num=11]\n",
      "Epoch 0:  14%|█▍        | 38/274 [00:33<03:30,  1.12it/s, v_num=11]\n",
      "Epoch 0:  14%|█▍        | 38/274 [00:33<03:30,  1.12it/s, v_num=11]\n",
      "Epoch 0:  14%|█▍        | 39/274 [00:34<03:29,  1.12it/s, v_num=11]\n",
      "Epoch 0:  14%|█▍        | 39/274 [00:34<03:29,  1.12it/s, v_num=11]\n",
      "Epoch 0:  15%|█▍        | 40/274 [00:35<03:28,  1.12it/s, v_num=11]\n",
      "Epoch 0:  15%|█▍        | 40/274 [00:35<03:28,  1.12it/s, v_num=11]\n",
      "Epoch 0:  15%|█▍        | 41/274 [00:36<03:27,  1.12it/s, v_num=11]\n",
      "Epoch 0:  15%|█▍        | 41/274 [00:36<03:27,  1.12it/s, v_num=11]\n",
      "Epoch 0:  15%|█▌        | 42/274 [00:37<03:26,  1.12it/s, v_num=11]\n",
      "Epoch 0:  15%|█▌        | 42/274 [00:37<03:26,  1.12it/s, v_num=11]\n",
      "Epoch 0:  16%|█▌        | 43/274 [00:38<03:25,  1.12it/s, v_num=11]\n",
      "Epoch 0:  16%|█▌        | 43/274 [00:38<03:26,  1.12it/s, v_num=11]\n",
      "Epoch 0:  16%|█▌        | 44/274 [00:39<03:25,  1.12it/s, v_num=11]\n",
      "Epoch 0:  16%|█▌        | 44/274 [00:39<03:25,  1.12it/s, v_num=11]\n",
      "Epoch 0:  16%|█▋        | 45/274 [00:40<03:24,  1.12it/s, v_num=11]\n",
      "Epoch 0:  16%|█▋        | 45/274 [00:40<03:24,  1.12it/s, v_num=11]\n",
      "Epoch 0:  17%|█▋        | 46/274 [00:41<03:23,  1.12it/s, v_num=11]\n",
      "Epoch 0:  17%|█▋        | 46/274 [00:41<03:23,  1.12it/s, v_num=11]\n",
      "Epoch 0:  17%|█▋        | 47/274 [00:41<03:22,  1.12it/s, v_num=11]\n",
      "Epoch 0:  17%|█▋        | 47/274 [00:41<03:22,  1.12it/s, v_num=11]\n",
      "Epoch 0:  18%|█▊        | 48/274 [00:42<03:21,  1.12it/s, v_num=11]\n",
      "Epoch 0:  18%|█▊        | 48/274 [00:42<03:21,  1.12it/s, v_num=11]\n",
      "Epoch 0:  18%|█▊        | 49/274 [00:43<03:20,  1.12it/s, v_num=11]\n",
      "Epoch 0:  18%|█▊        | 49/274 [00:43<03:20,  1.12it/s, v_num=11]\n",
      "Epoch 0:  18%|█▊        | 50/274 [00:44<03:19,  1.12it/s, v_num=11]\n",
      "Epoch 0:  18%|█▊        | 50/274 [00:44<03:19,  1.12it/s, v_num=11]\n",
      "Epoch 0:  19%|█▊        | 51/274 [00:45<03:19,  1.12it/s, v_num=11]\n",
      "Epoch 0:  19%|█▊        | 51/274 [00:45<03:19,  1.12it/s, v_num=11]\n",
      "Epoch 0:  19%|█▉        | 52/274 [00:46<03:18,  1.12it/s, v_num=11]\n",
      "Epoch 0:  19%|█▉        | 52/274 [00:46<03:18,  1.12it/s, v_num=11]\n",
      "Epoch 0:  19%|█▉        | 53/274 [00:47<03:17,  1.12it/s, v_num=11]\n",
      "Epoch 0:  19%|█▉        | 53/274 [00:47<03:17,  1.12it/s, v_num=11]\n",
      "Epoch 0:  20%|█▉        | 54/274 [00:48<03:16,  1.12it/s, v_num=11]\n",
      "Epoch 0:  20%|█▉        | 54/274 [00:48<03:16,  1.12it/s, v_num=11]\n",
      "Epoch 0:  20%|██        | 55/274 [00:49<03:15,  1.12it/s, v_num=11]\n",
      "Epoch 0:  20%|██        | 55/274 [00:49<03:15,  1.12it/s, v_num=11]\n",
      "Epoch 0:  20%|██        | 56/274 [00:50<03:14,  1.12it/s, v_num=11]\n",
      "Epoch 0:  20%|██        | 56/274 [00:50<03:14,  1.12it/s, v_num=11]\n",
      "Epoch 0:  21%|██        | 57/274 [00:50<03:13,  1.12it/s, v_num=11]\n",
      "Epoch 0:  21%|██        | 57/274 [00:50<03:13,  1.12it/s, v_num=11]\n",
      "Epoch 0:  21%|██        | 58/274 [00:51<03:13,  1.12it/s, v_num=11]\n",
      "Epoch 0:  21%|██        | 58/274 [00:51<03:13,  1.12it/s, v_num=11]\n",
      "Epoch 0:  22%|██▏       | 59/274 [00:52<03:12,  1.12it/s, v_num=11]\n",
      "Epoch 0:  22%|██▏       | 59/274 [00:52<03:12,  1.12it/s, v_num=11]\n",
      "Epoch 0:  22%|██▏       | 60/274 [00:53<03:11,  1.12it/s, v_num=11]\n",
      "Epoch 0:  22%|██▏       | 60/274 [00:53<03:11,  1.12it/s, v_num=11]\n",
      "Epoch 0:  22%|██▏       | 61/274 [00:54<03:10,  1.12it/s, v_num=11]\n",
      "Epoch 0:  22%|██▏       | 61/274 [00:54<03:10,  1.12it/s, v_num=11]\n",
      "Epoch 0:  23%|██▎       | 62/274 [00:55<03:09,  1.12it/s, v_num=11]\n",
      "Epoch 0:  23%|██▎       | 62/274 [00:55<03:09,  1.12it/s, v_num=11]\n",
      "Epoch 0:  23%|██▎       | 63/274 [00:56<03:08,  1.12it/s, v_num=11]\n",
      "Epoch 0:  23%|██▎       | 63/274 [00:56<03:08,  1.12it/s, v_num=11]\n",
      "Epoch 0:  23%|██▎       | 64/274 [00:57<03:07,  1.12it/s, v_num=11]\n",
      "Epoch 0:  23%|██▎       | 64/274 [00:57<03:07,  1.12it/s, v_num=11]\n",
      "Epoch 0:  24%|██▎       | 65/274 [00:58<03:06,  1.12it/s, v_num=11]\n",
      "Epoch 0:  24%|██▎       | 65/274 [00:58<03:06,  1.12it/s, v_num=11]\n",
      "Epoch 0:  24%|██▍       | 66/274 [00:59<03:06,  1.12it/s, v_num=11]\n",
      "Epoch 0:  24%|██▍       | 66/274 [00:59<03:06,  1.12it/s, v_num=11]\n",
      "Epoch 0:  24%|██▍       | 67/274 [00:59<03:05,  1.12it/s, v_num=11]\n",
      "Epoch 0:  24%|██▍       | 67/274 [00:59<03:05,  1.12it/s, v_num=11]\n",
      "Epoch 0:  25%|██▍       | 68/274 [01:00<03:04,  1.12it/s, v_num=11]\n",
      "Epoch 0:  25%|██▍       | 68/274 [01:00<03:04,  1.12it/s, v_num=11]\n",
      "Epoch 0:  25%|██▌       | 69/274 [01:01<03:03,  1.12it/s, v_num=11]\n",
      "Epoch 0:  25%|██▌       | 69/274 [01:01<03:03,  1.12it/s, v_num=11]\n",
      "Epoch 0:  26%|██▌       | 70/274 [01:02<03:02,  1.12it/s, v_num=11]\n",
      "Epoch 0:  26%|██▌       | 70/274 [01:02<03:02,  1.12it/s, v_num=11]\n",
      "Epoch 0:  26%|██▌       | 71/274 [01:03<03:01,  1.12it/s, v_num=11]\n",
      "Epoch 0:  26%|██▌       | 71/274 [01:03<03:01,  1.12it/s, v_num=11]\n",
      "Epoch 0:  26%|██▋       | 72/274 [01:04<03:00,  1.12it/s, v_num=11]\n",
      "Epoch 0:  26%|██▋       | 72/274 [01:04<03:00,  1.12it/s, v_num=11]\n",
      "Epoch 0:  27%|██▋       | 73/274 [01:05<02:59,  1.12it/s, v_num=11]\n",
      "Epoch 0:  27%|██▋       | 73/274 [01:05<02:59,  1.12it/s, v_num=11]\n",
      "Epoch 0:  27%|██▋       | 74/274 [01:06<02:59,  1.12it/s, v_num=11]\n",
      "Epoch 0:  27%|██▋       | 74/274 [01:06<02:59,  1.12it/s, v_num=11]\n",
      "Epoch 0:  27%|██▋       | 75/274 [01:07<02:58,  1.12it/s, v_num=11]\n",
      "Epoch 0:  27%|██▋       | 75/274 [01:07<02:58,  1.12it/s, v_num=11]\n",
      "Epoch 0:  28%|██▊       | 76/274 [01:08<02:57,  1.12it/s, v_num=11]\n",
      "Epoch 0:  28%|██▊       | 76/274 [01:08<02:57,  1.12it/s, v_num=11]\n",
      "Epoch 0:  28%|██▊       | 77/274 [01:08<02:56,  1.12it/s, v_num=11]\n",
      "Epoch 0:  28%|██▊       | 77/274 [01:08<02:56,  1.12it/s, v_num=11]\n",
      "Epoch 0:  28%|██▊       | 78/274 [01:09<02:55,  1.12it/s, v_num=11]\n",
      "Epoch 0:  28%|██▊       | 78/274 [01:09<02:55,  1.12it/s, v_num=11]\n",
      "Epoch 0:  29%|██▉       | 79/274 [01:10<02:54,  1.12it/s, v_num=11]\n",
      "Epoch 0:  29%|██▉       | 79/274 [01:10<02:54,  1.12it/s, v_num=11]\n",
      "Epoch 0:  29%|██▉       | 80/274 [01:11<02:53,  1.12it/s, v_num=11]\n",
      "Epoch 0:  29%|██▉       | 80/274 [01:11<02:53,  1.12it/s, v_num=11]\n",
      "Epoch 0:  30%|██▉       | 81/274 [01:12<02:52,  1.12it/s, v_num=11]\n",
      "Epoch 0:  30%|██▉       | 81/274 [01:12<02:52,  1.12it/s, v_num=11]\n",
      "Epoch 0:  30%|██▉       | 82/274 [01:13<02:52,  1.12it/s, v_num=11]\n",
      "Epoch 0:  30%|██▉       | 82/274 [01:13<02:52,  1.12it/s, v_num=11]\n",
      "Epoch 0:  30%|███       | 83/274 [01:14<02:51,  1.12it/s, v_num=11]\n",
      "Epoch 0:  30%|███       | 83/274 [01:14<02:51,  1.12it/s, v_num=11]\n",
      "Epoch 0:  31%|███       | 84/274 [01:15<02:50,  1.12it/s, v_num=11]\n",
      "Epoch 0:  31%|███       | 84/274 [01:15<02:50,  1.12it/s, v_num=11]\n",
      "Epoch 0:  31%|███       | 85/274 [01:16<02:49,  1.12it/s, v_num=11]\n",
      "Epoch 0:  31%|███       | 85/274 [01:16<02:49,  1.12it/s, v_num=11]\n",
      "Epoch 0:  31%|███▏      | 86/274 [01:17<02:48,  1.12it/s, v_num=11]\n",
      "Epoch 0:  31%|███▏      | 86/274 [01:17<02:48,  1.12it/s, v_num=11]\n",
      "Epoch 0:  32%|███▏      | 87/274 [01:17<02:47,  1.12it/s, v_num=11]\n",
      "Epoch 0:  32%|███▏      | 87/274 [01:17<02:47,  1.12it/s, v_num=11]\n",
      "Epoch 0:  32%|███▏      | 88/274 [01:18<02:46,  1.12it/s, v_num=11]\n",
      "Epoch 0:  32%|███▏      | 88/274 [01:18<02:46,  1.12it/s, v_num=11]\n",
      "Epoch 0:  32%|███▏      | 89/274 [01:19<02:45,  1.12it/s, v_num=11]\n",
      "Epoch 0:  32%|███▏      | 89/274 [01:19<02:45,  1.12it/s, v_num=11]\n",
      "Epoch 0:  33%|███▎      | 90/274 [01:20<02:44,  1.12it/s, v_num=11]\n",
      "Epoch 0:  33%|███▎      | 90/274 [01:20<02:44,  1.12it/s, v_num=11]\n",
      "Epoch 0:  33%|███▎      | 91/274 [01:21<02:44,  1.12it/s, v_num=11]\n",
      "Epoch 0:  33%|███▎      | 91/274 [01:21<02:44,  1.12it/s, v_num=11]\n",
      "Epoch 0:  34%|███▎      | 92/274 [01:22<02:43,  1.12it/s, v_num=11]\n",
      "Epoch 0:  34%|███▎      | 92/274 [01:22<02:43,  1.12it/s, v_num=11]\n",
      "Epoch 0:  34%|███▍      | 93/274 [01:23<02:42,  1.12it/s, v_num=11]\n",
      "Epoch 0:  34%|███▍      | 93/274 [01:23<02:42,  1.12it/s, v_num=11]\n",
      "Epoch 0:  34%|███▍      | 94/274 [01:24<02:41,  1.12it/s, v_num=11]\n",
      "Epoch 0:  34%|███▍      | 94/274 [01:24<02:41,  1.12it/s, v_num=11]\n",
      "Epoch 0:  35%|███▍      | 95/274 [01:25<02:40,  1.12it/s, v_num=11]\n",
      "Epoch 0:  35%|███▍      | 95/274 [01:25<02:40,  1.12it/s, v_num=11]\n",
      "Epoch 0:  35%|███▌      | 96/274 [01:26<02:39,  1.11it/s, v_num=11]\n",
      "Epoch 0:  35%|███▌      | 96/274 [01:26<02:39,  1.11it/s, v_num=11]\n",
      "Epoch 0:  35%|███▌      | 97/274 [01:27<02:38,  1.11it/s, v_num=11]\n",
      "Epoch 0:  35%|███▌      | 97/274 [01:27<02:38,  1.11it/s, v_num=11]\n",
      "Epoch 0:  36%|███▌      | 98/274 [01:27<02:37,  1.11it/s, v_num=11]\n",
      "Epoch 0:  36%|███▌      | 98/274 [01:27<02:37,  1.11it/s, v_num=11]\n",
      "Epoch 0:  36%|███▌      | 99/274 [01:28<02:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  36%|███▌      | 99/274 [01:28<02:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  36%|███▋      | 100/274 [01:29<02:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  36%|███▋      | 100/274 [01:29<02:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  37%|███▋      | 101/274 [01:30<02:35,  1.11it/s, v_num=11]\n",
      "Epoch 0:  37%|███▋      | 101/274 [01:30<02:35,  1.11it/s, v_num=11]\n",
      "Epoch 0:  37%|███▋      | 102/274 [01:31<02:34,  1.11it/s, v_num=11]\n",
      "Epoch 0:  37%|███▋      | 102/274 [01:31<02:34,  1.11it/s, v_num=11]\n",
      "Epoch 0:  38%|███▊      | 103/274 [01:32<02:33,  1.11it/s, v_num=11]\n",
      "Epoch 0:  38%|███▊      | 103/274 [01:32<02:33,  1.11it/s, v_num=11]\n",
      "Epoch 0:  38%|███▊      | 104/274 [01:33<02:32,  1.11it/s, v_num=11]\n",
      "Epoch 0:  38%|███▊      | 104/274 [01:33<02:32,  1.11it/s, v_num=11]\n",
      "Epoch 0:  38%|███▊      | 105/274 [01:34<02:31,  1.11it/s, v_num=11]\n",
      "Epoch 0:  38%|███▊      | 105/274 [01:34<02:31,  1.11it/s, v_num=11]\n",
      "Epoch 0:  39%|███▊      | 106/274 [01:35<02:30,  1.11it/s, v_num=11]\n",
      "Epoch 0:  39%|███▊      | 106/274 [01:35<02:30,  1.11it/s, v_num=11]\n",
      "Epoch 0:  39%|███▉      | 107/274 [01:36<02:29,  1.11it/s, v_num=11]\n",
      "Epoch 0:  39%|███▉      | 107/274 [01:36<02:29,  1.11it/s, v_num=11]\n",
      "Epoch 0:  39%|███▉      | 108/274 [01:36<02:29,  1.11it/s, v_num=11]\n",
      "Epoch 0:  39%|███▉      | 108/274 [01:36<02:29,  1.11it/s, v_num=11]\n",
      "Epoch 0:  40%|███▉      | 109/274 [01:37<02:28,  1.11it/s, v_num=11]\n",
      "Epoch 0:  40%|███▉      | 109/274 [01:37<02:28,  1.11it/s, v_num=11]\n",
      "Epoch 0:  40%|████      | 110/274 [01:38<02:27,  1.11it/s, v_num=11]\n",
      "Epoch 0:  40%|████      | 110/274 [01:38<02:27,  1.11it/s, v_num=11]\n",
      "Epoch 0:  41%|████      | 111/274 [01:39<02:26,  1.11it/s, v_num=11]\n",
      "Epoch 0:  41%|████      | 111/274 [01:39<02:26,  1.11it/s, v_num=11]\n",
      "Epoch 0:  41%|████      | 112/274 [01:40<02:25,  1.11it/s, v_num=11]\n",
      "Epoch 0:  41%|████      | 112/274 [01:40<02:25,  1.11it/s, v_num=11]\n",
      "Epoch 0:  41%|████      | 113/274 [01:41<02:24,  1.11it/s, v_num=11]\n",
      "Epoch 0:  41%|████      | 113/274 [01:41<02:24,  1.11it/s, v_num=11]\n",
      "Epoch 0:  42%|████▏     | 114/274 [01:42<02:23,  1.11it/s, v_num=11]\n",
      "Epoch 0:  42%|████▏     | 114/274 [01:42<02:23,  1.11it/s, v_num=11]\n",
      "Epoch 0:  42%|████▏     | 115/274 [01:43<02:22,  1.11it/s, v_num=11]\n",
      "Epoch 0:  42%|████▏     | 115/274 [01:43<02:22,  1.11it/s, v_num=11]\n",
      "Epoch 0:  42%|████▏     | 116/274 [01:44<02:21,  1.11it/s, v_num=11]\n",
      "Epoch 0:  42%|████▏     | 116/274 [01:44<02:21,  1.11it/s, v_num=11]\n",
      "Epoch 0:  43%|████▎     | 117/274 [01:45<02:20,  1.11it/s, v_num=11]\n",
      "Epoch 0:  43%|████▎     | 117/274 [01:45<02:20,  1.11it/s, v_num=11]\n",
      "Epoch 0:  43%|████▎     | 118/274 [01:45<02:20,  1.11it/s, v_num=11]\n",
      "Epoch 0:  43%|████▎     | 118/274 [01:45<02:20,  1.11it/s, v_num=11]\n",
      "Epoch 0:  43%|████▎     | 119/274 [01:46<02:19,  1.11it/s, v_num=11]\n",
      "Epoch 0:  43%|████▎     | 119/274 [01:46<02:19,  1.11it/s, v_num=11]\n",
      "Epoch 0:  44%|████▍     | 120/274 [01:47<02:18,  1.11it/s, v_num=11]\n",
      "Epoch 0:  44%|████▍     | 120/274 [01:47<02:18,  1.11it/s, v_num=11]\n",
      "Epoch 0:  44%|████▍     | 121/274 [01:48<02:17,  1.11it/s, v_num=11]\n",
      "Epoch 0:  44%|████▍     | 121/274 [01:48<02:17,  1.11it/s, v_num=11]\n",
      "Epoch 0:  45%|████▍     | 122/274 [01:49<02:16,  1.11it/s, v_num=11]\n",
      "Epoch 0:  45%|████▍     | 122/274 [01:49<02:16,  1.11it/s, v_num=11]\n",
      "Epoch 0:  45%|████▍     | 123/274 [01:50<02:15,  1.11it/s, v_num=11]\n",
      "Epoch 0:  45%|████▍     | 123/274 [01:50<02:15,  1.11it/s, v_num=11]\n",
      "Epoch 0:  45%|████▌     | 124/274 [01:51<02:14,  1.11it/s, v_num=11]\n",
      "Epoch 0:  45%|████▌     | 124/274 [01:51<02:14,  1.11it/s, v_num=11]\n",
      "Epoch 0:  46%|████▌     | 125/274 [01:52<02:13,  1.11it/s, v_num=11]\n",
      "Epoch 0:  46%|████▌     | 125/274 [01:52<02:13,  1.11it/s, v_num=11]\n",
      "Epoch 0:  46%|████▌     | 126/274 [01:53<02:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  46%|████▌     | 126/274 [01:53<02:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  46%|████▋     | 127/274 [01:54<02:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  46%|████▋     | 127/274 [01:54<02:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  47%|████▋     | 128/274 [01:55<02:11,  1.11it/s, v_num=11]\n",
      "Epoch 0:  47%|████▋     | 128/274 [01:55<02:11,  1.11it/s, v_num=11]\n",
      "Epoch 0:  47%|████▋     | 129/274 [01:55<02:10,  1.11it/s, v_num=11]\n",
      "Epoch 0:  47%|████▋     | 129/274 [01:55<02:10,  1.11it/s, v_num=11]\n",
      "Epoch 0:  47%|████▋     | 130/274 [01:56<02:09,  1.11it/s, v_num=11]\n",
      "Epoch 0:  47%|████▋     | 130/274 [01:56<02:09,  1.11it/s, v_num=11]\n",
      "Epoch 0:  48%|████▊     | 131/274 [01:57<02:08,  1.11it/s, v_num=11]\n",
      "Epoch 0:  48%|████▊     | 131/274 [01:57<02:08,  1.11it/s, v_num=11]\n",
      "Epoch 0:  48%|████▊     | 132/274 [01:58<02:07,  1.11it/s, v_num=11]\n",
      "Epoch 0:  48%|████▊     | 132/274 [01:58<02:07,  1.11it/s, v_num=11]\n",
      "Epoch 0:  49%|████▊     | 133/274 [01:59<02:06,  1.11it/s, v_num=11]\n",
      "Epoch 0:  49%|████▊     | 133/274 [01:59<02:06,  1.11it/s, v_num=11]\n",
      "Epoch 0:  49%|████▉     | 134/274 [02:00<02:05,  1.11it/s, v_num=11]\n",
      "Epoch 0:  49%|████▉     | 134/274 [02:00<02:05,  1.11it/s, v_num=11]\n",
      "Epoch 0:  49%|████▉     | 135/274 [02:01<02:04,  1.11it/s, v_num=11]\n",
      "Epoch 0:  49%|████▉     | 135/274 [02:01<02:04,  1.11it/s, v_num=11]\n",
      "Epoch 0:  50%|████▉     | 136/274 [02:02<02:04,  1.11it/s, v_num=11]\n",
      "Epoch 0:  50%|████▉     | 136/274 [02:02<02:04,  1.11it/s, v_num=11]\n",
      "Epoch 0:  50%|█████     | 137/274 [02:03<02:03,  1.11it/s, v_num=11]\n",
      "Epoch 0:  50%|█████     | 137/274 [02:03<02:03,  1.11it/s, v_num=11]\n",
      "Epoch 0:  50%|█████     | 138/274 [02:04<02:02,  1.11it/s, v_num=11]\n",
      "Epoch 0:  50%|█████     | 138/274 [02:04<02:02,  1.11it/s, v_num=11]\n",
      "Epoch 0:  51%|█████     | 139/274 [02:04<02:01,  1.11it/s, v_num=11]\n",
      "Epoch 0:  51%|█████     | 139/274 [02:04<02:01,  1.11it/s, v_num=11]\n",
      "Epoch 0:  51%|█████     | 140/274 [02:05<02:00,  1.11it/s, v_num=11]\n",
      "Epoch 0:  51%|█████     | 140/274 [02:05<02:00,  1.11it/s, v_num=11]\n",
      "Epoch 0:  51%|█████▏    | 141/274 [02:06<01:59,  1.11it/s, v_num=11]\n",
      "Epoch 0:  51%|█████▏    | 141/274 [02:06<01:59,  1.11it/s, v_num=11]\n",
      "Epoch 0:  52%|█████▏    | 142/274 [02:07<01:58,  1.11it/s, v_num=11]\n",
      "Epoch 0:  52%|█████▏    | 142/274 [02:07<01:58,  1.11it/s, v_num=11]\n",
      "Epoch 0:  52%|█████▏    | 143/274 [02:08<01:57,  1.11it/s, v_num=11]\n",
      "Epoch 0:  52%|█████▏    | 143/274 [02:08<01:57,  1.11it/s, v_num=11]\n",
      "Epoch 0:  53%|█████▎    | 144/274 [02:09<01:56,  1.11it/s, v_num=11]\n",
      "Epoch 0:  53%|█████▎    | 144/274 [02:09<01:56,  1.11it/s, v_num=11]\n",
      "Epoch 0:  53%|█████▎    | 145/274 [02:10<01:55,  1.11it/s, v_num=11]\n",
      "Epoch 0:  53%|█████▎    | 145/274 [02:10<01:55,  1.11it/s, v_num=11]\n",
      "Epoch 0:  53%|█████▎    | 146/274 [02:11<01:55,  1.11it/s, v_num=11]\n",
      "Epoch 0:  53%|█████▎    | 146/274 [02:11<01:55,  1.11it/s, v_num=11]\n",
      "Epoch 0:  54%|█████▎    | 147/274 [02:12<01:54,  1.11it/s, v_num=11]\n",
      "Epoch 0:  54%|█████▎    | 147/274 [02:12<01:54,  1.11it/s, v_num=11]\n",
      "Epoch 0:  54%|█████▍    | 148/274 [02:13<01:53,  1.11it/s, v_num=11]\n",
      "Epoch 0:  54%|█████▍    | 148/274 [02:13<01:53,  1.11it/s, v_num=11]\n",
      "Epoch 0:  54%|█████▍    | 149/274 [02:14<01:52,  1.11it/s, v_num=11]\n",
      "Epoch 0:  54%|█████▍    | 149/274 [02:14<01:52,  1.11it/s, v_num=11]\n",
      "Epoch 0:  55%|█████▍    | 150/274 [02:14<01:51,  1.11it/s, v_num=11]\n",
      "Epoch 0:  55%|█████▍    | 150/274 [02:14<01:51,  1.11it/s, v_num=11]\n",
      "Epoch 0:  55%|█████▌    | 151/274 [02:15<01:50,  1.11it/s, v_num=11]\n",
      "Epoch 0:  55%|█████▌    | 151/274 [02:15<01:50,  1.11it/s, v_num=11]\n",
      "Epoch 0:  55%|█████▌    | 152/274 [02:16<01:49,  1.11it/s, v_num=11]\n",
      "Epoch 0:  55%|█████▌    | 152/274 [02:16<01:49,  1.11it/s, v_num=11]\n",
      "Epoch 0:  56%|█████▌    | 153/274 [02:17<01:48,  1.11it/s, v_num=11]\n",
      "Epoch 0:  56%|█████▌    | 153/274 [02:17<01:48,  1.11it/s, v_num=11]\n",
      "Epoch 0:  56%|█████▌    | 154/274 [02:18<01:47,  1.11it/s, v_num=11]\n",
      "Epoch 0:  56%|█████▌    | 154/274 [02:18<01:47,  1.11it/s, v_num=11]\n",
      "Epoch 0:  57%|█████▋    | 155/274 [02:19<01:47,  1.11it/s, v_num=11]\n",
      "Epoch 0:  57%|█████▋    | 155/274 [02:19<01:47,  1.11it/s, v_num=11]\n",
      "Epoch 0:  57%|█████▋    | 156/274 [02:20<01:46,  1.11it/s, v_num=11]\n",
      "Epoch 0:  57%|█████▋    | 156/274 [02:20<01:46,  1.11it/s, v_num=11]\n",
      "Epoch 0:  57%|█████▋    | 157/274 [02:21<01:45,  1.11it/s, v_num=11]\n",
      "Epoch 0:  57%|█████▋    | 157/274 [02:21<01:45,  1.11it/s, v_num=11]\n",
      "Epoch 0:  58%|█████▊    | 158/274 [02:22<01:44,  1.11it/s, v_num=11]\n",
      "Epoch 0:  58%|█████▊    | 158/274 [02:22<01:44,  1.11it/s, v_num=11]\n",
      "Epoch 0:  58%|█████▊    | 159/274 [02:23<01:43,  1.11it/s, v_num=11]\n",
      "Epoch 0:  58%|█████▊    | 159/274 [02:23<01:43,  1.11it/s, v_num=11]\n",
      "Epoch 0:  58%|█████▊    | 160/274 [02:23<01:42,  1.11it/s, v_num=11]\n",
      "Epoch 0:  58%|█████▊    | 160/274 [02:23<01:42,  1.11it/s, v_num=11]\n",
      "Epoch 0:  59%|█████▉    | 161/274 [02:24<01:41,  1.11it/s, v_num=11]\n",
      "Epoch 0:  59%|█████▉    | 161/274 [02:24<01:41,  1.11it/s, v_num=11]\n",
      "Epoch 0:  59%|█████▉    | 162/274 [02:25<01:40,  1.11it/s, v_num=11]\n",
      "Epoch 0:  59%|█████▉    | 162/274 [02:25<01:40,  1.11it/s, v_num=11]\n",
      "Epoch 0:  59%|█████▉    | 163/274 [02:26<01:39,  1.11it/s, v_num=11]\n",
      "Epoch 0:  59%|█████▉    | 163/274 [02:26<01:39,  1.11it/s, v_num=11]\n",
      "Epoch 0:  60%|█████▉    | 164/274 [02:27<01:38,  1.11it/s, v_num=11]\n",
      "Epoch 0:  60%|█████▉    | 164/274 [02:27<01:38,  1.11it/s, v_num=11]\n",
      "Epoch 0:  60%|██████    | 165/274 [02:28<01:38,  1.11it/s, v_num=11]\n",
      "Epoch 0:  60%|██████    | 165/274 [02:28<01:38,  1.11it/s, v_num=11]\n",
      "Epoch 0:  61%|██████    | 166/274 [02:29<01:37,  1.11it/s, v_num=11]\n",
      "Epoch 0:  61%|██████    | 166/274 [02:29<01:37,  1.11it/s, v_num=11]\n",
      "Epoch 0:  61%|██████    | 167/274 [02:30<01:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  61%|██████    | 167/274 [02:30<01:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  61%|██████▏   | 168/274 [02:31<01:35,  1.11it/s, v_num=11]\n",
      "Epoch 0:  61%|██████▏   | 168/274 [02:31<01:35,  1.11it/s, v_num=11]\n",
      "Epoch 0:  62%|██████▏   | 169/274 [02:32<01:34,  1.11it/s, v_num=11]\n",
      "Epoch 0:  62%|██████▏   | 169/274 [02:32<01:34,  1.11it/s, v_num=11]\n",
      "Epoch 0:  62%|██████▏   | 170/274 [02:32<01:33,  1.11it/s, v_num=11]\n",
      "Epoch 0:  62%|██████▏   | 170/274 [02:32<01:33,  1.11it/s, v_num=11]\n",
      "Epoch 0:  62%|██████▏   | 171/274 [02:33<01:32,  1.11it/s, v_num=11]\n",
      "Epoch 0:  62%|██████▏   | 171/274 [02:33<01:32,  1.11it/s, v_num=11]\n",
      "Epoch 0:  63%|██████▎   | 172/274 [02:34<01:31,  1.11it/s, v_num=11]\n",
      "Epoch 0:  63%|██████▎   | 172/274 [02:34<01:31,  1.11it/s, v_num=11]\n",
      "Epoch 0:  63%|██████▎   | 173/274 [02:35<01:30,  1.11it/s, v_num=11]\n",
      "Epoch 0:  63%|██████▎   | 173/274 [02:35<01:30,  1.11it/s, v_num=11]\n",
      "Epoch 0:  64%|██████▎   | 174/274 [02:36<01:30,  1.11it/s, v_num=11]\n",
      "Epoch 0:  64%|██████▎   | 174/274 [02:36<01:30,  1.11it/s, v_num=11]\n",
      "Epoch 0:  64%|██████▍   | 175/274 [02:37<01:29,  1.11it/s, v_num=11]\n",
      "Epoch 0:  64%|██████▍   | 175/274 [02:37<01:29,  1.11it/s, v_num=11]\n",
      "Epoch 0:  64%|██████▍   | 176/274 [02:38<01:28,  1.11it/s, v_num=11]\n",
      "Epoch 0:  64%|██████▍   | 176/274 [02:38<01:28,  1.11it/s, v_num=11]\n",
      "Epoch 0:  65%|██████▍   | 177/274 [02:39<01:27,  1.11it/s, v_num=11]\n",
      "Epoch 0:  65%|██████▍   | 177/274 [02:39<01:27,  1.11it/s, v_num=11]\n",
      "Epoch 0:  65%|██████▍   | 178/274 [02:40<01:26,  1.11it/s, v_num=11]\n",
      "Epoch 0:  65%|██████▍   | 178/274 [02:40<01:26,  1.11it/s, v_num=11]\n",
      "Epoch 0:  65%|██████▌   | 179/274 [02:41<01:25,  1.11it/s, v_num=11]\n",
      "Epoch 0:  65%|██████▌   | 179/274 [02:41<01:25,  1.11it/s, v_num=11]\n",
      "Epoch 0:  66%|██████▌   | 180/274 [02:42<01:24,  1.11it/s, v_num=11]\n",
      "Epoch 0:  66%|██████▌   | 180/274 [02:42<01:24,  1.11it/s, v_num=11]\n",
      "Epoch 0:  66%|██████▌   | 181/274 [02:42<01:23,  1.11it/s, v_num=11]\n",
      "Epoch 0:  66%|██████▌   | 181/274 [02:42<01:23,  1.11it/s, v_num=11]\n",
      "Epoch 0:  66%|██████▋   | 182/274 [02:43<01:22,  1.11it/s, v_num=11]\n",
      "Epoch 0:  66%|██████▋   | 182/274 [02:43<01:22,  1.11it/s, v_num=11]\n",
      "Epoch 0:  67%|██████▋   | 183/274 [02:44<01:21,  1.11it/s, v_num=11]\n",
      "Epoch 0:  67%|██████▋   | 183/274 [02:44<01:21,  1.11it/s, v_num=11]\n",
      "Epoch 0:  67%|██████▋   | 184/274 [02:45<01:21,  1.11it/s, v_num=11]\n",
      "Epoch 0:  67%|██████▋   | 184/274 [02:45<01:21,  1.11it/s, v_num=11]\n",
      "Epoch 0:  68%|██████▊   | 185/274 [02:46<01:20,  1.11it/s, v_num=11]\n",
      "Epoch 0:  68%|██████▊   | 185/274 [02:46<01:20,  1.11it/s, v_num=11]\n",
      "Epoch 0:  68%|██████▊   | 186/274 [02:47<01:19,  1.11it/s, v_num=11]\n",
      "Epoch 0:  68%|██████▊   | 186/274 [02:47<01:19,  1.11it/s, v_num=11]\n",
      "Epoch 0:  68%|██████▊   | 187/274 [02:48<01:18,  1.11it/s, v_num=11]\n",
      "Epoch 0:  68%|██████▊   | 187/274 [02:48<01:18,  1.11it/s, v_num=11]\n",
      "Epoch 0:  69%|██████▊   | 188/274 [02:49<01:17,  1.11it/s, v_num=11]\n",
      "Epoch 0:  69%|██████▊   | 188/274 [02:49<01:17,  1.11it/s, v_num=11]\n",
      "Epoch 0:  69%|██████▉   | 189/274 [02:50<01:16,  1.11it/s, v_num=11]\n",
      "Epoch 0:  69%|██████▉   | 189/274 [02:50<01:16,  1.11it/s, v_num=11]\n",
      "Epoch 0:  69%|██████▉   | 190/274 [02:51<01:15,  1.11it/s, v_num=11]\n",
      "Epoch 0:  69%|██████▉   | 190/274 [02:51<01:15,  1.11it/s, v_num=11]\n",
      "Epoch 0:  70%|██████▉   | 191/274 [02:52<01:14,  1.11it/s, v_num=11]\n",
      "Epoch 0:  70%|██████▉   | 191/274 [02:52<01:14,  1.11it/s, v_num=11]\n",
      "Epoch 0:  70%|███████   | 192/274 [02:52<01:13,  1.11it/s, v_num=11]\n",
      "Epoch 0:  70%|███████   | 192/274 [02:52<01:13,  1.11it/s, v_num=11]\n",
      "Epoch 0:  70%|███████   | 193/274 [02:53<01:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  70%|███████   | 193/274 [02:53<01:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  71%|███████   | 194/274 [02:54<01:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  71%|███████   | 194/274 [02:54<01:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  71%|███████   | 195/274 [02:55<01:11,  1.11it/s, v_num=11]\n",
      "Epoch 0:  71%|███████   | 195/274 [02:55<01:11,  1.11it/s, v_num=11]\n",
      "Epoch 0:  72%|███████▏  | 196/274 [02:56<01:10,  1.11it/s, v_num=11]\n",
      "Epoch 0:  72%|███████▏  | 196/274 [02:56<01:10,  1.11it/s, v_num=11]\n",
      "Epoch 0:  72%|███████▏  | 197/274 [02:57<01:09,  1.11it/s, v_num=11]\n",
      "Epoch 0:  72%|███████▏  | 197/274 [02:57<01:09,  1.11it/s, v_num=11]\n",
      "Epoch 0:  72%|███████▏  | 198/274 [02:58<01:08,  1.11it/s, v_num=11]\n",
      "Epoch 0:  72%|███████▏  | 198/274 [02:58<01:08,  1.11it/s, v_num=11]\n",
      "Epoch 0:  73%|███████▎  | 199/274 [02:59<01:07,  1.11it/s, v_num=11]\n",
      "Epoch 0:  73%|███████▎  | 199/274 [02:59<01:07,  1.11it/s, v_num=11]\n",
      "Epoch 0:  73%|███████▎  | 200/274 [03:00<01:06,  1.11it/s, v_num=11]\n",
      "Epoch 0:  73%|███████▎  | 200/274 [03:00<01:06,  1.11it/s, v_num=11]\n",
      "Epoch 0:  73%|███████▎  | 201/274 [03:01<01:05,  1.11it/s, v_num=11]\n",
      "Epoch 0:  73%|███████▎  | 201/274 [03:01<01:05,  1.11it/s, v_num=11]\n",
      "Epoch 0:  74%|███████▎  | 202/274 [03:01<01:04,  1.11it/s, v_num=11]\n",
      "Epoch 0:  74%|███████▎  | 202/274 [03:01<01:04,  1.11it/s, v_num=11]\n",
      "Epoch 0:  74%|███████▍  | 203/274 [03:02<01:03,  1.11it/s, v_num=11]\n",
      "Epoch 0:  74%|███████▍  | 203/274 [03:02<01:03,  1.11it/s, v_num=11]\n",
      "Epoch 0:  74%|███████▍  | 204/274 [03:03<01:03,  1.11it/s, v_num=11]\n",
      "Epoch 0:  74%|███████▍  | 204/274 [03:03<01:03,  1.11it/s, v_num=11]\n",
      "Epoch 0:  75%|███████▍  | 205/274 [03:04<01:02,  1.11it/s, v_num=11]\n",
      "Epoch 0:  75%|███████▍  | 205/274 [03:04<01:02,  1.11it/s, v_num=11]\n",
      "Epoch 0:  75%|███████▌  | 206/274 [03:05<01:01,  1.11it/s, v_num=11]\n",
      "Epoch 0:  75%|███████▌  | 206/274 [03:05<01:01,  1.11it/s, v_num=11]\n",
      "Epoch 0:  76%|███████▌  | 207/274 [03:06<01:00,  1.11it/s, v_num=11]\n",
      "Epoch 0:  76%|███████▌  | 207/274 [03:06<01:00,  1.11it/s, v_num=11]\n",
      "Epoch 0:  76%|███████▌  | 208/274 [03:07<00:59,  1.11it/s, v_num=11]\n",
      "Epoch 0:  76%|███████▌  | 208/274 [03:07<00:59,  1.11it/s, v_num=11]\n",
      "Epoch 0:  76%|███████▋  | 209/274 [03:08<00:58,  1.11it/s, v_num=11]\n",
      "Epoch 0:  76%|███████▋  | 209/274 [03:08<00:58,  1.11it/s, v_num=11]\n",
      "Epoch 0:  77%|███████▋  | 210/274 [03:09<00:57,  1.11it/s, v_num=11]\n",
      "Epoch 0:  77%|███████▋  | 210/274 [03:09<00:57,  1.11it/s, v_num=11]\n",
      "Epoch 0:  77%|███████▋  | 211/274 [03:10<00:56,  1.11it/s, v_num=11]\n",
      "Epoch 0:  77%|███████▋  | 211/274 [03:10<00:56,  1.11it/s, v_num=11]\n",
      "Epoch 0:  77%|███████▋  | 212/274 [03:11<00:55,  1.11it/s, v_num=11]\n",
      "Epoch 0:  77%|███████▋  | 212/274 [03:11<00:55,  1.11it/s, v_num=11]\n",
      "Epoch 0:  78%|███████▊  | 213/274 [03:11<00:54,  1.11it/s, v_num=11]\n",
      "Epoch 0:  78%|███████▊  | 213/274 [03:11<00:54,  1.11it/s, v_num=11]\n",
      "Epoch 0:  78%|███████▊  | 214/274 [03:12<00:54,  1.11it/s, v_num=11]\n",
      "Epoch 0:  78%|███████▊  | 214/274 [03:12<00:54,  1.11it/s, v_num=11]\n",
      "Epoch 0:  78%|███████▊  | 215/274 [03:13<00:53,  1.11it/s, v_num=11]\n",
      "Epoch 0:  78%|███████▊  | 215/274 [03:13<00:53,  1.11it/s, v_num=11]\n",
      "Epoch 0:  79%|███████▉  | 216/274 [03:14<00:52,  1.11it/s, v_num=11]\n",
      "Epoch 0:  79%|███████▉  | 216/274 [03:14<00:52,  1.11it/s, v_num=11]\n",
      "Epoch 0:  79%|███████▉  | 217/274 [03:15<00:51,  1.11it/s, v_num=11]\n",
      "Epoch 0:  79%|███████▉  | 217/274 [03:15<00:51,  1.11it/s, v_num=11]\n",
      "Epoch 0:  80%|███████▉  | 218/274 [03:16<00:50,  1.11it/s, v_num=11]\n",
      "Epoch 0:  80%|███████▉  | 218/274 [03:16<00:50,  1.11it/s, v_num=11]\n",
      "Epoch 0:  80%|███████▉  | 219/274 [03:17<00:49,  1.11it/s, v_num=11]\n",
      "Epoch 0:  80%|███████▉  | 219/274 [03:17<00:49,  1.11it/s, v_num=11]\n",
      "Epoch 0:  80%|████████  | 220/274 [03:18<00:48,  1.11it/s, v_num=11]\n",
      "Epoch 0:  80%|████████  | 220/274 [03:18<00:48,  1.11it/s, v_num=11]\n",
      "Epoch 0:  81%|████████  | 221/274 [03:19<00:47,  1.11it/s, v_num=11]\n",
      "Epoch 0:  81%|████████  | 221/274 [03:19<00:47,  1.11it/s, v_num=11]\n",
      "Epoch 0:  81%|████████  | 222/274 [03:20<00:46,  1.11it/s, v_num=11]\n",
      "Epoch 0:  81%|████████  | 222/274 [03:20<00:46,  1.11it/s, v_num=11]\n",
      "Epoch 0:  81%|████████▏ | 223/274 [03:21<00:45,  1.11it/s, v_num=11]\n",
      "Epoch 0:  81%|████████▏ | 223/274 [03:21<00:45,  1.11it/s, v_num=11]\n",
      "Epoch 0:  82%|████████▏ | 224/274 [03:21<00:45,  1.11it/s, v_num=11]\n",
      "Epoch 0:  82%|████████▏ | 224/274 [03:21<00:45,  1.11it/s, v_num=11]\n",
      "Epoch 0:  82%|████████▏ | 225/274 [03:22<00:44,  1.11it/s, v_num=11]\n",
      "Epoch 0:  82%|████████▏ | 225/274 [03:22<00:44,  1.11it/s, v_num=11]\n",
      "Epoch 0:  82%|████████▏ | 226/274 [03:23<00:43,  1.11it/s, v_num=11]\n",
      "Epoch 0:  82%|████████▏ | 226/274 [03:23<00:43,  1.11it/s, v_num=11]\n",
      "Epoch 0:  83%|████████▎ | 227/274 [03:24<00:42,  1.11it/s, v_num=11]\n",
      "Epoch 0:  83%|████████▎ | 227/274 [03:24<00:42,  1.11it/s, v_num=11]\n",
      "Epoch 0:  83%|████████▎ | 228/274 [03:25<00:41,  1.11it/s, v_num=11]\n",
      "Epoch 0:  83%|████████▎ | 228/274 [03:25<00:41,  1.11it/s, v_num=11]\n",
      "Epoch 0:  84%|████████▎ | 229/274 [03:26<00:40,  1.11it/s, v_num=11]\n",
      "Epoch 0:  84%|████████▎ | 229/274 [03:26<00:40,  1.11it/s, v_num=11]\n",
      "Epoch 0:  84%|████████▍ | 230/274 [03:27<00:39,  1.11it/s, v_num=11]\n",
      "Epoch 0:  84%|████████▍ | 230/274 [03:27<00:39,  1.11it/s, v_num=11]\n",
      "Epoch 0:  84%|████████▍ | 231/274 [03:28<00:38,  1.11it/s, v_num=11]\n",
      "Epoch 0:  84%|████████▍ | 231/274 [03:28<00:38,  1.11it/s, v_num=11]\n",
      "Epoch 0:  85%|████████▍ | 232/274 [03:29<00:37,  1.11it/s, v_num=11]\n",
      "Epoch 0:  85%|████████▍ | 232/274 [03:29<00:37,  1.11it/s, v_num=11]\n",
      "Epoch 0:  85%|████████▌ | 233/274 [03:30<00:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  85%|████████▌ | 233/274 [03:30<00:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  85%|████████▌ | 234/274 [03:30<00:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  85%|████████▌ | 234/274 [03:30<00:36,  1.11it/s, v_num=11]\n",
      "Epoch 0:  86%|████████▌ | 235/274 [03:31<00:35,  1.11it/s, v_num=11]\n",
      "Epoch 0:  86%|████████▌ | 235/274 [03:31<00:35,  1.11it/s, v_num=11]\n",
      "Epoch 0:  86%|████████▌ | 236/274 [03:32<00:34,  1.11it/s, v_num=11]\n",
      "Epoch 0:  86%|████████▌ | 236/274 [03:32<00:34,  1.11it/s, v_num=11]\n",
      "Epoch 0:  86%|████████▋ | 237/274 [03:33<00:33,  1.11it/s, v_num=11]\n",
      "Epoch 0:  86%|████████▋ | 237/274 [03:33<00:33,  1.11it/s, v_num=11]\n",
      "Epoch 0:  87%|████████▋ | 238/274 [03:34<00:32,  1.11it/s, v_num=11]\n",
      "Epoch 0:  87%|████████▋ | 238/274 [03:34<00:32,  1.11it/s, v_num=11]\n",
      "Epoch 0:  87%|████████▋ | 239/274 [03:35<00:31,  1.11it/s, v_num=11]\n",
      "Epoch 0:  87%|████████▋ | 239/274 [03:35<00:31,  1.11it/s, v_num=11]\n",
      "Epoch 0:  88%|████████▊ | 240/274 [03:36<00:30,  1.11it/s, v_num=11]\n",
      "Epoch 0:  88%|████████▊ | 240/274 [03:36<00:30,  1.11it/s, v_num=11]\n",
      "Epoch 0:  88%|████████▊ | 241/274 [03:37<00:29,  1.11it/s, v_num=11]\n",
      "Epoch 0:  88%|████████▊ | 241/274 [03:37<00:29,  1.11it/s, v_num=11]\n",
      "Epoch 0:  88%|████████▊ | 242/274 [03:38<00:28,  1.11it/s, v_num=11]\n",
      "Epoch 0:  88%|████████▊ | 242/274 [03:38<00:28,  1.11it/s, v_num=11]\n",
      "Epoch 0:  89%|████████▊ | 243/274 [03:39<00:27,  1.11it/s, v_num=11]\n",
      "Epoch 0:  89%|████████▊ | 243/274 [03:39<00:27,  1.11it/s, v_num=11]\n",
      "Epoch 0:  89%|████████▉ | 244/274 [03:40<00:27,  1.11it/s, v_num=11]\n",
      "Epoch 0:  89%|████████▉ | 244/274 [03:40<00:27,  1.11it/s, v_num=11]\n",
      "Epoch 0:  89%|████████▉ | 245/274 [03:40<00:26,  1.11it/s, v_num=11]\n",
      "Epoch 0:  89%|████████▉ | 245/274 [03:40<00:26,  1.11it/s, v_num=11]\n",
      "Epoch 0:  90%|████████▉ | 246/274 [03:41<00:25,  1.11it/s, v_num=11]\n",
      "Epoch 0:  90%|████████▉ | 246/274 [03:41<00:25,  1.11it/s, v_num=11]\n",
      "Epoch 0:  90%|█████████ | 247/274 [03:42<00:24,  1.11it/s, v_num=11]\n",
      "Epoch 0:  90%|█████████ | 247/274 [03:42<00:24,  1.11it/s, v_num=11]\n",
      "Epoch 0:  91%|█████████ | 248/274 [03:43<00:23,  1.11it/s, v_num=11]\n",
      "Epoch 0:  91%|█████████ | 248/274 [03:43<00:23,  1.11it/s, v_num=11]\n",
      "Epoch 0:  91%|█████████ | 249/274 [03:44<00:22,  1.11it/s, v_num=11]\n",
      "Epoch 0:  91%|█████████ | 249/274 [03:44<00:22,  1.11it/s, v_num=11]\n",
      "Epoch 0:  91%|█████████ | 250/274 [03:45<00:21,  1.11it/s, v_num=11]\n",
      "Epoch 0:  91%|█████████ | 250/274 [03:45<00:21,  1.11it/s, v_num=11]\n",
      "Epoch 0:  92%|█████████▏| 251/274 [03:46<00:20,  1.11it/s, v_num=11]\n",
      "Epoch 0:  92%|█████████▏| 251/274 [03:46<00:20,  1.11it/s, v_num=11]\n",
      "Epoch 0:  92%|█████████▏| 252/274 [03:47<00:19,  1.11it/s, v_num=11]\n",
      "Epoch 0:  92%|█████████▏| 252/274 [03:47<00:19,  1.11it/s, v_num=11]\n",
      "Epoch 0:  92%|█████████▏| 253/274 [03:48<00:18,  1.11it/s, v_num=11]\n",
      "Epoch 0:  92%|█████████▏| 253/274 [03:48<00:18,  1.11it/s, v_num=11]\n",
      "Epoch 0:  93%|█████████▎| 254/274 [03:49<00:18,  1.11it/s, v_num=11]\n",
      "Epoch 0:  93%|█████████▎| 254/274 [03:49<00:18,  1.11it/s, v_num=11]\n",
      "Epoch 0:  93%|█████████▎| 255/274 [03:50<00:17,  1.11it/s, v_num=11]\n",
      "Epoch 0:  93%|█████████▎| 255/274 [03:50<00:17,  1.11it/s, v_num=11]\n",
      "Epoch 0:  93%|█████████▎| 256/274 [03:50<00:16,  1.11it/s, v_num=11]\n",
      "Epoch 0:  93%|█████████▎| 256/274 [03:50<00:16,  1.11it/s, v_num=11]\n",
      "Epoch 0:  94%|█████████▍| 257/274 [03:51<00:15,  1.11it/s, v_num=11]\n",
      "Epoch 0:  94%|█████████▍| 257/274 [03:51<00:15,  1.11it/s, v_num=11]\n",
      "Epoch 0:  94%|█████████▍| 258/274 [03:52<00:14,  1.11it/s, v_num=11]\n",
      "Epoch 0:  94%|█████████▍| 258/274 [03:52<00:14,  1.11it/s, v_num=11]\n",
      "Epoch 0:  95%|█████████▍| 259/274 [03:53<00:13,  1.11it/s, v_num=11]\n",
      "Epoch 0:  95%|█████████▍| 259/274 [03:53<00:13,  1.11it/s, v_num=11]\n",
      "Epoch 0:  95%|█████████▍| 260/274 [03:54<00:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  95%|█████████▍| 260/274 [03:54<00:12,  1.11it/s, v_num=11]\n",
      "Epoch 0:  95%|█████████▌| 261/274 [03:55<00:11,  1.11it/s, v_num=11]\n",
      "Epoch 0:  95%|█████████▌| 261/274 [03:55<00:11,  1.11it/s, v_num=11]\n",
      "Epoch 0:  96%|█████████▌| 262/274 [03:56<00:10,  1.11it/s, v_num=11]\n",
      "Epoch 0:  96%|█████████▌| 262/274 [03:56<00:10,  1.11it/s, v_num=11]\n",
      "Epoch 0:  96%|█████████▌| 263/274 [03:57<00:09,  1.11it/s, v_num=11]\n",
      "Epoch 0:  96%|█████████▌| 263/274 [03:57<00:09,  1.11it/s, v_num=11]\n",
      "Epoch 0:  96%|█████████▋| 264/274 [03:58<00:09,  1.11it/s, v_num=11]\n",
      "Epoch 0:  96%|█████████▋| 264/274 [03:58<00:09,  1.11it/s, v_num=11]\n",
      "Epoch 0:  97%|█████████▋| 265/274 [03:59<00:08,  1.11it/s, v_num=11]\n",
      "Epoch 0:  97%|█████████▋| 265/274 [03:59<00:08,  1.11it/s, v_num=11]\n",
      "Epoch 0:  97%|█████████▋| 266/274 [04:00<00:07,  1.11it/s, v_num=11]\n",
      "Epoch 0:  97%|█████████▋| 266/274 [04:00<00:07,  1.11it/s, v_num=11]\n",
      "Epoch 0:  97%|█████████▋| 267/274 [04:00<00:06,  1.11it/s, v_num=11]\n",
      "Epoch 0:  97%|█████████▋| 267/274 [04:00<00:06,  1.11it/s, v_num=11]\n",
      "Epoch 0:  98%|█████████▊| 268/274 [04:01<00:05,  1.11it/s, v_num=11]\n",
      "Epoch 0:  98%|█████████▊| 268/274 [04:01<00:05,  1.11it/s, v_num=11]\n",
      "Epoch 0:  98%|█████████▊| 269/274 [04:02<00:04,  1.11it/s, v_num=11]\n",
      "Epoch 0:  98%|█████████▊| 269/274 [04:02<00:04,  1.11it/s, v_num=11]\n",
      "Epoch 0:  99%|█████████▊| 270/274 [04:03<00:03,  1.11it/s, v_num=11]\n",
      "Epoch 0:  99%|█████████▊| 270/274 [04:03<00:03,  1.11it/s, v_num=11]\n",
      "Epoch 0:  99%|█████████▉| 271/274 [04:04<00:02,  1.11it/s, v_num=11]\n",
      "Epoch 0:  99%|█████████▉| 271/274 [04:04<00:02,  1.11it/s, v_num=11]\n",
      "Epoch 0:  99%|█████████▉| 272/274 [04:05<00:01,  1.11it/s, v_num=11]\n",
      "Epoch 0:  99%|█████████▉| 272/274 [04:05<00:01,  1.11it/s, v_num=11]\n",
      "Epoch 0: 100%|█████████▉| 273/274 [04:06<00:00,  1.11it/s, v_num=11]\n",
      "Epoch 0: 100%|█████████▉| 273/274 [04:06<00:00,  1.11it/s, v_num=11]\n",
      "Epoch 0: 100%|██████████| 274/274 [04:07<00:00,  1.11it/s, v_num=11]\n",
      "Epoch 0: 100%|██████████| 274/274 [04:07<00:00,  1.11it/s, v_num=11]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   2%|▏         | 1/59 [00:00<00:19,  2.93it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   3%|▎         | 2/59 [00:00<00:17,  3.29it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   5%|▌         | 3/59 [00:00<00:16,  3.42it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   7%|▋         | 4/59 [00:01<00:15,  3.49it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   8%|▊         | 5/59 [00:01<00:15,  3.53it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  10%|█         | 6/59 [00:01<00:14,  3.57it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▏        | 7/59 [00:01<00:14,  3.59it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  14%|█▎        | 8/59 [00:02<00:14,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  15%|█▌        | 9/59 [00:02<00:13,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  17%|█▋        | 10/59 [00:02<00:13,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  19%|█▊        | 11/59 [00:03<00:13,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  20%|██        | 12/59 [00:03<00:12,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  22%|██▏       | 13/59 [00:03<00:12,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  24%|██▎       | 14/59 [00:03<00:12,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 15/59 [00:04<00:12,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  27%|██▋       | 16/59 [00:04<00:11,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  29%|██▉       | 17/59 [00:04<00:11,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  31%|███       | 18/59 [00:04<00:11,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  32%|███▏      | 19/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  34%|███▍      | 20/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  36%|███▌      | 21/59 [00:05<00:10,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  37%|███▋      | 22/59 [00:05<00:10,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  39%|███▉      | 23/59 [00:06<00:09,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  41%|████      | 24/59 [00:06<00:09,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  42%|████▏     | 25/59 [00:06<00:09,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  44%|████▍     | 26/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  46%|████▌     | 27/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  47%|████▋     | 28/59 [00:07<00:08,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  49%|████▉     | 29/59 [00:07<00:08,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  51%|█████     | 30/59 [00:08<00:07,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  53%|█████▎    | 31/59 [00:08<00:07,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  54%|█████▍    | 32/59 [00:08<00:07,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  56%|█████▌    | 33/59 [00:08<00:07,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  58%|█████▊    | 34/59 [00:09<00:06,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  59%|█████▉    | 35/59 [00:09<00:06,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  61%|██████    | 36/59 [00:09<00:06,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  63%|██████▎   | 37/59 [00:10<00:05,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  64%|██████▍   | 38/59 [00:10<00:05,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  66%|██████▌   | 39/59 [00:10<00:05,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  68%|██████▊   | 40/59 [00:10<00:05,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  69%|██████▉   | 41/59 [00:11<00:04,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  71%|███████   | 42/59 [00:11<00:04,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  73%|███████▎  | 43/59 [00:11<00:04,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▍  | 44/59 [00:11<00:04,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  76%|███████▋  | 45/59 [00:12<00:03,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  78%|███████▊  | 46/59 [00:12<00:03,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  80%|███████▉  | 47/59 [00:12<00:03,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  81%|████████▏ | 48/59 [00:13<00:02,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  83%|████████▎ | 49/59 [00:13<00:02,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  85%|████████▍ | 50/59 [00:13<00:02,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  86%|████████▋ | 51/59 [00:13<00:02,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 52/59 [00:14<00:01,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  90%|████████▉ | 53/59 [00:14<00:01,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  92%|█████████▏| 54/59 [00:14<00:01,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  93%|█████████▎| 55/59 [00:14<00:01,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  95%|█████████▍| 56/59 [00:15<00:00,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  97%|█████████▋| 57/59 [00:15<00:00,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  98%|█████████▊| 58/59 [00:15<00:00,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 59/59 [00:15<00:00,  3.72it/s]\u001b[A\n",
      "\n",
      "                                                                        \u001b[A\n",
      "Epoch 0: 100%|██████████| 274/274 [04:23<00:00,  1.04it/s, v_num=11, val/loss=0.334, val/accuracy=0.888]\n",
      "Epoch 0: 100%|██████████| 274/274 [04:23<00:00,  1.04it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614][rank: 0] Metric val/loss improved. New best score: 0.334\n",
      "[rank: 1] Metric val/loss improved. New best score: 0.334\n",
      "[rank: 2] Metric val/loss improved. New best score: 0.334\n",
      "[rank: 3] Metric val/loss improved. New best score: 0.334\n",
      "Epoch 0, global step 274: 'val/loss' reached 0.33439 (best 0.33439), saving model to '/home/eaguayo/workspace/DeepLearning/Week3/bert-classifier/sentiment_checkpoints/best-checkpoint-epoch=00-val/loss=0.33.ckpt' as top 1\n",
      "\n",
      "Epoch 0:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   0%|          | 1/274 [00:00<02:37,  1.73it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   0%|          | 1/274 [00:00<02:38,  1.73it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   1%|          | 2/274 [00:01<03:21,  1.35it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   1%|          | 2/274 [00:01<03:21,  1.35it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   1%|          | 3/274 [00:02<03:35,  1.26it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   1%|          | 3/274 [00:02<03:35,  1.26it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   1%|▏         | 4/274 [00:03<03:42,  1.22it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   1%|▏         | 4/274 [00:03<03:42,  1.22it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   2%|▏         | 5/274 [00:04<03:45,  1.19it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   2%|▏         | 5/274 [00:04<03:45,  1.19it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   2%|▏         | 6/274 [00:05<03:47,  1.18it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   2%|▏         | 6/274 [00:05<03:47,  1.18it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   3%|▎         | 7/274 [00:05<03:48,  1.17it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   3%|▎         | 7/274 [00:05<03:48,  1.17it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   3%|▎         | 8/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   3%|▎         | 8/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   3%|▎         | 9/274 [00:07<03:49,  1.15it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   3%|▎         | 9/274 [00:07<03:49,  1.15it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   4%|▎         | 10/274 [00:08<03:49,  1.15it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   4%|▎         | 10/274 [00:08<03:49,  1.15it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   4%|▍         | 11/274 [00:09<03:49,  1.14it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   4%|▍         | 11/274 [00:09<03:49,  1.14it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   4%|▍         | 12/274 [00:10<03:49,  1.14it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   4%|▍         | 12/274 [00:10<03:49,  1.14it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   5%|▍         | 13/274 [00:11<03:49,  1.14it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   5%|▍         | 13/274 [00:11<03:49,  1.14it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   5%|▌         | 14/274 [00:12<03:49,  1.14it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   5%|▌         | 14/274 [00:12<03:49,  1.14it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   5%|▌         | 15/274 [00:13<03:48,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   5%|▌         | 15/274 [00:13<03:48,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   6%|▌         | 17/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   6%|▌         | 17/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   7%|▋         | 18/274 [00:15<03:46,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   7%|▋         | 18/274 [00:15<03:46,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   7%|▋         | 19/274 [00:16<03:46,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   7%|▋         | 19/274 [00:16<03:46,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   7%|▋         | 20/274 [00:17<03:45,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   7%|▋         | 20/274 [00:17<03:45,  1.13it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   8%|▊         | 21/274 [00:18<03:44,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   8%|▊         | 21/274 [00:18<03:44,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   8%|▊         | 23/274 [00:20<03:43,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   8%|▊         | 23/274 [00:20<03:43,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   9%|▉         | 24/274 [00:21<03:42,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   9%|▉         | 24/274 [00:21<03:42,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  10%|▉         | 27/274 [00:24<03:40,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  10%|▉         | 27/274 [00:24<03:40,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  10%|█         | 28/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  10%|█         | 28/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  11%|█         | 29/274 [00:25<03:38,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  12%|█▏        | 32/274 [00:28<03:36,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  12%|█▏        | 32/274 [00:28<03:36,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  12%|█▏        | 33/274 [00:29<03:35,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  12%|█▏        | 33/274 [00:29<03:35,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  12%|█▏        | 34/274 [00:30<03:34,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  12%|█▏        | 34/274 [00:30<03:34,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  13%|█▎        | 35/274 [00:31<03:34,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  13%|█▎        | 35/274 [00:31<03:34,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  13%|█▎        | 36/274 [00:32<03:33,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  13%|█▎        | 36/274 [00:32<03:33,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  14%|█▎        | 37/274 [00:33<03:32,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  14%|█▎        | 37/274 [00:33<03:32,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  14%|█▍        | 38/274 [00:34<03:31,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  14%|█▍        | 38/274 [00:34<03:31,  1.12it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  14%|█▍        | 39/274 [00:34<03:30,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  14%|█▍        | 39/274 [00:34<03:30,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  15%|█▍        | 40/274 [00:35<03:29,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  15%|█▍        | 40/274 [00:35<03:29,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  16%|█▌        | 43/274 [00:38<03:27,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  16%|█▌        | 43/274 [00:38<03:27,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  16%|█▌        | 44/274 [00:39<03:26,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  16%|█▌        | 44/274 [00:39<03:26,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  16%|█▋        | 45/274 [00:40<03:25,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  16%|█▋        | 45/274 [00:40<03:25,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  17%|█▋        | 46/274 [00:41<03:24,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  17%|█▋        | 46/274 [00:41<03:24,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  17%|█▋        | 47/274 [00:42<03:23,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  17%|█▋        | 47/274 [00:42<03:23,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  18%|█▊        | 50/274 [00:44<03:21,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  18%|█▊        | 50/274 [00:44<03:21,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  19%|█▊        | 51/274 [00:45<03:20,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  19%|█▊        | 51/274 [00:45<03:20,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  19%|█▉        | 52/274 [00:46<03:19,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  19%|█▉        | 52/274 [00:46<03:19,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  19%|█▉        | 53/274 [00:47<03:18,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  19%|█▉        | 53/274 [00:47<03:18,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  20%|█▉        | 54/274 [00:48<03:17,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  20%|█▉        | 54/274 [00:48<03:17,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  20%|██        | 55/274 [00:49<03:16,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  20%|██        | 55/274 [00:49<03:16,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  22%|██▏       | 59/274 [00:53<03:13,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  22%|██▏       | 59/274 [00:53<03:13,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  22%|██▏       | 60/274 [00:53<03:12,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  22%|██▏       | 60/274 [00:53<03:12,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  22%|██▏       | 61/274 [00:54<03:11,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  22%|██▏       | 61/274 [00:54<03:11,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  23%|██▎       | 62/274 [00:55<03:10,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  23%|██▎       | 62/274 [00:55<03:10,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  23%|██▎       | 63/274 [00:56<03:09,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  23%|██▎       | 63/274 [00:56<03:09,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  25%|██▍       | 68/274 [01:01<03:05,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  25%|██▍       | 68/274 [01:01<03:05,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  25%|██▌       | 69/274 [01:02<03:04,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  25%|██▌       | 69/274 [01:02<03:04,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  26%|██▌       | 70/274 [01:03<03:03,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  26%|██▌       | 70/274 [01:03<03:03,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  26%|██▌       | 71/274 [01:03<03:02,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  26%|██▌       | 71/274 [01:03<03:02,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  26%|██▋       | 72/274 [01:04<03:01,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  26%|██▋       | 72/274 [01:04<03:01,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  28%|██▊       | 77/274 [01:09<02:57,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  28%|██▊       | 77/274 [01:09<02:57,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  28%|██▊       | 78/274 [01:10<02:56,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  28%|██▊       | 78/274 [01:10<02:56,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  29%|██▉       | 79/274 [01:11<02:55,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  29%|██▉       | 79/274 [01:11<02:55,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  29%|██▉       | 80/274 [01:12<02:54,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  29%|██▉       | 80/274 [01:12<02:54,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  30%|██▉       | 81/274 [01:12<02:53,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  30%|██▉       | 81/274 [01:12<02:53,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  30%|██▉       | 82/274 [01:13<02:53,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  30%|██▉       | 82/274 [01:13<02:53,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  30%|███       | 83/274 [01:14<02:52,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  30%|███       | 83/274 [01:14<02:52,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  32%|███▏      | 87/274 [01:18<02:48,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  32%|███▏      | 87/274 [01:18<02:48,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  32%|███▏      | 88/274 [01:19<02:47,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  32%|███▏      | 88/274 [01:19<02:47,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  32%|███▏      | 89/274 [01:20<02:46,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  32%|███▏      | 89/274 [01:20<02:46,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  33%|███▎      | 90/274 [01:21<02:45,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  33%|███▎      | 90/274 [01:21<02:45,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  33%|███▎      | 91/274 [01:22<02:44,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  33%|███▎      | 91/274 [01:22<02:44,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  34%|███▎      | 92/274 [01:22<02:44,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  34%|███▎      | 92/274 [01:22<02:44,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  34%|███▍      | 93/274 [01:23<02:43,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  34%|███▍      | 93/274 [01:23<02:43,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  34%|███▍      | 94/274 [01:24<02:42,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  34%|███▍      | 94/274 [01:24<02:42,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  35%|███▌      | 96/274 [01:26<02:40,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  35%|███▌      | 96/274 [01:26<02:40,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  35%|███▌      | 97/274 [01:27<02:39,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  35%|███▌      | 97/274 [01:27<02:39,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  36%|███▌      | 98/274 [01:28<02:38,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  36%|███▌      | 98/274 [01:28<02:38,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  36%|███▌      | 99/274 [01:29<02:37,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  36%|███▌      | 99/274 [01:29<02:37,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  36%|███▋      | 100/274 [01:30<02:36,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  36%|███▋      | 100/274 [01:30<02:36,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  38%|███▊      | 103/274 [01:32<02:34,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  38%|███▊      | 103/274 [01:32<02:34,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  38%|███▊      | 104/274 [01:33<02:33,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  38%|███▊      | 104/274 [01:33<02:33,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  39%|███▊      | 106/274 [01:35<02:31,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  39%|███▊      | 106/274 [01:35<02:31,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  39%|███▉      | 107/274 [01:36<02:30,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  39%|███▉      | 107/274 [01:36<02:30,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  39%|███▉      | 108/274 [01:37<02:29,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  39%|███▉      | 108/274 [01:37<02:29,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  40%|███▉      | 109/274 [01:38<02:28,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  40%|███▉      | 109/274 [01:38<02:28,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  40%|████      | 110/274 [01:39<02:28,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  40%|████      | 110/274 [01:39<02:28,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  41%|████      | 111/274 [01:40<02:27,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  41%|████      | 111/274 [01:40<02:27,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  41%|████      | 112/274 [01:41<02:26,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  41%|████      | 112/274 [01:41<02:26,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  41%|████      | 113/274 [01:41<02:25,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  41%|████      | 113/274 [01:41<02:25,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  42%|████▏     | 114/274 [01:42<02:24,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  42%|████▏     | 114/274 [01:42<02:24,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  42%|████▏     | 115/274 [01:43<02:23,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  42%|████▏     | 115/274 [01:43<02:23,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  42%|████▏     | 116/274 [01:44<02:22,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  42%|████▏     | 116/274 [01:44<02:22,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  43%|████▎     | 117/274 [01:45<02:21,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  43%|████▎     | 117/274 [01:45<02:21,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  43%|████▎     | 118/274 [01:46<02:20,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  43%|████▎     | 118/274 [01:46<02:20,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  43%|████▎     | 119/274 [01:47<02:19,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  43%|████▎     | 119/274 [01:47<02:19,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  44%|████▍     | 120/274 [01:48<02:19,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  44%|████▍     | 120/274 [01:48<02:19,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  44%|████▍     | 121/274 [01:49<02:18,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  44%|████▍     | 121/274 [01:49<02:18,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  45%|████▍     | 122/274 [01:50<02:17,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  45%|████▍     | 122/274 [01:50<02:17,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  45%|████▍     | 123/274 [01:51<02:16,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  45%|████▍     | 123/274 [01:51<02:16,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  45%|████▌     | 124/274 [01:51<02:15,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  45%|████▌     | 124/274 [01:51<02:15,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  46%|████▌     | 125/274 [01:52<02:14,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  46%|████▌     | 125/274 [01:52<02:14,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  46%|████▌     | 126/274 [01:53<02:13,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  46%|████▌     | 126/274 [01:53<02:13,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  46%|████▋     | 127/274 [01:54<02:12,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  46%|████▋     | 127/274 [01:54<02:12,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  47%|████▋     | 128/274 [01:55<02:11,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  47%|████▋     | 128/274 [01:55<02:11,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  47%|████▋     | 129/274 [01:56<02:10,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  47%|████▋     | 129/274 [01:56<02:10,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  47%|████▋     | 130/274 [01:57<02:10,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  47%|████▋     | 130/274 [01:57<02:10,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  48%|████▊     | 131/274 [01:58<02:09,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  48%|████▊     | 131/274 [01:58<02:09,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  48%|████▊     | 132/274 [01:59<02:08,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  48%|████▊     | 132/274 [01:59<02:08,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  49%|████▊     | 133/274 [02:00<02:07,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  49%|████▊     | 133/274 [02:00<02:07,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  49%|████▉     | 134/274 [02:01<02:06,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  49%|████▉     | 134/274 [02:01<02:06,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  49%|████▉     | 135/274 [02:01<02:05,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  49%|████▉     | 135/274 [02:01<02:05,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  50%|████▉     | 136/274 [02:02<02:04,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  50%|████▉     | 136/274 [02:02<02:04,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  50%|█████     | 137/274 [02:03<02:03,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  50%|█████     | 137/274 [02:03<02:03,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  50%|█████     | 138/274 [02:04<02:02,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  50%|█████     | 138/274 [02:04<02:02,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  51%|█████     | 139/274 [02:05<02:01,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  51%|█████     | 139/274 [02:05<02:01,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  51%|█████     | 140/274 [02:06<02:01,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  51%|█████     | 140/274 [02:06<02:01,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  51%|█████▏    | 141/274 [02:07<02:00,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  51%|█████▏    | 141/274 [02:07<02:00,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  52%|█████▏    | 142/274 [02:08<01:59,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  52%|█████▏    | 142/274 [02:08<01:59,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  52%|█████▏    | 143/274 [02:09<01:58,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  52%|█████▏    | 143/274 [02:09<01:58,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  53%|█████▎    | 144/274 [02:10<01:57,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  53%|█████▎    | 144/274 [02:10<01:57,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  53%|█████▎    | 145/274 [02:10<01:56,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  53%|█████▎    | 145/274 [02:10<01:56,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  53%|█████▎    | 146/274 [02:11<01:55,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  53%|█████▎    | 146/274 [02:11<01:55,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  54%|█████▎    | 147/274 [02:12<01:54,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  54%|█████▎    | 147/274 [02:12<01:54,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  54%|█████▍    | 148/274 [02:13<01:53,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  54%|█████▍    | 148/274 [02:13<01:53,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  54%|█████▍    | 149/274 [02:14<01:52,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  54%|█████▍    | 149/274 [02:14<01:52,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  55%|█████▍    | 150/274 [02:15<01:52,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  55%|█████▍    | 150/274 [02:15<01:52,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  55%|█████▌    | 151/274 [02:16<01:51,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  55%|█████▌    | 151/274 [02:16<01:51,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  55%|█████▌    | 152/274 [02:17<01:50,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  55%|█████▌    | 152/274 [02:17<01:50,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  56%|█████▌    | 153/274 [02:18<01:49,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  56%|█████▌    | 153/274 [02:18<01:49,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  56%|█████▌    | 154/274 [02:19<01:48,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  56%|█████▌    | 154/274 [02:19<01:48,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  57%|█████▋    | 155/274 [02:20<01:47,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  57%|█████▋    | 155/274 [02:20<01:47,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  57%|█████▋    | 156/274 [02:20<01:46,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  57%|█████▋    | 156/274 [02:20<01:46,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  57%|█████▋    | 157/274 [02:21<01:45,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  57%|█████▋    | 157/274 [02:21<01:45,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  58%|█████▊    | 158/274 [02:22<01:44,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  58%|█████▊    | 158/274 [02:22<01:44,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  58%|█████▊    | 159/274 [02:23<01:43,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  58%|█████▊    | 159/274 [02:23<01:43,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  58%|█████▊    | 160/274 [02:24<01:43,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  58%|█████▊    | 160/274 [02:24<01:43,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  59%|█████▉    | 161/274 [02:25<01:42,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  59%|█████▉    | 161/274 [02:25<01:42,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  59%|█████▉    | 162/274 [02:26<01:41,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  59%|█████▉    | 162/274 [02:26<01:41,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  59%|█████▉    | 163/274 [02:27<01:40,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  59%|█████▉    | 163/274 [02:27<01:40,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  60%|█████▉    | 164/274 [02:28<01:39,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  60%|█████▉    | 164/274 [02:28<01:39,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  60%|██████    | 165/274 [02:29<01:38,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  60%|██████    | 165/274 [02:29<01:38,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  61%|██████    | 166/274 [02:30<01:37,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  61%|██████    | 166/274 [02:30<01:37,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  61%|██████    | 167/274 [02:30<01:36,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  61%|██████    | 167/274 [02:30<01:36,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  61%|██████▏   | 168/274 [02:31<01:35,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  61%|██████▏   | 168/274 [02:31<01:35,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  62%|██████▏   | 169/274 [02:32<01:34,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  62%|██████▏   | 169/274 [02:32<01:34,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  62%|██████▏   | 170/274 [02:33<01:34,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  62%|██████▏   | 170/274 [02:33<01:34,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  62%|██████▏   | 171/274 [02:34<01:33,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  62%|██████▏   | 171/274 [02:34<01:33,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  63%|██████▎   | 172/274 [02:35<01:32,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  63%|██████▎   | 172/274 [02:35<01:32,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  63%|██████▎   | 173/274 [02:36<01:31,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  63%|██████▎   | 173/274 [02:36<01:31,  1.11it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  65%|██████▍   | 178/274 [02:41<01:27,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  65%|██████▍   | 178/274 [02:41<01:27,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  66%|██████▌   | 181/274 [02:44<01:24,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  66%|██████▌   | 181/274 [02:44<01:24,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  66%|██████▋   | 182/274 [02:44<01:23,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  66%|██████▋   | 182/274 [02:44<01:23,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  67%|██████▋   | 183/274 [02:45<01:22,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  67%|██████▋   | 183/274 [02:45<01:22,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  69%|██████▊   | 188/274 [02:50<01:17,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  69%|██████▊   | 188/274 [02:50<01:17,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  70%|███████   | 192/274 [02:54<01:14,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  70%|███████   | 192/274 [02:54<01:14,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  70%|███████   | 193/274 [02:54<01:13,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  70%|███████   | 193/274 [02:54<01:13,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  71%|███████   | 194/274 [02:55<01:12,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  71%|███████   | 194/274 [02:55<01:12,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  73%|███████▎  | 199/274 [03:00<01:07,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  73%|███████▎  | 199/274 [03:00<01:07,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  74%|███████▍  | 204/274 [03:04<01:03,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  74%|███████▍  | 204/274 [03:04<01:03,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  75%|███████▍  | 205/274 [03:05<01:02,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  75%|███████▍  | 205/274 [03:05<01:02,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  78%|███████▊  | 215/274 [03:14<00:53,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  78%|███████▊  | 215/274 [03:14<00:53,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  79%|███████▉  | 216/274 [03:15<00:52,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  79%|███████▉  | 216/274 [03:15<00:52,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  80%|████████  | 220/274 [03:19<00:48,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  80%|████████  | 220/274 [03:19<00:48,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  82%|████████▏ | 225/274 [03:23<00:44,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  82%|████████▏ | 225/274 [03:23<00:44,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  84%|████████▍ | 231/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  84%|████████▍ | 231/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  86%|████████▌ | 236/274 [03:33<00:34,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  86%|████████▌ | 236/274 [03:33<00:34,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  90%|█████████ | 247/274 [03:43<00:24,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  90%|█████████ | 247/274 [03:43<00:24,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  94%|█████████▍| 258/274 [03:53<00:14,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  94%|█████████▍| 258/274 [03:53<00:14,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  95%|█████████▍| 259/274 [03:54<00:13,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  95%|█████████▍| 259/274 [03:54<00:13,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  98%|█████████▊| 269/274 [04:03<00:04,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  98%|█████████▊| 269/274 [04:03<00:04,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  99%|█████████▊| 270/274 [04:04<00:03,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  99%|█████████▊| 270/274 [04:04<00:03,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "Epoch 1: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.334, val/accuracy=0.888, train/loss=0.614]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   2%|▏         | 1/59 [00:00<00:20,  2.77it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   3%|▎         | 2/59 [00:00<00:17,  3.18it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   5%|▌         | 3/59 [00:00<00:16,  3.34it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   7%|▋         | 4/59 [00:01<00:16,  3.43it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   8%|▊         | 5/59 [00:01<00:15,  3.48it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  10%|█         | 6/59 [00:01<00:15,  3.52it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▏        | 7/59 [00:01<00:14,  3.54it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  14%|█▎        | 8/59 [00:02<00:14,  3.56it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  15%|█▌        | 9/59 [00:02<00:13,  3.58it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  17%|█▋        | 10/59 [00:02<00:13,  3.59it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  19%|█▊        | 11/59 [00:03<00:13,  3.60it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  20%|██        | 12/59 [00:03<00:13,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  22%|██▏       | 13/59 [00:03<00:12,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  24%|██▎       | 14/59 [00:03<00:12,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 15/59 [00:04<00:12,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  27%|██▋       | 16/59 [00:04<00:11,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  29%|██▉       | 17/59 [00:04<00:11,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  31%|███       | 18/59 [00:04<00:11,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  32%|███▏      | 19/59 [00:05<00:10,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  34%|███▍      | 20/59 [00:05<00:10,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  36%|███▌      | 21/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  37%|███▋      | 22/59 [00:06<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  39%|███▉      | 23/59 [00:06<00:09,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  41%|████      | 24/59 [00:06<00:09,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  42%|████▏     | 25/59 [00:06<00:09,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  44%|████▍     | 26/59 [00:07<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  46%|████▌     | 27/59 [00:07<00:08,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  47%|████▋     | 28/59 [00:07<00:08,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  49%|████▉     | 29/59 [00:07<00:08,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  51%|█████     | 30/59 [00:08<00:07,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  53%|█████▎    | 31/59 [00:08<00:07,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  54%|█████▍    | 32/59 [00:08<00:07,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  56%|█████▌    | 33/59 [00:09<00:07,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  58%|█████▊    | 34/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  59%|█████▉    | 35/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  61%|██████    | 36/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  63%|██████▎   | 37/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  64%|██████▍   | 38/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  66%|██████▌   | 39/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  68%|██████▊   | 40/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  69%|██████▉   | 41/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  71%|███████   | 42/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  73%|███████▎  | 43/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▍  | 44/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  76%|███████▋  | 45/59 [00:12<00:03,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  78%|███████▊  | 46/59 [00:12<00:03,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  80%|███████▉  | 47/59 [00:12<00:03,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  81%|████████▏ | 48/59 [00:13<00:02,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  83%|████████▎ | 49/59 [00:13<00:02,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  85%|████████▍ | 50/59 [00:13<00:02,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  86%|████████▋ | 51/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 52/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  90%|████████▉ | 53/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  92%|█████████▏| 54/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  93%|█████████▎| 55/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  95%|█████████▍| 56/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  97%|█████████▋| 57/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  98%|█████████▊| 58/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 59/59 [00:15<00:00,  3.70it/s]\u001b[A\n",
      "\n",
      "                                                                        \u001b[A\n",
      "Epoch 1: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.614]\n",
      "Epoch 1: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245][rank: 1] Metric val/loss improved by 0.116 >= min_delta = 0.0. New best score: 0.219\n",
      "[rank: 2] Metric val/loss improved by 0.116 >= min_delta = 0.0. New best score: 0.219\n",
      "[rank: 0] Metric val/loss improved by 0.116 >= min_delta = 0.0. New best score: 0.219\n",
      "[rank: 3] Metric val/loss improved by 0.116 >= min_delta = 0.0. New best score: 0.219\n",
      "Epoch 1, global step 548: 'val/loss' reached 0.21850 (best 0.21850), saving model to '/home/eaguayo/workspace/DeepLearning/Week3/bert-classifier/sentiment_checkpoints/best-checkpoint-epoch=01-val/loss=0.22.ckpt' as top 1\n",
      "\n",
      "Epoch 1:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   0%|          | 1/274 [00:00<02:40,  1.71it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   0%|          | 1/274 [00:00<02:40,  1.70it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   1%|          | 2/274 [00:01<03:21,  1.35it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   1%|          | 2/274 [00:01<03:21,  1.35it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   1%|          | 3/274 [00:02<03:36,  1.25it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   1%|          | 3/274 [00:02<03:36,  1.25it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   1%|▏         | 4/274 [00:03<03:42,  1.21it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   1%|▏         | 4/274 [00:03<03:42,  1.21it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   2%|▏         | 5/274 [00:04<03:46,  1.19it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   2%|▏         | 5/274 [00:04<03:46,  1.19it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   2%|▏         | 6/274 [00:05<03:47,  1.18it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   2%|▏         | 6/274 [00:05<03:47,  1.18it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   3%|▎         | 8/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   3%|▎         | 8/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   4%|▎         | 10/274 [00:08<03:50,  1.15it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   4%|▎         | 10/274 [00:08<03:50,  1.15it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   4%|▍         | 12/274 [00:10<03:50,  1.14it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   4%|▍         | 12/274 [00:10<03:50,  1.14it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   5%|▍         | 13/274 [00:11<03:49,  1.14it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   5%|▍         | 13/274 [00:11<03:49,  1.14it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   5%|▌         | 14/274 [00:12<03:49,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   5%|▌         | 14/274 [00:12<03:49,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   5%|▌         | 15/274 [00:13<03:48,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   5%|▌         | 15/274 [00:13<03:48,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   6%|▌         | 17/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   6%|▌         | 17/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   7%|▋         | 18/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   7%|▋         | 18/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   7%|▋         | 19/274 [00:16<03:46,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   7%|▋         | 19/274 [00:16<03:46,  1.13it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   7%|▋         | 20/274 [00:17<03:45,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   7%|▋         | 20/274 [00:17<03:45,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   8%|▊         | 23/274 [00:20<03:43,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   8%|▊         | 23/274 [00:20<03:43,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   9%|▉         | 24/274 [00:21<03:43,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   9%|▉         | 24/274 [00:21<03:43,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  10%|▉         | 27/274 [00:24<03:40,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  10%|▉         | 27/274 [00:24<03:40,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  10%|█         | 28/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  10%|█         | 28/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  12%|█▏        | 32/274 [00:28<03:36,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  12%|█▏        | 32/274 [00:28<03:36,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  12%|█▏        | 33/274 [00:29<03:35,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  12%|█▏        | 33/274 [00:29<03:35,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  12%|█▏        | 34/274 [00:30<03:35,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  12%|█▏        | 34/274 [00:30<03:35,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  13%|█▎        | 35/274 [00:31<03:34,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  13%|█▎        | 35/274 [00:31<03:34,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  13%|█▎        | 36/274 [00:32<03:33,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  13%|█▎        | 36/274 [00:32<03:33,  1.12it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  14%|█▎        | 37/274 [00:33<03:32,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  14%|█▎        | 37/274 [00:33<03:32,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  14%|█▍        | 38/274 [00:34<03:31,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  14%|█▍        | 38/274 [00:34<03:31,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  14%|█▍        | 39/274 [00:34<03:30,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  14%|█▍        | 39/274 [00:34<03:30,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  15%|█▍        | 40/274 [00:35<03:30,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  15%|█▍        | 40/274 [00:35<03:30,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  16%|█▌        | 43/274 [00:38<03:27,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  16%|█▌        | 43/274 [00:38<03:27,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  16%|█▌        | 44/274 [00:39<03:26,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  16%|█▌        | 44/274 [00:39<03:26,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  16%|█▋        | 45/274 [00:40<03:25,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  16%|█▋        | 45/274 [00:40<03:25,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  17%|█▋        | 46/274 [00:41<03:24,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  17%|█▋        | 46/274 [00:41<03:24,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  17%|█▋        | 47/274 [00:42<03:23,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  17%|█▋        | 47/274 [00:42<03:23,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  18%|█▊        | 50/274 [00:44<03:21,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  18%|█▊        | 50/274 [00:44<03:21,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  19%|█▊        | 51/274 [00:45<03:20,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  19%|█▊        | 51/274 [00:45<03:20,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  19%|█▉        | 52/274 [00:46<03:19,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  19%|█▉        | 52/274 [00:46<03:19,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  19%|█▉        | 53/274 [00:47<03:18,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  19%|█▉        | 53/274 [00:47<03:18,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  20%|█▉        | 54/274 [00:48<03:17,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  20%|█▉        | 54/274 [00:48<03:17,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  22%|██▏       | 59/274 [00:53<03:13,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  22%|██▏       | 59/274 [00:53<03:13,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  22%|██▏       | 60/274 [00:54<03:12,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  22%|██▏       | 60/274 [00:54<03:12,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  22%|██▏       | 61/274 [00:54<03:11,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  22%|██▏       | 61/274 [00:54<03:11,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  23%|██▎       | 62/274 [00:55<03:10,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  23%|██▎       | 62/274 [00:55<03:10,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  23%|██▎       | 63/274 [00:56<03:09,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  23%|██▎       | 63/274 [00:56<03:09,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  25%|██▍       | 68/274 [01:01<03:05,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  25%|██▍       | 68/274 [01:01<03:05,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  25%|██▌       | 69/274 [01:02<03:04,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  25%|██▌       | 69/274 [01:02<03:04,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  26%|██▌       | 70/274 [01:03<03:03,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  26%|██▌       | 70/274 [01:03<03:03,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  26%|██▌       | 71/274 [01:03<03:02,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  26%|██▌       | 71/274 [01:03<03:02,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  26%|██▋       | 72/274 [01:04<03:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  26%|██▋       | 72/274 [01:04<03:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  28%|██▊       | 77/274 [01:09<02:57,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  28%|██▊       | 77/274 [01:09<02:57,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  28%|██▊       | 78/274 [01:10<02:56,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  28%|██▊       | 78/274 [01:10<02:56,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  29%|██▉       | 79/274 [01:11<02:55,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  29%|██▉       | 79/274 [01:11<02:55,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  29%|██▉       | 80/274 [01:12<02:54,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  29%|██▉       | 80/274 [01:12<02:54,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  30%|██▉       | 81/274 [01:13<02:53,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  30%|██▉       | 81/274 [01:13<02:53,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  30%|██▉       | 82/274 [01:13<02:53,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  30%|██▉       | 82/274 [01:13<02:53,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  30%|███       | 83/274 [01:14<02:52,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  30%|███       | 83/274 [01:14<02:52,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  32%|███▏      | 87/274 [01:18<02:48,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  32%|███▏      | 87/274 [01:18<02:48,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  32%|███▏      | 88/274 [01:19<02:47,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  32%|███▏      | 88/274 [01:19<02:47,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  32%|███▏      | 89/274 [01:20<02:46,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  32%|███▏      | 89/274 [01:20<02:46,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  33%|███▎      | 90/274 [01:21<02:45,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  33%|███▎      | 90/274 [01:21<02:45,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  34%|███▎      | 92/274 [01:22<02:44,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  34%|███▎      | 92/274 [01:22<02:44,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  34%|███▍      | 93/274 [01:23<02:43,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  34%|███▍      | 93/274 [01:23<02:43,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  34%|███▍      | 94/274 [01:24<02:42,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  34%|███▍      | 94/274 [01:24<02:42,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  35%|███▌      | 96/274 [01:26<02:40,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  35%|███▌      | 96/274 [01:26<02:40,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  35%|███▌      | 97/274 [01:27<02:39,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  35%|███▌      | 97/274 [01:27<02:39,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  36%|███▌      | 98/274 [01:28<02:38,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  36%|███▌      | 98/274 [01:28<02:38,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  36%|███▌      | 99/274 [01:29<02:37,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  36%|███▌      | 99/274 [01:29<02:37,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  36%|███▋      | 100/274 [01:30<02:37,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  36%|███▋      | 100/274 [01:30<02:37,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  38%|███▊      | 103/274 [01:32<02:34,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  38%|███▊      | 103/274 [01:32<02:34,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  38%|███▊      | 104/274 [01:33<02:33,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  38%|███▊      | 104/274 [01:33<02:33,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  39%|███▊      | 106/274 [01:35<02:31,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  39%|███▊      | 106/274 [01:35<02:31,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  39%|███▉      | 107/274 [01:36<02:30,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  39%|███▉      | 107/274 [01:36<02:30,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  39%|███▉      | 108/274 [01:37<02:29,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  39%|███▉      | 108/274 [01:37<02:29,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  40%|███▉      | 109/274 [01:38<02:28,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  40%|███▉      | 109/274 [01:38<02:28,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  40%|████      | 110/274 [01:39<02:28,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  40%|████      | 110/274 [01:39<02:28,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  41%|████      | 111/274 [01:40<02:27,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  41%|████      | 111/274 [01:40<02:27,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  41%|████      | 112/274 [01:41<02:26,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  41%|████      | 112/274 [01:41<02:26,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  41%|████      | 113/274 [01:42<02:25,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  41%|████      | 113/274 [01:42<02:25,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  42%|████▏     | 114/274 [01:42<02:24,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  42%|████▏     | 114/274 [01:42<02:24,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  42%|████▏     | 115/274 [01:43<02:23,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  42%|████▏     | 115/274 [01:43<02:23,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  42%|████▏     | 116/274 [01:44<02:22,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  42%|████▏     | 116/274 [01:44<02:22,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  43%|████▎     | 117/274 [01:45<02:21,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  43%|████▎     | 117/274 [01:45<02:21,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  43%|████▎     | 118/274 [01:46<02:20,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  43%|████▎     | 118/274 [01:46<02:20,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  43%|████▎     | 119/274 [01:47<02:19,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  43%|████▎     | 119/274 [01:47<02:19,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  44%|████▍     | 120/274 [01:48<02:19,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  44%|████▍     | 120/274 [01:48<02:19,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  44%|████▍     | 121/274 [01:49<02:18,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  44%|████▍     | 121/274 [01:49<02:18,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  45%|████▍     | 122/274 [01:50<02:17,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  45%|████▍     | 122/274 [01:50<02:17,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  45%|████▍     | 123/274 [01:51<02:16,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  45%|████▍     | 123/274 [01:51<02:16,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  45%|████▌     | 124/274 [01:52<02:15,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  45%|████▌     | 124/274 [01:52<02:15,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  46%|████▌     | 125/274 [01:52<02:14,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  46%|████▌     | 125/274 [01:52<02:14,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  46%|████▌     | 126/274 [01:53<02:13,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  46%|████▌     | 126/274 [01:53<02:13,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  46%|████▋     | 127/274 [01:54<02:12,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  46%|████▋     | 127/274 [01:54<02:12,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  47%|████▋     | 128/274 [01:55<02:11,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  47%|████▋     | 128/274 [01:55<02:11,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  47%|████▋     | 129/274 [01:56<02:10,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  47%|████▋     | 129/274 [01:56<02:10,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  47%|████▋     | 130/274 [01:57<02:10,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  47%|████▋     | 130/274 [01:57<02:10,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  48%|████▊     | 131/274 [01:58<02:09,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  48%|████▊     | 131/274 [01:58<02:09,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  48%|████▊     | 132/274 [01:59<02:08,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  48%|████▊     | 132/274 [01:59<02:08,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  49%|████▊     | 133/274 [02:00<02:07,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  49%|████▊     | 133/274 [02:00<02:07,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  49%|████▉     | 134/274 [02:01<02:06,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  49%|████▉     | 134/274 [02:01<02:06,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  49%|████▉     | 135/274 [02:01<02:05,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  49%|████▉     | 135/274 [02:01<02:05,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  50%|████▉     | 136/274 [02:02<02:04,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  50%|████▉     | 136/274 [02:02<02:04,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  50%|█████     | 137/274 [02:03<02:03,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  50%|█████     | 137/274 [02:03<02:03,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  50%|█████     | 138/274 [02:04<02:02,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  50%|█████     | 138/274 [02:04<02:02,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  51%|█████     | 139/274 [02:05<02:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  51%|█████     | 139/274 [02:05<02:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  51%|█████     | 140/274 [02:06<02:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  51%|█████     | 140/274 [02:06<02:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  51%|█████▏    | 141/274 [02:07<02:00,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  51%|█████▏    | 141/274 [02:07<02:00,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  52%|█████▏    | 142/274 [02:08<01:59,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  52%|█████▏    | 142/274 [02:08<01:59,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  52%|█████▏    | 143/274 [02:09<01:58,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  52%|█████▏    | 143/274 [02:09<01:58,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  53%|█████▎    | 144/274 [02:10<01:57,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  53%|█████▎    | 144/274 [02:10<01:57,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  53%|█████▎    | 145/274 [02:11<01:56,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  53%|█████▎    | 145/274 [02:11<01:56,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  53%|█████▎    | 146/274 [02:11<01:55,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  53%|█████▎    | 146/274 [02:11<01:55,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  54%|█████▎    | 147/274 [02:12<01:54,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  54%|█████▎    | 147/274 [02:12<01:54,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  54%|█████▍    | 148/274 [02:13<01:53,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  54%|█████▍    | 148/274 [02:13<01:53,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  54%|█████▍    | 149/274 [02:14<01:52,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  54%|█████▍    | 149/274 [02:14<01:52,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  55%|█████▍    | 150/274 [02:15<01:52,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  55%|█████▍    | 150/274 [02:15<01:52,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  55%|█████▌    | 151/274 [02:16<01:51,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  55%|█████▌    | 151/274 [02:16<01:51,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  55%|█████▌    | 152/274 [02:17<01:50,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  55%|█████▌    | 152/274 [02:17<01:50,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  56%|█████▌    | 153/274 [02:18<01:49,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  56%|█████▌    | 153/274 [02:18<01:49,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  56%|█████▌    | 154/274 [02:19<01:48,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  56%|█████▌    | 154/274 [02:19<01:48,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  57%|█████▋    | 155/274 [02:20<01:47,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  57%|█████▋    | 155/274 [02:20<01:47,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  57%|█████▋    | 156/274 [02:21<01:46,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  57%|█████▋    | 156/274 [02:21<01:46,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  57%|█████▋    | 157/274 [02:21<01:45,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  57%|█████▋    | 157/274 [02:21<01:45,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  58%|█████▊    | 158/274 [02:22<01:44,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  58%|█████▊    | 158/274 [02:22<01:44,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  58%|█████▊    | 159/274 [02:23<01:43,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  58%|█████▊    | 159/274 [02:23<01:43,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  58%|█████▊    | 160/274 [02:24<01:43,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  58%|█████▊    | 160/274 [02:24<01:43,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  59%|█████▉    | 161/274 [02:25<01:42,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  59%|█████▉    | 161/274 [02:25<01:42,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  59%|█████▉    | 162/274 [02:26<01:41,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  59%|█████▉    | 162/274 [02:26<01:41,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  59%|█████▉    | 163/274 [02:27<01:40,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  59%|█████▉    | 163/274 [02:27<01:40,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  60%|█████▉    | 164/274 [02:28<01:39,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  60%|█████▉    | 164/274 [02:28<01:39,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  60%|██████    | 165/274 [02:29<01:38,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  60%|██████    | 165/274 [02:29<01:38,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  61%|██████    | 166/274 [02:30<01:37,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  61%|██████    | 166/274 [02:30<01:37,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  61%|██████    | 167/274 [02:30<01:36,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  61%|██████    | 167/274 [02:30<01:36,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  61%|██████▏   | 168/274 [02:31<01:35,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  61%|██████▏   | 168/274 [02:31<01:35,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  62%|██████▏   | 169/274 [02:32<01:34,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  62%|██████▏   | 169/274 [02:32<01:34,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  62%|██████▏   | 170/274 [02:33<01:34,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  62%|██████▏   | 170/274 [02:33<01:34,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  62%|██████▏   | 171/274 [02:34<01:33,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  62%|██████▏   | 171/274 [02:34<01:33,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  63%|██████▎   | 172/274 [02:35<01:32,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  63%|██████▎   | 172/274 [02:35<01:32,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  63%|██████▎   | 173/274 [02:36<01:31,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  63%|██████▎   | 173/274 [02:36<01:31,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  64%|██████▎   | 174/274 [02:37<01:30,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  64%|██████▎   | 174/274 [02:37<01:30,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  64%|██████▍   | 175/274 [02:38<01:29,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  64%|██████▍   | 175/274 [02:38<01:29,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  64%|██████▍   | 176/274 [02:39<01:28,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  64%|██████▍   | 176/274 [02:39<01:28,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  65%|██████▍   | 177/274 [02:40<01:27,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  65%|██████▍   | 177/274 [02:40<01:27,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  65%|██████▍   | 178/274 [02:40<01:26,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  65%|██████▍   | 178/274 [02:40<01:26,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  65%|██████▌   | 179/274 [02:41<01:25,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  65%|██████▌   | 179/274 [02:41<01:25,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  66%|██████▌   | 180/274 [02:42<01:25,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  66%|██████▌   | 180/274 [02:42<01:25,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  66%|██████▌   | 181/274 [02:43<01:24,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  66%|██████▌   | 181/274 [02:43<01:24,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  66%|██████▋   | 182/274 [02:44<01:23,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  66%|██████▋   | 182/274 [02:44<01:23,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  67%|██████▋   | 183/274 [02:45<01:22,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  67%|██████▋   | 183/274 [02:45<01:22,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  67%|██████▋   | 184/274 [02:46<01:21,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  67%|██████▋   | 184/274 [02:46<01:21,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  68%|██████▊   | 185/274 [02:47<01:20,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  68%|██████▊   | 185/274 [02:47<01:20,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  68%|██████▊   | 186/274 [02:48<01:19,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  68%|██████▊   | 186/274 [02:48<01:19,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  68%|██████▊   | 187/274 [02:49<01:18,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  68%|██████▊   | 187/274 [02:49<01:18,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  69%|██████▊   | 188/274 [02:50<01:17,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  69%|██████▊   | 188/274 [02:50<01:17,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  69%|██████▉   | 189/274 [02:50<01:16,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  69%|██████▉   | 189/274 [02:50<01:16,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  69%|██████▉   | 190/274 [02:51<01:15,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  69%|██████▉   | 190/274 [02:51<01:15,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  70%|██████▉   | 191/274 [02:52<01:15,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  70%|██████▉   | 191/274 [02:52<01:15,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  70%|███████   | 192/274 [02:53<01:14,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  70%|███████   | 192/274 [02:53<01:14,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  70%|███████   | 193/274 [02:54<01:13,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  70%|███████   | 193/274 [02:54<01:13,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  71%|███████   | 194/274 [02:55<01:12,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  71%|███████   | 194/274 [02:55<01:12,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  71%|███████   | 195/274 [02:56<01:11,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  71%|███████   | 195/274 [02:56<01:11,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  72%|███████▏  | 196/274 [02:57<01:10,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  72%|███████▏  | 196/274 [02:57<01:10,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  72%|███████▏  | 197/274 [02:58<01:09,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  72%|███████▏  | 197/274 [02:58<01:09,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  72%|███████▏  | 198/274 [02:59<01:08,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  72%|███████▏  | 198/274 [02:59<01:08,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  73%|███████▎  | 199/274 [03:00<01:07,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  73%|███████▎  | 199/274 [03:00<01:07,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  73%|███████▎  | 200/274 [03:00<01:06,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  73%|███████▎  | 200/274 [03:00<01:06,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  73%|███████▎  | 201/274 [03:01<01:06,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  73%|███████▎  | 201/274 [03:01<01:06,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  74%|███████▎  | 202/274 [03:02<01:05,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  74%|███████▎  | 202/274 [03:02<01:05,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  74%|███████▍  | 203/274 [03:03<01:04,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  74%|███████▍  | 203/274 [03:03<01:04,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  74%|███████▍  | 204/274 [03:04<01:03,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  74%|███████▍  | 204/274 [03:04<01:03,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  75%|███████▍  | 205/274 [03:05<01:02,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  75%|███████▍  | 205/274 [03:05<01:02,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  75%|███████▌  | 206/274 [03:06<01:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  75%|███████▌  | 206/274 [03:06<01:01,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  76%|███████▌  | 207/274 [03:07<01:00,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  76%|███████▌  | 207/274 [03:07<01:00,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  76%|███████▌  | 208/274 [03:08<00:59,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  76%|███████▌  | 208/274 [03:08<00:59,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  76%|███████▋  | 209/274 [03:09<00:58,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  76%|███████▋  | 209/274 [03:09<00:58,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  77%|███████▋  | 210/274 [03:10<00:57,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  77%|███████▋  | 210/274 [03:10<00:57,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  77%|███████▋  | 211/274 [03:10<00:57,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  77%|███████▋  | 211/274 [03:10<00:57,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  77%|███████▋  | 212/274 [03:11<00:56,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  77%|███████▋  | 212/274 [03:11<00:56,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  78%|███████▊  | 213/274 [03:12<00:55,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  78%|███████▊  | 213/274 [03:12<00:55,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  78%|███████▊  | 214/274 [03:13<00:54,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  78%|███████▊  | 214/274 [03:13<00:54,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  78%|███████▊  | 215/274 [03:14<00:53,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  78%|███████▊  | 215/274 [03:14<00:53,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  79%|███████▉  | 216/274 [03:15<00:52,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  79%|███████▉  | 216/274 [03:15<00:52,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  79%|███████▉  | 217/274 [03:16<00:51,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  79%|███████▉  | 217/274 [03:16<00:51,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  80%|███████▉  | 218/274 [03:17<00:50,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  80%|███████▉  | 218/274 [03:17<00:50,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  80%|███████▉  | 219/274 [03:18<00:49,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  80%|███████▉  | 219/274 [03:18<00:49,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  80%|████████  | 220/274 [03:19<00:48,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  80%|████████  | 220/274 [03:19<00:48,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  81%|████████  | 221/274 [03:19<00:47,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  81%|████████  | 221/274 [03:19<00:47,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  81%|████████  | 222/274 [03:20<00:47,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  81%|████████  | 222/274 [03:20<00:47,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  81%|████████▏ | 223/274 [03:21<00:46,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  81%|████████▏ | 223/274 [03:21<00:46,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  82%|████████▏ | 224/274 [03:22<00:45,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  82%|████████▏ | 224/274 [03:22<00:45,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  82%|████████▏ | 225/274 [03:23<00:44,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  82%|████████▏ | 225/274 [03:23<00:44,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  84%|████████▍ | 231/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  84%|████████▍ | 231/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  85%|████████▍ | 232/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  85%|████████▍ | 232/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  85%|████████▌ | 233/274 [03:30<00:37,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  85%|████████▌ | 233/274 [03:30<00:37,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  85%|████████▌ | 234/274 [03:31<00:36,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  85%|████████▌ | 234/274 [03:31<00:36,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  86%|████████▌ | 235/274 [03:32<00:35,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  86%|████████▌ | 235/274 [03:32<00:35,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  86%|████████▌ | 236/274 [03:33<00:34,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  86%|████████▌ | 236/274 [03:33<00:34,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  88%|████████▊ | 242/274 [03:39<00:28,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  88%|████████▊ | 242/274 [03:39<00:28,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  89%|████████▊ | 243/274 [03:39<00:28,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  89%|████████▊ | 243/274 [03:39<00:28,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  89%|████████▉ | 244/274 [03:40<00:27,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  89%|████████▉ | 244/274 [03:40<00:27,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  89%|████████▉ | 245/274 [03:41<00:26,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  89%|████████▉ | 245/274 [03:41<00:26,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  90%|████████▉ | 246/274 [03:42<00:25,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  90%|████████▉ | 246/274 [03:42<00:25,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  90%|█████████ | 247/274 [03:43<00:24,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  90%|█████████ | 247/274 [03:43<00:24,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  93%|█████████▎| 254/274 [03:49<00:18,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  93%|█████████▎| 254/274 [03:49<00:18,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  93%|█████████▎| 255/274 [03:50<00:17,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  93%|█████████▎| 255/274 [03:50<00:17,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  93%|█████████▎| 256/274 [03:51<00:16,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  93%|█████████▎| 256/274 [03:51<00:16,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  94%|█████████▍| 257/274 [03:52<00:15,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  94%|█████████▍| 257/274 [03:52<00:15,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  94%|█████████▍| 258/274 [03:53<00:14,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  94%|█████████▍| 258/274 [03:53<00:14,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  95%|█████████▍| 259/274 [03:54<00:13,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  95%|█████████▍| 259/274 [03:54<00:13,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  97%|█████████▋| 265/274 [03:59<00:08,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  97%|█████████▋| 265/274 [03:59<00:08,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  97%|█████████▋| 266/274 [04:00<00:07,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  97%|█████████▋| 266/274 [04:00<00:07,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  97%|█████████▋| 267/274 [04:01<00:06,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  97%|█████████▋| 267/274 [04:01<00:06,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  98%|█████████▊| 268/274 [04:02<00:05,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  98%|█████████▊| 268/274 [04:02<00:05,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  98%|█████████▊| 269/274 [04:03<00:04,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  98%|█████████▊| 269/274 [04:03<00:04,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  99%|█████████▊| 270/274 [04:04<00:03,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  99%|█████████▊| 270/274 [04:04<00:03,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2: 100%|██████████| 274/274 [04:07<00:00,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2: 100%|██████████| 274/274 [04:07<00:00,  1.11it/s, v_num=11, val/loss=0.219, val/accuracy=0.919, train/loss=0.245]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   2%|▏         | 1/59 [00:00<00:20,  2.87it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   3%|▎         | 2/59 [00:00<00:17,  3.24it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   5%|▌         | 3/59 [00:00<00:16,  3.38it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   7%|▋         | 4/59 [00:01<00:15,  3.46it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   8%|▊         | 5/59 [00:01<00:15,  3.50it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  10%|█         | 6/59 [00:01<00:14,  3.53it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▏        | 7/59 [00:01<00:14,  3.56it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  14%|█▎        | 8/59 [00:02<00:14,  3.57it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  15%|█▌        | 9/59 [00:02<00:13,  3.59it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  17%|█▋        | 10/59 [00:02<00:13,  3.60it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  19%|█▊        | 11/59 [00:03<00:13,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  20%|██        | 12/59 [00:03<00:12,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  22%|██▏       | 13/59 [00:03<00:12,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  24%|██▎       | 14/59 [00:03<00:12,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 15/59 [00:04<00:12,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  27%|██▋       | 16/59 [00:04<00:11,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  29%|██▉       | 17/59 [00:04<00:11,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  31%|███       | 18/59 [00:04<00:11,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  32%|███▏      | 19/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  34%|███▍      | 20/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  36%|███▌      | 21/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  37%|███▋      | 22/59 [00:06<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  39%|███▉      | 23/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  41%|████      | 24/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  42%|████▏     | 25/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  44%|████▍     | 26/59 [00:07<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  46%|████▌     | 27/59 [00:07<00:08,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  47%|████▋     | 28/59 [00:07<00:08,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  49%|████▉     | 29/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  51%|█████     | 30/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  53%|█████▎    | 31/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  54%|█████▍    | 32/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  56%|█████▌    | 33/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  58%|█████▊    | 34/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  59%|█████▉    | 35/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  61%|██████    | 36/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  63%|██████▎   | 37/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  64%|██████▍   | 38/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  66%|██████▌   | 39/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  68%|██████▊   | 40/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  69%|██████▉   | 41/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  71%|███████   | 42/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  73%|███████▎  | 43/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▍  | 44/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  76%|███████▋  | 45/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  78%|███████▊  | 46/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  80%|███████▉  | 47/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  81%|████████▏ | 48/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  83%|████████▎ | 49/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  85%|████████▍ | 50/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  86%|████████▋ | 51/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 52/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  90%|████████▉ | 53/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  92%|█████████▏| 54/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  93%|█████████▎| 55/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  95%|█████████▍| 56/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  97%|█████████▋| 57/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  98%|█████████▊| 58/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 59/59 [00:15<00:00,  3.71it/s]\u001b[A\n",
      "\n",
      "                                                                        \u001b[A\n",
      "Epoch 2: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.245]\n",
      "Epoch 2: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]Epoch 2, global step 822: 'val/loss' was not in top 1\n",
      "\n",
      "Epoch 2:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   0%|          | 1/274 [00:00<02:40,  1.70it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   0%|          | 1/274 [00:00<02:40,  1.70it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   1%|          | 2/274 [00:01<03:23,  1.34it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   1%|          | 2/274 [00:01<03:23,  1.34it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   1%|          | 3/274 [00:02<03:36,  1.25it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   1%|          | 3/274 [00:02<03:36,  1.25it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   1%|▏         | 4/274 [00:03<03:43,  1.21it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   1%|▏         | 4/274 [00:03<03:43,  1.21it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   2%|▏         | 5/274 [00:04<03:46,  1.19it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   2%|▏         | 5/274 [00:04<03:46,  1.19it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   2%|▏         | 6/274 [00:05<03:48,  1.17it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   2%|▏         | 6/274 [00:05<03:48,  1.17it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   3%|▎         | 8/274 [00:06<03:50,  1.15it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   3%|▎         | 8/274 [00:06<03:50,  1.15it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   4%|▎         | 10/274 [00:08<03:51,  1.14it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   4%|▎         | 10/274 [00:08<03:51,  1.14it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   4%|▍         | 12/274 [00:10<03:50,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   4%|▍         | 12/274 [00:10<03:50,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   5%|▍         | 13/274 [00:11<03:50,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   5%|▍         | 13/274 [00:11<03:50,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   5%|▌         | 14/274 [00:12<03:50,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   5%|▌         | 14/274 [00:12<03:50,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   5%|▌         | 15/274 [00:13<03:49,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   5%|▌         | 15/274 [00:13<03:49,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   6%|▌         | 16/274 [00:14<03:49,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   6%|▌         | 16/274 [00:14<03:49,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   6%|▌         | 17/274 [00:15<03:48,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   6%|▌         | 17/274 [00:15<03:48,  1.13it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   7%|▋         | 18/274 [00:16<03:47,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   7%|▋         | 18/274 [00:16<03:47,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   7%|▋         | 19/274 [00:16<03:47,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   7%|▋         | 19/274 [00:16<03:47,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   7%|▋         | 20/274 [00:17<03:46,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   7%|▋         | 20/274 [00:17<03:46,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   8%|▊         | 22/274 [00:19<03:45,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   8%|▊         | 22/274 [00:19<03:45,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   8%|▊         | 23/274 [00:20<03:44,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   8%|▊         | 23/274 [00:20<03:44,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   9%|▉         | 24/274 [00:21<03:43,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   9%|▉         | 24/274 [00:21<03:43,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   9%|▉         | 26/274 [00:23<03:42,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:   9%|▉         | 26/274 [00:23<03:42,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  10%|▉         | 27/274 [00:24<03:41,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  10%|▉         | 27/274 [00:24<03:41,  1.12it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  10%|█         | 28/274 [00:25<03:40,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  10%|█         | 28/274 [00:25<03:40,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  11%|█         | 29/274 [00:26<03:39,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  11%|█         | 29/274 [00:26<03:39,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  11%|█         | 30/274 [00:26<03:39,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  11%|█         | 30/274 [00:26<03:39,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  11%|█▏        | 31/274 [00:27<03:38,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  11%|█▏        | 31/274 [00:27<03:38,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  12%|█▏        | 32/274 [00:28<03:37,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  12%|█▏        | 32/274 [00:28<03:37,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  12%|█▏        | 33/274 [00:29<03:36,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  12%|█▏        | 33/274 [00:29<03:36,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  12%|█▏        | 34/274 [00:30<03:35,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  12%|█▏        | 34/274 [00:30<03:35,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  13%|█▎        | 35/274 [00:31<03:34,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  13%|█▎        | 35/274 [00:31<03:34,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  13%|█▎        | 36/274 [00:32<03:34,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  13%|█▎        | 36/274 [00:32<03:34,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  14%|█▎        | 37/274 [00:33<03:33,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  14%|█▎        | 37/274 [00:33<03:33,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  14%|█▍        | 38/274 [00:34<03:32,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  14%|█▍        | 38/274 [00:34<03:32,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  14%|█▍        | 39/274 [00:35<03:31,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  14%|█▍        | 39/274 [00:35<03:31,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  15%|█▍        | 40/274 [00:36<03:30,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  15%|█▍        | 40/274 [00:36<03:30,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  15%|█▌        | 42/274 [00:37<03:29,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  15%|█▌        | 42/274 [00:37<03:29,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  16%|█▌        | 43/274 [00:38<03:28,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  16%|█▌        | 43/274 [00:38<03:28,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  16%|█▌        | 44/274 [00:39<03:27,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  16%|█▌        | 44/274 [00:39<03:27,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  16%|█▋        | 45/274 [00:40<03:26,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  16%|█▋        | 45/274 [00:40<03:26,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  17%|█▋        | 46/274 [00:41<03:25,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  17%|█▋        | 46/274 [00:41<03:25,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  17%|█▋        | 47/274 [00:42<03:24,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  17%|█▋        | 47/274 [00:42<03:24,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  18%|█▊        | 50/274 [00:45<03:22,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  18%|█▊        | 50/274 [00:45<03:22,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  19%|█▊        | 51/274 [00:46<03:21,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  19%|█▊        | 51/274 [00:46<03:21,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  19%|█▉        | 52/274 [00:46<03:20,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  19%|█▉        | 52/274 [00:46<03:20,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  19%|█▉        | 53/274 [00:47<03:19,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  19%|█▉        | 53/274 [00:47<03:19,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  20%|█▉        | 54/274 [00:48<03:18,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  20%|█▉        | 54/274 [00:48<03:18,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  22%|██▏       | 59/274 [00:53<03:14,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  22%|██▏       | 59/274 [00:53<03:14,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  22%|██▏       | 60/274 [00:54<03:13,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  22%|██▏       | 60/274 [00:54<03:13,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  22%|██▏       | 61/274 [00:55<03:12,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  22%|██▏       | 61/274 [00:55<03:12,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  23%|██▎       | 62/274 [00:55<03:11,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  23%|██▎       | 62/274 [00:55<03:11,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  23%|██▎       | 63/274 [00:56<03:10,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  23%|██▎       | 63/274 [00:56<03:10,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  24%|██▍       | 67/274 [01:00<03:07,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  24%|██▍       | 67/274 [01:00<03:07,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  25%|██▍       | 68/274 [01:01<03:06,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  25%|██▍       | 68/274 [01:01<03:06,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  25%|██▌       | 69/274 [01:02<03:05,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  25%|██▌       | 69/274 [01:02<03:05,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  26%|██▌       | 70/274 [01:03<03:04,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  26%|██▌       | 70/274 [01:03<03:04,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  26%|██▌       | 71/274 [01:04<03:03,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  26%|██▌       | 71/274 [01:04<03:03,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  26%|██▋       | 72/274 [01:05<03:02,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  26%|██▋       | 72/274 [01:05<03:02,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  28%|██▊       | 77/274 [01:09<02:58,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  28%|██▊       | 77/274 [01:09<02:58,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  28%|██▊       | 78/274 [01:10<02:57,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  28%|██▊       | 78/274 [01:10<02:57,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  29%|██▉       | 79/274 [01:11<02:56,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  29%|██▉       | 79/274 [01:11<02:56,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  29%|██▉       | 80/274 [01:12<02:55,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  29%|██▉       | 80/274 [01:12<02:55,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  30%|██▉       | 81/274 [01:13<02:54,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  30%|██▉       | 81/274 [01:13<02:54,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  30%|██▉       | 82/274 [01:14<02:53,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  30%|██▉       | 82/274 [01:14<02:53,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  30%|███       | 83/274 [01:15<02:52,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  30%|███       | 83/274 [01:15<02:52,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  31%|███▏      | 86/274 [01:17<02:50,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  31%|███▏      | 86/274 [01:17<02:50,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  32%|███▏      | 87/274 [01:18<02:49,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  32%|███▏      | 87/274 [01:18<02:49,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  32%|███▏      | 88/274 [01:19<02:48,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  32%|███▏      | 88/274 [01:19<02:48,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  32%|███▏      | 89/274 [01:20<02:47,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  32%|███▏      | 89/274 [01:20<02:47,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  33%|███▎      | 90/274 [01:21<02:46,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  33%|███▎      | 90/274 [01:21<02:46,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  34%|███▎      | 92/274 [01:23<02:44,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  34%|███▎      | 92/274 [01:23<02:44,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  34%|███▍      | 93/274 [01:24<02:43,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  34%|███▍      | 93/274 [01:24<02:43,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  34%|███▍      | 94/274 [01:25<02:42,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  34%|███▍      | 94/274 [01:25<02:42,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  35%|███▌      | 96/274 [01:26<02:41,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  35%|███▌      | 96/274 [01:26<02:41,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  35%|███▌      | 97/274 [01:27<02:40,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  35%|███▌      | 97/274 [01:27<02:40,  1.11it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  36%|███▌      | 98/274 [01:28<02:39,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  36%|███▌      | 98/274 [01:28<02:39,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  36%|███▌      | 99/274 [01:29<02:38,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  36%|███▌      | 99/274 [01:29<02:38,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  36%|███▋      | 100/274 [01:30<02:37,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  36%|███▋      | 100/274 [01:30<02:37,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  37%|███▋      | 101/274 [01:31<02:36,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  37%|███▋      | 101/274 [01:31<02:36,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  37%|███▋      | 102/274 [01:32<02:35,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  37%|███▋      | 102/274 [01:32<02:35,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  38%|███▊      | 103/274 [01:33<02:34,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  38%|███▊      | 103/274 [01:33<02:34,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  38%|███▊      | 104/274 [01:34<02:33,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  38%|███▊      | 104/274 [01:34<02:33,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  38%|███▊      | 105/274 [01:35<02:32,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  38%|███▊      | 105/274 [01:35<02:32,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  39%|███▊      | 106/274 [01:35<02:32,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  39%|███▊      | 106/274 [01:35<02:32,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  39%|███▉      | 107/274 [01:36<02:31,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  39%|███▉      | 107/274 [01:36<02:31,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  39%|███▉      | 108/274 [01:37<02:30,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  39%|███▉      | 108/274 [01:37<02:30,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  40%|███▉      | 109/274 [01:38<02:29,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  40%|███▉      | 109/274 [01:38<02:29,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  40%|████      | 110/274 [01:39<02:28,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  40%|████      | 110/274 [01:39<02:28,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  41%|████      | 111/274 [01:40<02:27,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  41%|████      | 111/274 [01:40<02:27,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  41%|████      | 112/274 [01:41<02:26,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  41%|████      | 112/274 [01:41<02:26,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  41%|████      | 113/274 [01:42<02:25,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  41%|████      | 113/274 [01:42<02:25,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  42%|████▏     | 114/274 [01:43<02:24,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  42%|████▏     | 114/274 [01:43<02:24,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  42%|████▏     | 115/274 [01:44<02:24,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  42%|████▏     | 115/274 [01:44<02:24,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  42%|████▏     | 116/274 [01:45<02:23,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  42%|████▏     | 116/274 [01:45<02:23,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  43%|████▎     | 117/274 [01:45<02:22,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  43%|████▎     | 117/274 [01:45<02:22,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  43%|████▎     | 118/274 [01:46<02:21,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  43%|████▎     | 118/274 [01:46<02:21,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  43%|████▎     | 119/274 [01:47<02:20,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  43%|████▎     | 119/274 [01:47<02:20,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  44%|████▍     | 120/274 [01:48<02:19,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  44%|████▍     | 120/274 [01:48<02:19,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  44%|████▍     | 121/274 [01:49<02:18,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  44%|████▍     | 121/274 [01:49<02:18,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  45%|████▍     | 122/274 [01:50<02:17,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  45%|████▍     | 122/274 [01:50<02:17,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  45%|████▍     | 123/274 [01:51<02:16,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  45%|████▍     | 123/274 [01:51<02:16,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  45%|████▌     | 124/274 [01:52<02:15,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  45%|████▌     | 124/274 [01:52<02:15,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  46%|████▌     | 125/274 [01:53<02:14,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  46%|████▌     | 125/274 [01:53<02:14,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  46%|████▌     | 126/274 [01:54<02:14,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  46%|████▌     | 126/274 [01:54<02:14,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  46%|████▋     | 127/274 [01:55<02:13,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  46%|████▋     | 127/274 [01:55<02:13,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  47%|████▋     | 128/274 [01:55<02:12,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  47%|████▋     | 128/274 [01:55<02:12,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  47%|████▋     | 129/274 [01:56<02:11,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  47%|████▋     | 129/274 [01:56<02:11,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  47%|████▋     | 130/274 [01:57<02:10,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  47%|████▋     | 130/274 [01:57<02:10,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  48%|████▊     | 131/274 [01:58<02:09,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  48%|████▊     | 131/274 [01:58<02:09,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  48%|████▊     | 132/274 [01:59<02:08,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  48%|████▊     | 132/274 [01:59<02:08,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  49%|████▊     | 133/274 [02:00<02:07,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  49%|████▊     | 133/274 [02:00<02:07,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  49%|████▉     | 134/274 [02:01<02:06,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  49%|████▉     | 134/274 [02:01<02:06,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  49%|████▉     | 135/274 [02:02<02:05,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  49%|████▉     | 135/274 [02:02<02:05,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  50%|████▉     | 136/274 [02:03<02:05,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  50%|████▉     | 136/274 [02:03<02:05,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  50%|█████     | 137/274 [02:04<02:04,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  50%|█████     | 137/274 [02:04<02:04,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  50%|█████     | 138/274 [02:05<02:03,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  50%|█████     | 138/274 [02:05<02:03,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  51%|█████     | 139/274 [02:05<02:02,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  51%|█████     | 139/274 [02:05<02:02,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  51%|█████     | 140/274 [02:06<02:01,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  51%|█████     | 140/274 [02:06<02:01,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  51%|█████▏    | 141/274 [02:07<02:00,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  51%|█████▏    | 141/274 [02:07<02:00,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  52%|█████▏    | 142/274 [02:08<01:59,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  52%|█████▏    | 142/274 [02:08<01:59,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  52%|█████▏    | 143/274 [02:09<01:58,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  52%|█████▏    | 143/274 [02:09<01:58,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  53%|█████▎    | 144/274 [02:10<01:57,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  53%|█████▎    | 144/274 [02:10<01:57,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  53%|█████▎    | 145/274 [02:11<01:56,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  53%|█████▎    | 145/274 [02:11<01:56,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  53%|█████▎    | 146/274 [02:12<01:56,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  53%|█████▎    | 146/274 [02:12<01:56,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  54%|█████▎    | 147/274 [02:13<01:55,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  54%|█████▎    | 147/274 [02:13<01:55,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  54%|█████▍    | 148/274 [02:14<01:54,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  54%|█████▍    | 148/274 [02:14<01:54,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  54%|█████▍    | 149/274 [02:15<01:53,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  54%|█████▍    | 149/274 [02:15<01:53,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  55%|█████▍    | 150/274 [02:15<01:52,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  55%|█████▍    | 150/274 [02:15<01:52,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  55%|█████▌    | 151/274 [02:16<01:51,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  55%|█████▌    | 151/274 [02:16<01:51,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  55%|█████▌    | 152/274 [02:17<01:50,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  55%|█████▌    | 152/274 [02:17<01:50,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  56%|█████▌    | 153/274 [02:18<01:49,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  56%|█████▌    | 153/274 [02:18<01:49,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  56%|█████▌    | 154/274 [02:19<01:48,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  56%|█████▌    | 154/274 [02:19<01:48,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  57%|█████▋    | 155/274 [02:20<01:47,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  57%|█████▋    | 155/274 [02:20<01:47,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  57%|█████▋    | 156/274 [02:21<01:46,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  57%|█████▋    | 156/274 [02:21<01:46,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  57%|█████▋    | 157/274 [02:22<01:46,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  57%|█████▋    | 157/274 [02:22<01:46,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  58%|█████▊    | 158/274 [02:23<01:45,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  58%|█████▊    | 158/274 [02:23<01:45,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  58%|█████▊    | 159/274 [02:24<01:44,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  58%|█████▊    | 159/274 [02:24<01:44,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  58%|█████▊    | 160/274 [02:25<01:43,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  58%|█████▊    | 160/274 [02:25<01:43,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  59%|█████▉    | 161/274 [02:25<01:42,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  59%|█████▉    | 161/274 [02:25<01:42,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  59%|█████▉    | 162/274 [02:26<01:41,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  59%|█████▉    | 162/274 [02:26<01:41,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  59%|█████▉    | 163/274 [02:27<01:40,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  59%|█████▉    | 163/274 [02:27<01:40,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  60%|█████▉    | 164/274 [02:28<01:39,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  60%|█████▉    | 164/274 [02:28<01:39,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  60%|██████    | 165/274 [02:29<01:38,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  60%|██████    | 165/274 [02:29<01:38,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  61%|██████    | 166/274 [02:30<01:37,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  61%|██████    | 166/274 [02:30<01:37,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  61%|██████    | 167/274 [02:31<01:37,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  61%|██████    | 167/274 [02:31<01:37,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  61%|██████▏   | 168/274 [02:32<01:36,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  61%|██████▏   | 168/274 [02:32<01:36,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  62%|██████▏   | 169/274 [02:33<01:35,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  62%|██████▏   | 169/274 [02:33<01:35,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  62%|██████▏   | 170/274 [02:34<01:34,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  62%|██████▏   | 170/274 [02:34<01:34,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  62%|██████▏   | 171/274 [02:35<01:33,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  62%|██████▏   | 171/274 [02:35<01:33,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  63%|██████▎   | 172/274 [02:35<01:32,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  63%|██████▎   | 172/274 [02:35<01:32,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  63%|██████▎   | 173/274 [02:36<01:31,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  63%|██████▎   | 173/274 [02:36<01:31,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  65%|██████▍   | 178/274 [02:41<01:27,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  65%|██████▍   | 178/274 [02:41<01:27,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  66%|██████▌   | 181/274 [02:44<01:24,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  66%|██████▌   | 181/274 [02:44<01:24,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  66%|██████▋   | 182/274 [02:45<01:23,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  66%|██████▋   | 182/274 [02:45<01:23,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  67%|██████▋   | 183/274 [02:46<01:22,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  67%|██████▋   | 183/274 [02:46<01:22,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  69%|██████▊   | 188/274 [02:50<01:18,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  69%|██████▊   | 188/274 [02:50<01:18,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  70%|███████   | 192/274 [02:54<01:14,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  70%|███████   | 192/274 [02:54<01:14,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  70%|███████   | 193/274 [02:55<01:13,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  70%|███████   | 193/274 [02:55<01:13,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  71%|███████   | 194/274 [02:56<01:12,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  71%|███████   | 194/274 [02:56<01:12,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  73%|███████▎  | 199/274 [03:00<01:08,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  73%|███████▎  | 199/274 [03:00<01:08,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  74%|███████▍  | 204/274 [03:05<01:03,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  74%|███████▍  | 204/274 [03:05<01:03,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  75%|███████▍  | 205/274 [03:06<01:02,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  75%|███████▍  | 205/274 [03:06<01:02,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  78%|███████▊  | 215/274 [03:15<00:53,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  78%|███████▊  | 215/274 [03:15<00:53,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  79%|███████▉  | 216/274 [03:16<00:52,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  79%|███████▉  | 216/274 [03:16<00:52,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  80%|████████  | 220/274 [03:19<00:49,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  80%|████████  | 220/274 [03:19<00:49,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  82%|████████▏ | 225/274 [03:24<00:44,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  82%|████████▏ | 225/274 [03:24<00:44,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  82%|████████▏ | 226/274 [03:25<00:43,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  82%|████████▏ | 226/274 [03:25<00:43,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  83%|████████▎ | 227/274 [03:26<00:42,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  83%|████████▎ | 227/274 [03:26<00:42,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  84%|████████▍ | 231/274 [03:29<00:39,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  84%|████████▍ | 231/274 [03:29<00:39,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  86%|████████▌ | 236/274 [03:34<00:34,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  86%|████████▌ | 236/274 [03:34<00:34,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  86%|████████▋ | 237/274 [03:35<00:33,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  86%|████████▋ | 237/274 [03:35<00:33,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  87%|████████▋ | 238/274 [03:36<00:32,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  87%|████████▋ | 238/274 [03:36<00:32,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  90%|█████████ | 247/274 [03:44<00:24,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  90%|█████████ | 247/274 [03:44<00:24,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  91%|█████████ | 248/274 [03:45<00:23,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  91%|█████████ | 248/274 [03:45<00:23,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  91%|█████████ | 249/274 [03:46<00:22,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  91%|█████████ | 249/274 [03:46<00:22,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  94%|█████████▍| 258/274 [03:54<00:14,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  94%|█████████▍| 258/274 [03:54<00:14,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  95%|█████████▍| 259/274 [03:55<00:13,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  95%|█████████▍| 259/274 [03:55<00:13,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  95%|█████████▍| 260/274 [03:56<00:12,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  95%|█████████▍| 260/274 [03:56<00:12,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  98%|█████████▊| 269/274 [04:04<00:04,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  98%|█████████▊| 269/274 [04:04<00:04,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  99%|█████████▊| 270/274 [04:05<00:03,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  99%|█████████▊| 270/274 [04:05<00:03,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  99%|█████████▉| 271/274 [04:06<00:02,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  99%|█████████▉| 271/274 [04:06<00:02,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "Epoch 3: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.225, val/accuracy=0.919, train/loss=0.166]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   2%|▏         | 1/59 [00:00<00:20,  2.81it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   3%|▎         | 2/59 [00:00<00:17,  3.20it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   5%|▌         | 3/59 [00:00<00:16,  3.36it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   7%|▋         | 4/59 [00:01<00:15,  3.44it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   8%|▊         | 5/59 [00:01<00:15,  3.49it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  10%|█         | 6/59 [00:01<00:15,  3.53it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▏        | 7/59 [00:01<00:14,  3.55it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  14%|█▎        | 8/59 [00:02<00:14,  3.57it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  15%|█▌        | 9/59 [00:02<00:13,  3.59it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  17%|█▋        | 10/59 [00:02<00:13,  3.60it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  19%|█▊        | 11/59 [00:03<00:13,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  20%|██        | 12/59 [00:03<00:12,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  22%|██▏       | 13/59 [00:03<00:12,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  24%|██▎       | 14/59 [00:03<00:12,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 15/59 [00:04<00:12,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  27%|██▋       | 16/59 [00:04<00:11,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  29%|██▉       | 17/59 [00:04<00:11,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  31%|███       | 18/59 [00:04<00:11,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  32%|███▏      | 19/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  34%|███▍      | 20/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  36%|███▌      | 21/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  37%|███▋      | 22/59 [00:06<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  39%|███▉      | 23/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  41%|████      | 24/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  42%|████▏     | 25/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  44%|████▍     | 26/59 [00:07<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  46%|████▌     | 27/59 [00:07<00:08,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  47%|████▋     | 28/59 [00:07<00:08,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  49%|████▉     | 29/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  51%|█████     | 30/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  53%|█████▎    | 31/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  54%|█████▍    | 32/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  56%|█████▌    | 33/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  58%|█████▊    | 34/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  59%|█████▉    | 35/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  61%|██████    | 36/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  63%|██████▎   | 37/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  64%|██████▍   | 38/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  66%|██████▌   | 39/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  68%|██████▊   | 40/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  69%|██████▉   | 41/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  71%|███████   | 42/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  73%|███████▎  | 43/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▍  | 44/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  76%|███████▋  | 45/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  78%|███████▊  | 46/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  80%|███████▉  | 47/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  81%|████████▏ | 48/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  83%|████████▎ | 49/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  85%|████████▍ | 50/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  86%|████████▋ | 51/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 52/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  90%|████████▉ | 53/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  92%|█████████▏| 54/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  93%|█████████▎| 55/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  95%|█████████▍| 56/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  97%|█████████▋| 57/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  98%|█████████▊| 58/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 59/59 [00:15<00:00,  3.70it/s]\u001b[A\n",
      "\n",
      "                                                                        \u001b[A\n",
      "Epoch 3: 100%|██████████| 274/274 [04:24<00:00,  1.03it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.166]\n",
      "Epoch 3: 100%|██████████| 274/274 [04:24<00:00,  1.03it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110][rank: 2] Metric val/loss improved by 0.002 >= min_delta = 0.0. New best score: 0.217\n",
      "[rank: 3] Metric val/loss improved by 0.002 >= min_delta = 0.0. New best score: 0.217\n",
      "[rank: 0] Metric val/loss improved by 0.002 >= min_delta = 0.0. New best score: 0.217\n",
      "[rank: 1] Metric val/loss improved by 0.002 >= min_delta = 0.0. New best score: 0.217\n",
      "Epoch 3, global step 1096: 'val/loss' reached 0.21698 (best 0.21698), saving model to '/home/eaguayo/workspace/DeepLearning/Week3/bert-classifier/sentiment_checkpoints/best-checkpoint-epoch=03-val/loss=0.22.ckpt' as top 1\n",
      "\n",
      "Epoch 3:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   0%|          | 1/274 [00:00<02:43,  1.67it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   0%|          | 1/274 [00:00<02:43,  1.67it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   1%|          | 2/274 [00:01<03:23,  1.34it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   1%|          | 2/274 [00:01<03:23,  1.34it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   1%|          | 3/274 [00:02<03:36,  1.25it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   1%|          | 3/274 [00:02<03:37,  1.25it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   1%|▏         | 4/274 [00:03<03:42,  1.21it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   1%|▏         | 4/274 [00:03<03:42,  1.21it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   2%|▏         | 5/274 [00:04<03:46,  1.19it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   2%|▏         | 5/274 [00:04<03:46,  1.19it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   2%|▏         | 6/274 [00:05<03:48,  1.17it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   2%|▏         | 6/274 [00:05<03:48,  1.17it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   3%|▎         | 8/274 [00:06<03:50,  1.15it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   3%|▎         | 8/274 [00:06<03:50,  1.15it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   4%|▎         | 10/274 [00:08<03:50,  1.14it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   4%|▎         | 10/274 [00:08<03:50,  1.14it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   4%|▍         | 12/274 [00:10<03:50,  1.14it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   4%|▍         | 12/274 [00:10<03:50,  1.14it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   5%|▍         | 13/274 [00:11<03:50,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   5%|▍         | 13/274 [00:11<03:50,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   5%|▌         | 14/274 [00:12<03:49,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   5%|▌         | 14/274 [00:12<03:49,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   5%|▌         | 15/274 [00:13<03:49,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   5%|▌         | 15/274 [00:13<03:49,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   6%|▌         | 17/274 [00:15<03:48,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   6%|▌         | 17/274 [00:15<03:48,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   7%|▋         | 18/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   7%|▋         | 18/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   7%|▋         | 19/274 [00:16<03:46,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   7%|▋         | 19/274 [00:16<03:46,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   7%|▋         | 20/274 [00:17<03:46,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   7%|▋         | 20/274 [00:17<03:46,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   8%|▊         | 23/274 [00:20<03:44,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   8%|▊         | 23/274 [00:20<03:44,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   9%|▉         | 24/274 [00:21<03:43,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   9%|▉         | 24/274 [00:21<03:43,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  10%|▉         | 27/274 [00:24<03:40,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  10%|▉         | 27/274 [00:24<03:40,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  10%|█         | 28/274 [00:25<03:40,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  10%|█         | 28/274 [00:25<03:40,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  12%|█▏        | 32/274 [00:28<03:37,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  12%|█▏        | 32/274 [00:28<03:37,  1.12it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  12%|█▏        | 33/274 [00:29<03:36,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  12%|█▏        | 33/274 [00:29<03:36,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  12%|█▏        | 34/274 [00:30<03:35,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  12%|█▏        | 34/274 [00:30<03:35,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  13%|█▎        | 35/274 [00:31<03:34,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  13%|█▎        | 35/274 [00:31<03:34,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  13%|█▎        | 36/274 [00:32<03:33,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  13%|█▎        | 36/274 [00:32<03:33,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  14%|█▎        | 37/274 [00:33<03:32,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  14%|█▎        | 37/274 [00:33<03:32,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  14%|█▍        | 38/274 [00:34<03:32,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  14%|█▍        | 38/274 [00:34<03:32,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  14%|█▍        | 39/274 [00:35<03:31,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  14%|█▍        | 39/274 [00:35<03:31,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  15%|█▍        | 40/274 [00:35<03:30,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  15%|█▍        | 40/274 [00:35<03:30,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  16%|█▌        | 43/274 [00:38<03:27,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  16%|█▌        | 43/274 [00:38<03:27,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  16%|█▌        | 44/274 [00:39<03:26,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  16%|█▌        | 44/274 [00:39<03:26,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  16%|█▋        | 45/274 [00:40<03:26,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  16%|█▋        | 45/274 [00:40<03:26,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  17%|█▋        | 46/274 [00:41<03:25,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  17%|█▋        | 46/274 [00:41<03:25,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  17%|█▋        | 47/274 [00:42<03:24,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  17%|█▋        | 47/274 [00:42<03:24,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  18%|█▊        | 50/274 [00:45<03:21,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  18%|█▊        | 50/274 [00:45<03:21,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  19%|█▊        | 51/274 [00:45<03:20,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  19%|█▊        | 51/274 [00:45<03:20,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  19%|█▉        | 52/274 [00:46<03:19,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  19%|█▉        | 52/274 [00:46<03:19,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  19%|█▉        | 53/274 [00:47<03:19,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  19%|█▉        | 53/274 [00:47<03:19,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  20%|█▉        | 54/274 [00:48<03:18,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  20%|█▉        | 54/274 [00:48<03:18,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  22%|██▏       | 59/274 [00:53<03:13,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  22%|██▏       | 59/274 [00:53<03:13,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  22%|██▏       | 60/274 [00:54<03:12,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  22%|██▏       | 60/274 [00:54<03:12,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  22%|██▏       | 61/274 [00:55<03:12,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  22%|██▏       | 61/274 [00:55<03:12,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  23%|██▎       | 62/274 [00:55<03:11,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  23%|██▎       | 62/274 [00:55<03:11,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  23%|██▎       | 63/274 [00:56<03:10,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  23%|██▎       | 63/274 [00:56<03:10,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  25%|██▍       | 68/274 [01:01<03:05,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  25%|██▍       | 68/274 [01:01<03:05,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  25%|██▌       | 69/274 [01:02<03:05,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  25%|██▌       | 69/274 [01:02<03:05,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  26%|██▌       | 70/274 [01:03<03:04,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  26%|██▌       | 70/274 [01:03<03:04,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  26%|██▌       | 71/274 [01:04<03:03,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  26%|██▌       | 71/274 [01:04<03:03,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  26%|██▋       | 72/274 [01:04<03:02,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  26%|██▋       | 72/274 [01:04<03:02,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  28%|██▊       | 77/274 [01:09<02:57,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  28%|██▊       | 77/274 [01:09<02:57,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  28%|██▊       | 78/274 [01:10<02:56,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  28%|██▊       | 78/274 [01:10<02:56,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  29%|██▉       | 79/274 [01:11<02:56,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  29%|██▉       | 79/274 [01:11<02:56,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  29%|██▉       | 80/274 [01:12<02:55,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  29%|██▉       | 80/274 [01:12<02:55,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  30%|██▉       | 81/274 [01:13<02:54,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  30%|██▉       | 81/274 [01:13<02:54,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  30%|██▉       | 82/274 [01:14<02:53,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  30%|██▉       | 82/274 [01:14<02:53,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  30%|███       | 83/274 [01:14<02:52,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  30%|███       | 83/274 [01:14<02:52,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  32%|███▏      | 87/274 [01:18<02:48,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  32%|███▏      | 87/274 [01:18<02:48,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  32%|███▏      | 88/274 [01:19<02:48,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  32%|███▏      | 88/274 [01:19<02:48,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  32%|███▏      | 89/274 [01:20<02:47,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  32%|███▏      | 89/274 [01:20<02:47,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  33%|███▎      | 90/274 [01:21<02:46,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  33%|███▎      | 90/274 [01:21<02:46,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  34%|███▎      | 92/274 [01:23<02:44,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  34%|███▎      | 92/274 [01:23<02:44,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  34%|███▍      | 93/274 [01:24<02:43,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  34%|███▍      | 93/274 [01:24<02:43,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  34%|███▍      | 94/274 [01:24<02:42,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  34%|███▍      | 94/274 [01:24<02:42,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  35%|███▌      | 96/274 [01:26<02:40,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  35%|███▌      | 96/274 [01:26<02:40,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  35%|███▌      | 97/274 [01:27<02:39,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  35%|███▌      | 97/274 [01:27<02:39,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  36%|███▌      | 98/274 [01:28<02:39,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  36%|███▌      | 98/274 [01:28<02:39,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  36%|███▌      | 99/274 [01:29<02:38,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  36%|███▌      | 99/274 [01:29<02:38,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  36%|███▋      | 100/274 [01:30<02:37,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  36%|███▋      | 100/274 [01:30<02:37,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  38%|███▊      | 103/274 [01:33<02:34,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  38%|███▊      | 103/274 [01:33<02:34,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  38%|███▊      | 104/274 [01:34<02:33,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  38%|███▊      | 104/274 [01:34<02:33,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  39%|███▊      | 106/274 [01:35<02:31,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  39%|███▊      | 106/274 [01:35<02:31,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  39%|███▉      | 107/274 [01:36<02:31,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  39%|███▉      | 107/274 [01:36<02:31,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  39%|███▉      | 108/274 [01:37<02:30,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  39%|███▉      | 108/274 [01:37<02:30,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  40%|███▉      | 109/274 [01:38<02:29,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  40%|███▉      | 109/274 [01:38<02:29,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  40%|████      | 110/274 [01:39<02:28,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  40%|████      | 110/274 [01:39<02:28,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  41%|████      | 111/274 [01:40<02:27,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  41%|████      | 111/274 [01:40<02:27,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  41%|████      | 112/274 [01:41<02:26,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  41%|████      | 112/274 [01:41<02:26,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  41%|████      | 113/274 [01:42<02:25,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  41%|████      | 113/274 [01:42<02:25,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  42%|████▏     | 114/274 [01:43<02:24,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  42%|████▏     | 114/274 [01:43<02:24,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  42%|████▏     | 115/274 [01:44<02:23,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  42%|████▏     | 115/274 [01:44<02:23,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  42%|████▏     | 116/274 [01:44<02:22,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  42%|████▏     | 116/274 [01:44<02:22,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  43%|████▎     | 117/274 [01:45<02:22,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  43%|████▎     | 117/274 [01:45<02:22,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  43%|████▎     | 118/274 [01:46<02:21,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  43%|████▎     | 118/274 [01:46<02:21,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  43%|████▎     | 119/274 [01:47<02:20,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  43%|████▎     | 119/274 [01:47<02:20,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  44%|████▍     | 120/274 [01:48<02:19,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  44%|████▍     | 120/274 [01:48<02:19,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  44%|████▍     | 121/274 [01:49<02:18,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  44%|████▍     | 121/274 [01:49<02:18,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  45%|████▍     | 122/274 [01:50<02:17,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  45%|████▍     | 122/274 [01:50<02:17,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  45%|████▍     | 123/274 [01:51<02:16,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  45%|████▍     | 123/274 [01:51<02:16,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  45%|████▌     | 124/274 [01:52<02:15,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  45%|████▌     | 124/274 [01:52<02:15,  1.11it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  46%|████▌     | 125/274 [01:53<02:14,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  46%|████▌     | 125/274 [01:53<02:14,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  46%|████▌     | 126/274 [01:54<02:13,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  46%|████▌     | 126/274 [01:54<02:13,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  46%|████▋     | 127/274 [01:54<02:13,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  46%|████▋     | 127/274 [01:54<02:13,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  47%|████▋     | 128/274 [01:55<02:12,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  47%|████▋     | 128/274 [01:55<02:12,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  47%|████▋     | 129/274 [01:56<02:11,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  47%|████▋     | 129/274 [01:56<02:11,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  47%|████▋     | 130/274 [01:57<02:10,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  47%|████▋     | 130/274 [01:57<02:10,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  48%|████▊     | 131/274 [01:58<02:09,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  48%|████▊     | 131/274 [01:58<02:09,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  48%|████▊     | 132/274 [01:59<02:08,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  48%|████▊     | 132/274 [01:59<02:08,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  49%|████▊     | 133/274 [02:00<02:07,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  49%|████▊     | 133/274 [02:00<02:07,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  49%|████▉     | 134/274 [02:01<02:06,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  49%|████▉     | 134/274 [02:01<02:06,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  49%|████▉     | 135/274 [02:02<02:05,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  49%|████▉     | 135/274 [02:02<02:05,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  50%|████▉     | 136/274 [02:03<02:04,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  50%|████▉     | 136/274 [02:03<02:04,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  50%|█████     | 137/274 [02:04<02:04,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  50%|█████     | 137/274 [02:04<02:04,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  50%|█████     | 138/274 [02:04<02:03,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  50%|█████     | 138/274 [02:04<02:03,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  51%|█████     | 139/274 [02:05<02:02,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  51%|█████     | 139/274 [02:05<02:02,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  51%|█████     | 140/274 [02:06<02:01,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  51%|█████     | 140/274 [02:06<02:01,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  51%|█████▏    | 141/274 [02:07<02:00,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  51%|█████▏    | 141/274 [02:07<02:00,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  52%|█████▏    | 142/274 [02:08<01:59,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  52%|█████▏    | 142/274 [02:08<01:59,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  52%|█████▏    | 143/274 [02:09<01:58,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  52%|█████▏    | 143/274 [02:09<01:58,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  53%|█████▎    | 144/274 [02:10<01:57,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  53%|█████▎    | 144/274 [02:10<01:57,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  53%|█████▎    | 145/274 [02:11<01:56,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  53%|█████▎    | 145/274 [02:11<01:56,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  53%|█████▎    | 146/274 [02:12<01:55,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  53%|█████▎    | 146/274 [02:12<01:55,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  54%|█████▎    | 147/274 [02:13<01:55,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  54%|█████▎    | 147/274 [02:13<01:55,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  54%|█████▍    | 148/274 [02:14<01:54,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  54%|█████▍    | 148/274 [02:14<01:54,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  54%|█████▍    | 149/274 [02:14<01:53,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  54%|█████▍    | 149/274 [02:14<01:53,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  55%|█████▍    | 150/274 [02:15<01:52,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  55%|█████▍    | 150/274 [02:15<01:52,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  55%|█████▌    | 151/274 [02:16<01:51,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  55%|█████▌    | 151/274 [02:16<01:51,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  55%|█████▌    | 152/274 [02:17<01:50,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  55%|█████▌    | 152/274 [02:17<01:50,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  56%|█████▌    | 153/274 [02:18<01:49,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  56%|█████▌    | 153/274 [02:18<01:49,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  56%|█████▌    | 154/274 [02:19<01:48,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  56%|█████▌    | 154/274 [02:19<01:48,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  57%|█████▋    | 155/274 [02:20<01:47,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  57%|█████▋    | 155/274 [02:20<01:47,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  57%|█████▋    | 156/274 [02:21<01:46,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  57%|█████▋    | 156/274 [02:21<01:46,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  57%|█████▋    | 157/274 [02:22<01:45,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  57%|█████▋    | 157/274 [02:22<01:45,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  58%|█████▊    | 158/274 [02:23<01:45,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  58%|█████▊    | 158/274 [02:23<01:45,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  58%|█████▊    | 159/274 [02:24<01:44,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  58%|█████▊    | 159/274 [02:24<01:44,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  58%|█████▊    | 160/274 [02:24<01:43,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  58%|█████▊    | 160/274 [02:24<01:43,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  59%|█████▉    | 161/274 [02:25<01:42,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  59%|█████▉    | 161/274 [02:25<01:42,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  59%|█████▉    | 162/274 [02:26<01:41,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  59%|█████▉    | 162/274 [02:26<01:41,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  59%|█████▉    | 163/274 [02:27<01:40,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  59%|█████▉    | 163/274 [02:27<01:40,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  60%|█████▉    | 164/274 [02:28<01:39,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  60%|█████▉    | 164/274 [02:28<01:39,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  60%|██████    | 165/274 [02:29<01:38,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  60%|██████    | 165/274 [02:29<01:38,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  61%|██████    | 166/274 [02:30<01:37,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  61%|██████    | 166/274 [02:30<01:37,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  61%|██████    | 167/274 [02:31<01:36,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  61%|██████    | 167/274 [02:31<01:36,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  61%|██████▏   | 168/274 [02:32<01:36,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  61%|██████▏   | 168/274 [02:32<01:36,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  62%|██████▏   | 169/274 [02:33<01:35,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  62%|██████▏   | 169/274 [02:33<01:35,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  62%|██████▏   | 170/274 [02:34<01:34,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  62%|██████▏   | 170/274 [02:34<01:34,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  62%|██████▏   | 171/274 [02:34<01:33,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  62%|██████▏   | 171/274 [02:34<01:33,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  63%|██████▎   | 172/274 [02:35<01:32,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  63%|██████▎   | 172/274 [02:35<01:32,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  63%|██████▎   | 173/274 [02:36<01:31,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  63%|██████▎   | 173/274 [02:36<01:31,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  65%|██████▍   | 178/274 [02:41<01:26,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  65%|██████▍   | 178/274 [02:41<01:26,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  66%|██████▌   | 181/274 [02:44<01:24,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  66%|██████▌   | 181/274 [02:44<01:24,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  66%|██████▋   | 182/274 [02:44<01:23,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  66%|██████▋   | 182/274 [02:44<01:23,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  67%|██████▋   | 183/274 [02:45<01:22,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  67%|██████▋   | 183/274 [02:45<01:22,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  69%|██████▊   | 188/274 [02:50<01:17,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  69%|██████▊   | 188/274 [02:50<01:17,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  70%|███████   | 192/274 [02:54<01:14,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  70%|███████   | 192/274 [02:54<01:14,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  70%|███████   | 193/274 [02:54<01:13,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  70%|███████   | 193/274 [02:54<01:13,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  71%|███████   | 194/274 [02:55<01:12,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  71%|███████   | 194/274 [02:55<01:12,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  73%|███████▎  | 199/274 [03:00<01:07,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  73%|███████▎  | 199/274 [03:00<01:07,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  74%|███████▍  | 204/274 [03:04<01:03,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  74%|███████▍  | 204/274 [03:04<01:03,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  75%|███████▍  | 205/274 [03:05<01:02,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  75%|███████▍  | 205/274 [03:05<01:02,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  78%|███████▊  | 215/274 [03:14<00:53,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  78%|███████▊  | 215/274 [03:14<00:53,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  79%|███████▉  | 216/274 [03:15<00:52,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  79%|███████▉  | 216/274 [03:15<00:52,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  80%|████████  | 220/274 [03:19<00:48,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  80%|████████  | 220/274 [03:19<00:48,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  82%|████████▏ | 225/274 [03:24<00:44,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  82%|████████▏ | 225/274 [03:24<00:44,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  84%|████████▍ | 231/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  84%|████████▍ | 231/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  86%|████████▌ | 236/274 [03:33<00:34,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  86%|████████▌ | 236/274 [03:33<00:34,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  90%|█████████ | 247/274 [03:43<00:24,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  90%|█████████ | 247/274 [03:43<00:24,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  94%|█████████▍| 258/274 [03:54<00:14,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  94%|█████████▍| 258/274 [03:54<00:14,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  95%|█████████▍| 259/274 [03:54<00:13,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  95%|█████████▍| 259/274 [03:54<00:13,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  98%|█████████▊| 269/274 [04:04<00:04,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  98%|█████████▊| 269/274 [04:04<00:04,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  99%|█████████▊| 270/274 [04:04<00:03,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  99%|█████████▊| 270/274 [04:04<00:03,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "Epoch 4: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.217, val/accuracy=0.926, train/loss=0.110]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   2%|▏         | 1/59 [00:00<00:19,  3.03it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   3%|▎         | 2/59 [00:00<00:17,  3.34it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   5%|▌         | 3/59 [00:00<00:16,  3.45it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   7%|▋         | 4/59 [00:01<00:15,  3.51it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   8%|▊         | 5/59 [00:01<00:15,  3.55it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  10%|█         | 6/59 [00:01<00:14,  3.57it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▏        | 7/59 [00:01<00:14,  3.59it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  14%|█▎        | 8/59 [00:02<00:14,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  15%|█▌        | 9/59 [00:02<00:13,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  17%|█▋        | 10/59 [00:02<00:13,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  19%|█▊        | 11/59 [00:03<00:13,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  20%|██        | 12/59 [00:03<00:12,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  22%|██▏       | 13/59 [00:03<00:12,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  24%|██▎       | 14/59 [00:03<00:12,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 15/59 [00:04<00:12,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  27%|██▋       | 16/59 [00:04<00:11,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  29%|██▉       | 17/59 [00:04<00:11,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  31%|███       | 18/59 [00:04<00:11,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  32%|███▏      | 19/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  34%|███▍      | 20/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  36%|███▌      | 21/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  37%|███▋      | 22/59 [00:06<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  39%|███▉      | 23/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  41%|████      | 24/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  42%|████▏     | 25/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  44%|████▍     | 26/59 [00:07<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  46%|████▌     | 27/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  47%|████▋     | 28/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  49%|████▉     | 29/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  51%|█████     | 30/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  53%|█████▎    | 31/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  54%|█████▍    | 32/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  56%|█████▌    | 33/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  58%|█████▊    | 34/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  59%|█████▉    | 35/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  61%|██████    | 36/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  63%|██████▎   | 37/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  64%|██████▍   | 38/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  66%|██████▌   | 39/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  68%|██████▊   | 40/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  69%|██████▉   | 41/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  71%|███████   | 42/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  73%|███████▎  | 43/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▍  | 44/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  76%|███████▋  | 45/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  78%|███████▊  | 46/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  80%|███████▉  | 47/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  81%|████████▏ | 48/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  83%|████████▎ | 49/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  85%|████████▍ | 50/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  86%|████████▋ | 51/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 52/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  90%|████████▉ | 53/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  92%|█████████▏| 54/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  93%|█████████▎| 55/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  95%|█████████▍| 56/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  97%|█████████▋| 57/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  98%|█████████▊| 58/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 59/59 [00:15<00:00,  3.70it/s]\u001b[A\n",
      "\n",
      "                                                                        \u001b[A\n",
      "Epoch 4: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.110]\n",
      "Epoch 4: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]Epoch 4, global step 1370: 'val/loss' was not in top 1\n",
      "\n",
      "Epoch 4:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   0%|          | 1/274 [00:00<02:37,  1.74it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   0%|          | 1/274 [00:00<02:37,  1.73it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   1%|          | 2/274 [00:01<03:21,  1.35it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   1%|          | 2/274 [00:01<03:21,  1.35it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   1%|          | 3/274 [00:02<03:35,  1.26it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   1%|          | 3/274 [00:02<03:35,  1.26it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   1%|▏         | 4/274 [00:03<03:41,  1.22it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   1%|▏         | 4/274 [00:03<03:41,  1.22it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   2%|▏         | 5/274 [00:04<03:45,  1.19it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   2%|▏         | 5/274 [00:04<03:45,  1.19it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   2%|▏         | 6/274 [00:05<03:47,  1.18it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   2%|▏         | 6/274 [00:05<03:47,  1.18it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   3%|▎         | 8/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   3%|▎         | 8/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   4%|▎         | 10/274 [00:08<03:50,  1.15it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   4%|▎         | 10/274 [00:08<03:50,  1.15it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   4%|▍         | 12/274 [00:10<03:49,  1.14it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   4%|▍         | 12/274 [00:10<03:49,  1.14it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   5%|▍         | 13/274 [00:11<03:49,  1.14it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   5%|▍         | 13/274 [00:11<03:49,  1.14it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   5%|▌         | 14/274 [00:12<03:49,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   5%|▌         | 14/274 [00:12<03:49,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   5%|▌         | 15/274 [00:13<03:48,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   5%|▌         | 15/274 [00:13<03:48,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   6%|▌         | 17/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   6%|▌         | 17/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   7%|▋         | 18/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   7%|▋         | 18/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   7%|▋         | 19/274 [00:16<03:46,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   7%|▋         | 19/274 [00:16<03:46,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   7%|▋         | 20/274 [00:17<03:45,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   7%|▋         | 20/274 [00:17<03:45,  1.13it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   8%|▊         | 23/274 [00:20<03:43,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   8%|▊         | 23/274 [00:20<03:43,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   9%|▉         | 24/274 [00:21<03:42,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   9%|▉         | 24/274 [00:21<03:42,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  10%|▉         | 27/274 [00:24<03:40,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  10%|▉         | 27/274 [00:24<03:40,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  10%|█         | 28/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  10%|█         | 28/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  12%|█▏        | 32/274 [00:28<03:36,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  12%|█▏        | 32/274 [00:28<03:36,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  12%|█▏        | 33/274 [00:29<03:36,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  12%|█▏        | 33/274 [00:29<03:36,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  12%|█▏        | 34/274 [00:30<03:35,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  12%|█▏        | 34/274 [00:30<03:35,  1.12it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  13%|█▎        | 35/274 [00:31<03:34,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  13%|█▎        | 35/274 [00:31<03:34,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  13%|█▎        | 36/274 [00:32<03:33,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  13%|█▎        | 36/274 [00:32<03:33,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  14%|█▎        | 37/274 [00:33<03:32,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  14%|█▎        | 37/274 [00:33<03:32,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  14%|█▍        | 38/274 [00:34<03:31,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  14%|█▍        | 38/274 [00:34<03:31,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  14%|█▍        | 39/274 [00:35<03:31,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  14%|█▍        | 39/274 [00:35<03:31,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  15%|█▍        | 40/274 [00:35<03:30,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  15%|█▍        | 40/274 [00:35<03:30,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  16%|█▌        | 43/274 [00:38<03:27,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  16%|█▌        | 43/274 [00:38<03:27,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  16%|█▌        | 44/274 [00:39<03:26,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  16%|█▌        | 44/274 [00:39<03:26,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  16%|█▋        | 45/274 [00:40<03:25,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  16%|█▋        | 45/274 [00:40<03:25,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  17%|█▋        | 46/274 [00:41<03:25,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  17%|█▋        | 46/274 [00:41<03:25,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  17%|█▋        | 47/274 [00:42<03:24,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  17%|█▋        | 47/274 [00:42<03:24,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  18%|█▊        | 50/274 [00:45<03:21,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  18%|█▊        | 50/274 [00:45<03:21,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  19%|█▊        | 51/274 [00:45<03:20,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  19%|█▊        | 51/274 [00:45<03:20,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  19%|█▉        | 52/274 [00:46<03:19,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  19%|█▉        | 52/274 [00:46<03:19,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  19%|█▉        | 53/274 [00:47<03:19,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  19%|█▉        | 53/274 [00:47<03:19,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  20%|█▉        | 54/274 [00:48<03:18,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  20%|█▉        | 54/274 [00:48<03:18,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  22%|██▏       | 59/274 [00:53<03:13,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  22%|██▏       | 59/274 [00:53<03:13,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  22%|██▏       | 60/274 [00:54<03:12,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  22%|██▏       | 60/274 [00:54<03:12,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  22%|██▏       | 61/274 [00:54<03:11,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  22%|██▏       | 61/274 [00:54<03:11,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  23%|██▎       | 62/274 [00:55<03:11,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  23%|██▎       | 62/274 [00:55<03:11,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  23%|██▎       | 63/274 [00:56<03:10,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  23%|██▎       | 63/274 [00:56<03:10,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  25%|██▍       | 68/274 [01:01<03:05,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  25%|██▍       | 68/274 [01:01<03:05,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  25%|██▌       | 69/274 [01:02<03:04,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  25%|██▌       | 69/274 [01:02<03:04,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  26%|██▌       | 70/274 [01:03<03:04,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  26%|██▌       | 70/274 [01:03<03:04,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  26%|██▌       | 71/274 [01:04<03:03,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  26%|██▌       | 71/274 [01:04<03:03,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  26%|██▋       | 72/274 [01:04<03:02,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  26%|██▋       | 72/274 [01:04<03:02,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  28%|██▊       | 77/274 [01:09<02:57,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  28%|██▊       | 77/274 [01:09<02:57,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  28%|██▊       | 78/274 [01:10<02:56,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  28%|██▊       | 78/274 [01:10<02:56,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  29%|██▉       | 79/274 [01:11<02:56,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  29%|██▉       | 79/274 [01:11<02:56,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  29%|██▉       | 80/274 [01:12<02:55,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  29%|██▉       | 80/274 [01:12<02:55,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  30%|██▉       | 81/274 [01:13<02:54,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  30%|██▉       | 81/274 [01:13<02:54,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  30%|██▉       | 82/274 [01:14<02:53,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  30%|██▉       | 82/274 [01:14<02:53,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  30%|███       | 83/274 [01:14<02:52,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  30%|███       | 83/274 [01:14<02:52,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  32%|███▏      | 87/274 [01:18<02:48,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  32%|███▏      | 87/274 [01:18<02:48,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  32%|███▏      | 88/274 [01:19<02:48,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  32%|███▏      | 88/274 [01:19<02:48,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  32%|███▏      | 89/274 [01:20<02:47,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  32%|███▏      | 89/274 [01:20<02:47,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  33%|███▎      | 90/274 [01:21<02:46,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  33%|███▎      | 90/274 [01:21<02:46,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  34%|███▎      | 92/274 [01:23<02:44,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  34%|███▎      | 92/274 [01:23<02:44,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  34%|███▍      | 93/274 [01:24<02:43,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  34%|███▍      | 93/274 [01:24<02:43,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  34%|███▍      | 94/274 [01:24<02:42,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  34%|███▍      | 94/274 [01:24<02:42,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  35%|███▌      | 96/274 [01:26<02:40,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  35%|███▌      | 96/274 [01:26<02:40,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  35%|███▌      | 97/274 [01:27<02:39,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  35%|███▌      | 97/274 [01:27<02:39,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  36%|███▌      | 98/274 [01:28<02:39,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  36%|███▌      | 98/274 [01:28<02:39,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  36%|███▌      | 99/274 [01:29<02:38,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  36%|███▌      | 99/274 [01:29<02:38,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  36%|███▋      | 100/274 [01:30<02:37,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  36%|███▋      | 100/274 [01:30<02:37,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  38%|███▊      | 103/274 [01:33<02:34,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  38%|███▊      | 103/274 [01:33<02:34,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  38%|███▊      | 104/274 [01:34<02:33,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  38%|███▊      | 104/274 [01:34<02:33,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  39%|███▊      | 106/274 [01:35<02:31,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  39%|███▊      | 106/274 [01:35<02:31,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  39%|███▉      | 107/274 [01:36<02:30,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  39%|███▉      | 107/274 [01:36<02:30,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  39%|███▉      | 108/274 [01:37<02:30,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  39%|███▉      | 108/274 [01:37<02:30,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  40%|███▉      | 109/274 [01:38<02:29,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  40%|███▉      | 109/274 [01:38<02:29,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  40%|████      | 110/274 [01:39<02:28,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  40%|████      | 110/274 [01:39<02:28,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  41%|████      | 111/274 [01:40<02:27,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  41%|████      | 111/274 [01:40<02:27,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  41%|████      | 112/274 [01:41<02:26,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  41%|████      | 112/274 [01:41<02:26,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  41%|████      | 113/274 [01:42<02:25,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  41%|████      | 113/274 [01:42<02:25,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  42%|████▏     | 114/274 [01:43<02:24,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  42%|████▏     | 114/274 [01:43<02:24,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  42%|████▏     | 115/274 [01:44<02:23,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  42%|████▏     | 115/274 [01:44<02:23,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  42%|████▏     | 116/274 [01:44<02:22,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  42%|████▏     | 116/274 [01:44<02:22,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  43%|████▎     | 117/274 [01:45<02:22,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  43%|████▎     | 117/274 [01:45<02:22,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  43%|████▎     | 118/274 [01:46<02:21,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  43%|████▎     | 118/274 [01:46<02:21,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  43%|████▎     | 119/274 [01:47<02:20,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  43%|████▎     | 119/274 [01:47<02:20,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  44%|████▍     | 120/274 [01:48<02:19,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  44%|████▍     | 120/274 [01:48<02:19,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  44%|████▍     | 121/274 [01:49<02:18,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  44%|████▍     | 121/274 [01:49<02:18,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  45%|████▍     | 122/274 [01:50<02:17,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  45%|████▍     | 122/274 [01:50<02:17,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  45%|████▍     | 123/274 [01:51<02:16,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  45%|████▍     | 123/274 [01:51<02:16,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  45%|████▌     | 124/274 [01:52<02:15,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  45%|████▌     | 124/274 [01:52<02:15,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  46%|████▌     | 125/274 [01:53<02:14,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  46%|████▌     | 125/274 [01:53<02:14,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  46%|████▌     | 126/274 [01:53<02:13,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  46%|████▌     | 126/274 [01:53<02:13,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  46%|████▋     | 127/274 [01:54<02:13,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  46%|████▋     | 127/274 [01:54<02:13,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  47%|████▋     | 128/274 [01:55<02:12,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  47%|████▋     | 128/274 [01:55<02:12,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  47%|████▋     | 129/274 [01:56<02:11,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  47%|████▋     | 129/274 [01:56<02:11,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  47%|████▋     | 130/274 [01:57<02:10,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  47%|████▋     | 130/274 [01:57<02:10,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  48%|████▊     | 131/274 [01:58<02:09,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  48%|████▊     | 131/274 [01:58<02:09,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  48%|████▊     | 132/274 [01:59<02:08,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  48%|████▊     | 132/274 [01:59<02:08,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  49%|████▊     | 133/274 [02:00<02:07,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  49%|████▊     | 133/274 [02:00<02:07,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  49%|████▉     | 134/274 [02:01<02:06,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  49%|████▉     | 134/274 [02:01<02:06,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  49%|████▉     | 135/274 [02:02<02:05,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  49%|████▉     | 135/274 [02:02<02:05,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  50%|████▉     | 136/274 [02:03<02:04,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  50%|████▉     | 136/274 [02:03<02:04,  1.11it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  50%|█████     | 137/274 [02:03<02:03,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  50%|█████     | 137/274 [02:03<02:03,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  50%|█████     | 138/274 [02:04<02:03,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  50%|█████     | 138/274 [02:04<02:03,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  51%|█████     | 139/274 [02:05<02:02,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  51%|█████     | 139/274 [02:05<02:02,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  51%|█████     | 140/274 [02:06<02:01,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  51%|█████     | 140/274 [02:06<02:01,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  51%|█████▏    | 141/274 [02:07<02:00,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  51%|█████▏    | 141/274 [02:07<02:00,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  52%|█████▏    | 142/274 [02:08<01:59,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  52%|█████▏    | 142/274 [02:08<01:59,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  52%|█████▏    | 143/274 [02:09<01:58,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  52%|█████▏    | 143/274 [02:09<01:58,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  53%|█████▎    | 144/274 [02:10<01:57,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  53%|█████▎    | 144/274 [02:10<01:57,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  53%|█████▎    | 145/274 [02:11<01:56,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  53%|█████▎    | 145/274 [02:11<01:56,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  53%|█████▎    | 146/274 [02:12<01:55,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  53%|█████▎    | 146/274 [02:12<01:55,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  54%|█████▎    | 147/274 [02:13<01:54,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  54%|█████▎    | 147/274 [02:13<01:54,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  54%|█████▍    | 148/274 [02:13<01:54,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  54%|█████▍    | 148/274 [02:13<01:54,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  54%|█████▍    | 149/274 [02:14<01:53,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  54%|█████▍    | 149/274 [02:14<01:53,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  55%|█████▍    | 150/274 [02:15<01:52,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  55%|█████▍    | 150/274 [02:15<01:52,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  55%|█████▌    | 151/274 [02:16<01:51,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  55%|█████▌    | 151/274 [02:16<01:51,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  55%|█████▌    | 152/274 [02:17<01:50,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  55%|█████▌    | 152/274 [02:17<01:50,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  56%|█████▌    | 153/274 [02:18<01:49,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  56%|█████▌    | 153/274 [02:18<01:49,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  56%|█████▌    | 154/274 [02:19<01:48,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  56%|█████▌    | 154/274 [02:19<01:48,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  57%|█████▋    | 155/274 [02:20<01:47,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  57%|█████▋    | 155/274 [02:20<01:47,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  57%|█████▋    | 156/274 [02:21<01:46,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  57%|█████▋    | 156/274 [02:21<01:46,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  57%|█████▋    | 157/274 [02:22<01:45,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  57%|█████▋    | 157/274 [02:22<01:45,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  58%|█████▊    | 158/274 [02:23<01:45,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  58%|█████▊    | 158/274 [02:23<01:45,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  58%|█████▊    | 159/274 [02:23<01:44,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  58%|█████▊    | 159/274 [02:23<01:44,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  58%|█████▊    | 160/274 [02:24<01:43,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  58%|█████▊    | 160/274 [02:24<01:43,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  59%|█████▉    | 161/274 [02:25<01:42,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  59%|█████▉    | 161/274 [02:25<01:42,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  59%|█████▉    | 162/274 [02:26<01:41,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  59%|█████▉    | 162/274 [02:26<01:41,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  59%|█████▉    | 163/274 [02:27<01:40,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  59%|█████▉    | 163/274 [02:27<01:40,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  60%|█████▉    | 164/274 [02:28<01:39,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  60%|█████▉    | 164/274 [02:28<01:39,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  60%|██████    | 165/274 [02:29<01:38,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  60%|██████    | 165/274 [02:29<01:38,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  61%|██████    | 166/274 [02:30<01:37,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  61%|██████    | 166/274 [02:30<01:37,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  61%|██████    | 167/274 [02:31<01:36,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  61%|██████    | 167/274 [02:31<01:36,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  61%|██████▏   | 168/274 [02:32<01:35,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  61%|██████▏   | 168/274 [02:32<01:35,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  62%|██████▏   | 169/274 [02:33<01:35,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  62%|██████▏   | 169/274 [02:33<01:35,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  62%|██████▏   | 170/274 [02:33<01:34,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  62%|██████▏   | 170/274 [02:33<01:34,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  62%|██████▏   | 171/274 [02:34<01:33,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  62%|██████▏   | 171/274 [02:34<01:33,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  63%|██████▎   | 172/274 [02:35<01:32,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  63%|██████▎   | 172/274 [02:35<01:32,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  63%|██████▎   | 173/274 [02:36<01:31,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  63%|██████▎   | 173/274 [02:36<01:31,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  65%|██████▍   | 178/274 [02:41<01:26,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  65%|██████▍   | 178/274 [02:41<01:26,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  66%|██████▌   | 181/274 [02:43<01:24,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  66%|██████▌   | 181/274 [02:43<01:24,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  66%|██████▋   | 182/274 [02:44<01:23,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  66%|██████▋   | 182/274 [02:44<01:23,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  67%|██████▋   | 183/274 [02:45<01:22,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  67%|██████▋   | 183/274 [02:45<01:22,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  69%|██████▊   | 188/274 [02:50<01:17,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  69%|██████▊   | 188/274 [02:50<01:17,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  70%|███████   | 192/274 [02:53<01:14,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  70%|███████   | 192/274 [02:53<01:14,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  70%|███████   | 193/274 [02:54<01:13,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  70%|███████   | 193/274 [02:54<01:13,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  71%|███████   | 194/274 [02:55<01:12,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  71%|███████   | 194/274 [02:55<01:12,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  73%|███████▎  | 199/274 [03:00<01:07,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  73%|███████▎  | 199/274 [03:00<01:07,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  74%|███████▍  | 204/274 [03:04<01:03,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  74%|███████▍  | 204/274 [03:04<01:03,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  75%|███████▍  | 205/274 [03:05<01:02,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  75%|███████▍  | 205/274 [03:05<01:02,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  78%|███████▊  | 215/274 [03:14<00:53,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  78%|███████▊  | 215/274 [03:14<00:53,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  79%|███████▉  | 216/274 [03:15<00:52,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  79%|███████▉  | 216/274 [03:15<00:52,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  80%|████████  | 220/274 [03:19<00:48,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  80%|████████  | 220/274 [03:19<00:48,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  82%|████████▏ | 225/274 [03:24<00:44,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  82%|████████▏ | 225/274 [03:24<00:44,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  84%|████████▍ | 231/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  84%|████████▍ | 231/274 [03:29<00:38,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  86%|████████▌ | 236/274 [03:34<00:34,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  86%|████████▌ | 236/274 [03:34<00:34,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  90%|█████████ | 247/274 [03:44<00:24,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  90%|█████████ | 247/274 [03:44<00:24,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  94%|█████████▍| 258/274 [03:54<00:14,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  94%|█████████▍| 258/274 [03:54<00:14,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  95%|█████████▍| 259/274 [03:54<00:13,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  95%|█████████▍| 259/274 [03:54<00:13,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  98%|█████████▊| 269/274 [04:04<00:04,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  98%|█████████▊| 269/274 [04:04<00:04,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  99%|█████████▊| 270/274 [04:04<00:03,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  99%|█████████▊| 270/274 [04:04<00:03,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "Epoch 5: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.244, val/accuracy=0.922, train/loss=0.0603]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   2%|▏         | 1/59 [00:00<00:20,  2.77it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   3%|▎         | 2/59 [00:00<00:17,  3.17it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   5%|▌         | 3/59 [00:00<00:16,  3.33it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   7%|▋         | 4/59 [00:01<00:16,  3.42it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   8%|▊         | 5/59 [00:01<00:15,  3.47it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  10%|█         | 6/59 [00:01<00:15,  3.51it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▏        | 7/59 [00:01<00:14,  3.54it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  14%|█▎        | 8/59 [00:02<00:14,  3.56it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  15%|█▌        | 9/59 [00:02<00:13,  3.58it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  17%|█▋        | 10/59 [00:02<00:13,  3.59it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  19%|█▊        | 11/59 [00:03<00:13,  3.60it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  20%|██        | 12/59 [00:03<00:13,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  22%|██▏       | 13/59 [00:03<00:12,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  24%|██▎       | 14/59 [00:03<00:12,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 15/59 [00:04<00:12,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  27%|██▋       | 16/59 [00:04<00:11,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  29%|██▉       | 17/59 [00:04<00:11,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  31%|███       | 18/59 [00:04<00:11,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  32%|███▏      | 19/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  34%|███▍      | 20/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  36%|███▌      | 21/59 [00:05<00:10,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  37%|███▋      | 22/59 [00:06<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  39%|███▉      | 23/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  41%|████      | 24/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  42%|████▏     | 25/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  44%|████▍     | 26/59 [00:07<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  46%|████▌     | 27/59 [00:07<00:08,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  47%|████▋     | 28/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  49%|████▉     | 29/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  51%|█████     | 30/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  53%|█████▎    | 31/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  54%|█████▍    | 32/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  56%|█████▌    | 33/59 [00:08<00:07,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  58%|█████▊    | 34/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  59%|█████▉    | 35/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  61%|██████    | 36/59 [00:09<00:06,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  63%|██████▎   | 37/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  64%|██████▍   | 38/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  66%|██████▌   | 39/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  68%|██████▊   | 40/59 [00:10<00:05,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  69%|██████▉   | 41/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  71%|███████   | 42/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  73%|███████▎  | 43/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▍  | 44/59 [00:11<00:04,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  76%|███████▋  | 45/59 [00:12<00:03,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  78%|███████▊  | 46/59 [00:12<00:03,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  80%|███████▉  | 47/59 [00:12<00:03,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  81%|████████▏ | 48/59 [00:13<00:02,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  83%|████████▎ | 49/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  85%|████████▍ | 50/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  86%|████████▋ | 51/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 52/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  90%|████████▉ | 53/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  92%|█████████▏| 54/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  93%|█████████▎| 55/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  95%|█████████▍| 56/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  97%|█████████▋| 57/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  98%|█████████▊| 58/59 [00:15<00:00,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 59/59 [00:15<00:00,  3.70it/s]\u001b[A\n",
      "\n",
      "                                                                        \u001b[A\n",
      "Epoch 5: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0603]\n",
      "Epoch 5: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]Epoch 5, global step 1644: 'val/loss' was not in top 1\n",
      "\n",
      "Epoch 5:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   0%|          | 0/274 [00:00<?, ?it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   0%|          | 1/274 [00:00<02:39,  1.71it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   0%|          | 1/274 [00:00<02:39,  1.71it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   1%|          | 2/274 [00:01<03:22,  1.34it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   1%|          | 2/274 [00:01<03:22,  1.34it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   1%|          | 3/274 [00:02<03:36,  1.25it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   1%|          | 3/274 [00:02<03:36,  1.25it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   1%|▏         | 4/274 [00:03<03:42,  1.21it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   1%|▏         | 4/274 [00:03<03:42,  1.21it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   2%|▏         | 5/274 [00:04<03:46,  1.19it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   2%|▏         | 5/274 [00:04<03:46,  1.19it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   2%|▏         | 6/274 [00:05<03:48,  1.17it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   2%|▏         | 6/274 [00:05<03:48,  1.17it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   3%|▎         | 7/274 [00:06<03:49,  1.16it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   3%|▎         | 8/274 [00:06<03:50,  1.15it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   3%|▎         | 8/274 [00:06<03:50,  1.15it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   3%|▎         | 9/274 [00:07<03:50,  1.15it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   4%|▎         | 10/274 [00:08<03:50,  1.14it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   4%|▎         | 10/274 [00:08<03:50,  1.14it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   4%|▍         | 11/274 [00:09<03:50,  1.14it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   4%|▍         | 12/274 [00:10<03:50,  1.14it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   4%|▍         | 12/274 [00:10<03:50,  1.14it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   5%|▍         | 13/274 [00:11<03:50,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   5%|▍         | 13/274 [00:11<03:50,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   5%|▌         | 14/274 [00:12<03:49,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   5%|▌         | 14/274 [00:12<03:49,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   5%|▌         | 15/274 [00:13<03:49,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   5%|▌         | 15/274 [00:13<03:49,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   6%|▌         | 16/274 [00:14<03:48,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   6%|▌         | 17/274 [00:15<03:48,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   6%|▌         | 17/274 [00:15<03:48,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   7%|▋         | 18/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   7%|▋         | 18/274 [00:15<03:47,  1.13it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   7%|▋         | 19/274 [00:16<03:46,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   7%|▋         | 19/274 [00:16<03:46,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   7%|▋         | 20/274 [00:17<03:46,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   7%|▋         | 20/274 [00:17<03:46,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   8%|▊         | 21/274 [00:18<03:45,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   8%|▊         | 22/274 [00:19<03:44,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   8%|▊         | 23/274 [00:20<03:44,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   8%|▊         | 23/274 [00:20<03:44,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   9%|▉         | 24/274 [00:21<03:43,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   9%|▉         | 24/274 [00:21<03:43,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   9%|▉         | 25/274 [00:22<03:42,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:   9%|▉         | 26/274 [00:23<03:41,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  10%|▉         | 27/274 [00:24<03:41,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  10%|▉         | 27/274 [00:24<03:41,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  10%|█         | 28/274 [00:25<03:40,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  10%|█         | 28/274 [00:25<03:40,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  11%|█         | 29/274 [00:25<03:39,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  11%|█         | 30/274 [00:26<03:38,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  11%|█▏        | 31/274 [00:27<03:37,  1.12it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  12%|█▏        | 32/274 [00:28<03:37,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  12%|█▏        | 32/274 [00:28<03:37,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  12%|█▏        | 33/274 [00:29<03:36,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  12%|█▏        | 33/274 [00:29<03:36,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  12%|█▏        | 34/274 [00:30<03:35,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  12%|█▏        | 34/274 [00:30<03:35,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  13%|█▎        | 35/274 [00:31<03:34,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  13%|█▎        | 35/274 [00:31<03:34,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  13%|█▎        | 36/274 [00:32<03:33,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  13%|█▎        | 36/274 [00:32<03:33,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  14%|█▎        | 37/274 [00:33<03:33,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  14%|█▎        | 37/274 [00:33<03:33,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  14%|█▍        | 38/274 [00:34<03:32,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  14%|█▍        | 38/274 [00:34<03:32,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  14%|█▍        | 39/274 [00:35<03:31,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  14%|█▍        | 39/274 [00:35<03:31,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  15%|█▍        | 40/274 [00:35<03:30,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  15%|█▍        | 40/274 [00:35<03:30,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  15%|█▍        | 41/274 [00:36<03:29,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  15%|█▌        | 42/274 [00:37<03:28,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  16%|█▌        | 43/274 [00:38<03:28,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  16%|█▌        | 43/274 [00:38<03:28,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  16%|█▌        | 44/274 [00:39<03:27,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  16%|█▌        | 44/274 [00:39<03:27,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  16%|█▋        | 45/274 [00:40<03:26,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  16%|█▋        | 45/274 [00:40<03:26,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  17%|█▋        | 46/274 [00:41<03:25,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  17%|█▋        | 46/274 [00:41<03:25,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  17%|█▋        | 47/274 [00:42<03:24,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  17%|█▋        | 47/274 [00:42<03:24,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  18%|█▊        | 48/274 [00:43<03:23,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  18%|█▊        | 49/274 [00:44<03:22,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  18%|█▊        | 50/274 [00:45<03:21,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  18%|█▊        | 50/274 [00:45<03:21,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  19%|█▊        | 51/274 [00:45<03:21,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  19%|█▊        | 51/274 [00:45<03:21,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  19%|█▉        | 52/274 [00:46<03:20,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  19%|█▉        | 52/274 [00:46<03:20,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  19%|█▉        | 53/274 [00:47<03:19,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  19%|█▉        | 53/274 [00:47<03:19,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  20%|█▉        | 54/274 [00:48<03:18,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  20%|█▉        | 54/274 [00:48<03:18,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  20%|██        | 55/274 [00:49<03:17,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  20%|██        | 56/274 [00:50<03:16,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  21%|██        | 57/274 [00:51<03:15,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  21%|██        | 58/274 [00:52<03:14,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  22%|██▏       | 59/274 [00:53<03:14,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  22%|██▏       | 59/274 [00:53<03:14,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  22%|██▏       | 60/274 [00:54<03:13,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  22%|██▏       | 60/274 [00:54<03:13,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  22%|██▏       | 61/274 [00:55<03:12,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  22%|██▏       | 61/274 [00:55<03:12,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  23%|██▎       | 62/274 [00:55<03:11,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  23%|██▎       | 62/274 [00:55<03:11,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  23%|██▎       | 63/274 [00:56<03:10,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  23%|██▎       | 63/274 [00:56<03:10,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  23%|██▎       | 64/274 [00:57<03:09,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  24%|██▎       | 65/274 [00:58<03:08,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  24%|██▍       | 66/274 [00:59<03:07,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  24%|██▍       | 67/274 [01:00<03:06,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  25%|██▍       | 68/274 [01:01<03:06,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  25%|██▍       | 68/274 [01:01<03:06,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  25%|██▌       | 69/274 [01:02<03:05,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  25%|██▌       | 69/274 [01:02<03:05,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  26%|██▌       | 70/274 [01:03<03:04,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  26%|██▌       | 70/274 [01:03<03:04,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  26%|██▌       | 71/274 [01:04<03:03,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  26%|██▌       | 71/274 [01:04<03:03,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  26%|██▋       | 72/274 [01:05<03:02,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  26%|██▋       | 72/274 [01:05<03:02,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  27%|██▋       | 73/274 [01:05<03:01,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  27%|██▋       | 74/274 [01:06<03:00,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  27%|██▋       | 75/274 [01:07<02:59,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  28%|██▊       | 76/274 [01:08<02:58,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  28%|██▊       | 77/274 [01:09<02:58,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  28%|██▊       | 77/274 [01:09<02:58,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  28%|██▊       | 78/274 [01:10<02:57,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  28%|██▊       | 78/274 [01:10<02:57,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  29%|██▉       | 79/274 [01:11<02:56,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  29%|██▉       | 79/274 [01:11<02:56,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  29%|██▉       | 80/274 [01:12<02:55,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  29%|██▉       | 80/274 [01:12<02:55,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  30%|██▉       | 81/274 [01:13<02:54,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  30%|██▉       | 81/274 [01:13<02:54,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  30%|██▉       | 82/274 [01:14<02:53,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  30%|██▉       | 82/274 [01:14<02:53,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  30%|███       | 83/274 [01:15<02:52,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  30%|███       | 83/274 [01:15<02:52,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  31%|███       | 84/274 [01:15<02:51,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  31%|███       | 85/274 [01:16<02:50,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  31%|███▏      | 86/274 [01:17<02:49,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  32%|███▏      | 87/274 [01:18<02:49,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  32%|███▏      | 87/274 [01:18<02:49,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  32%|███▏      | 88/274 [01:19<02:48,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  32%|███▏      | 88/274 [01:19<02:48,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  32%|███▏      | 89/274 [01:20<02:47,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  32%|███▏      | 89/274 [01:20<02:47,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  33%|███▎      | 90/274 [01:21<02:46,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  33%|███▎      | 90/274 [01:21<02:46,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  33%|███▎      | 91/274 [01:22<02:45,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  34%|███▎      | 92/274 [01:23<02:44,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  34%|███▎      | 92/274 [01:23<02:44,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  34%|███▍      | 93/274 [01:24<02:43,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  34%|███▍      | 93/274 [01:24<02:43,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  34%|███▍      | 94/274 [01:25<02:42,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  34%|███▍      | 94/274 [01:25<02:42,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  35%|███▍      | 95/274 [01:25<02:41,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  35%|███▌      | 96/274 [01:26<02:41,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  35%|███▌      | 96/274 [01:26<02:41,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  35%|███▌      | 97/274 [01:27<02:40,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  35%|███▌      | 97/274 [01:27<02:40,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  36%|███▌      | 98/274 [01:28<02:39,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  36%|███▌      | 98/274 [01:28<02:39,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  36%|███▌      | 99/274 [01:29<02:38,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  36%|███▌      | 99/274 [01:29<02:38,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  36%|███▋      | 100/274 [01:30<02:37,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  36%|███▋      | 100/274 [01:30<02:37,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  37%|███▋      | 101/274 [01:31<02:36,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  37%|███▋      | 102/274 [01:32<02:35,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  38%|███▊      | 103/274 [01:33<02:34,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  38%|███▊      | 103/274 [01:33<02:34,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  38%|███▊      | 104/274 [01:34<02:33,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  38%|███▊      | 104/274 [01:34<02:33,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  38%|███▊      | 105/274 [01:34<02:32,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  39%|███▊      | 106/274 [01:35<02:32,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  39%|███▊      | 106/274 [01:35<02:32,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  39%|███▉      | 107/274 [01:36<02:31,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  39%|███▉      | 107/274 [01:36<02:31,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  39%|███▉      | 108/274 [01:37<02:30,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  39%|███▉      | 108/274 [01:37<02:30,  1.11it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  40%|███▉      | 109/274 [01:38<02:29,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  40%|███▉      | 109/274 [01:38<02:29,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  40%|████      | 110/274 [01:39<02:28,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  40%|████      | 110/274 [01:39<02:28,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  41%|████      | 111/274 [01:40<02:27,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  41%|████      | 111/274 [01:40<02:27,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  41%|████      | 112/274 [01:41<02:26,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  41%|████      | 112/274 [01:41<02:26,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  41%|████      | 113/274 [01:42<02:25,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  41%|████      | 113/274 [01:42<02:25,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  42%|████▏     | 114/274 [01:43<02:24,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  42%|████▏     | 114/274 [01:43<02:24,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  42%|████▏     | 115/274 [01:44<02:23,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  42%|████▏     | 115/274 [01:44<02:23,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  42%|████▏     | 116/274 [01:45<02:23,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  42%|████▏     | 116/274 [01:45<02:23,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  43%|████▎     | 117/274 [01:45<02:22,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  43%|████▎     | 117/274 [01:45<02:22,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  43%|████▎     | 118/274 [01:46<02:21,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  43%|████▎     | 118/274 [01:46<02:21,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  43%|████▎     | 119/274 [01:47<02:20,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  43%|████▎     | 119/274 [01:47<02:20,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  44%|████▍     | 120/274 [01:48<02:19,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  44%|████▍     | 120/274 [01:48<02:19,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  44%|████▍     | 121/274 [01:49<02:18,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  44%|████▍     | 121/274 [01:49<02:18,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  45%|████▍     | 122/274 [01:50<02:17,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  45%|████▍     | 122/274 [01:50<02:17,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  45%|████▍     | 123/274 [01:51<02:16,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  45%|████▍     | 123/274 [01:51<02:16,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  45%|████▌     | 124/274 [01:52<02:15,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  45%|████▌     | 124/274 [01:52<02:15,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  46%|████▌     | 125/274 [01:53<02:14,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  46%|████▌     | 125/274 [01:53<02:14,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  46%|████▌     | 126/274 [01:54<02:14,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  46%|████▌     | 126/274 [01:54<02:14,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  46%|████▋     | 127/274 [01:55<02:13,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  46%|████▋     | 127/274 [01:55<02:13,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  47%|████▋     | 128/274 [01:55<02:12,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  47%|████▋     | 128/274 [01:55<02:12,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  47%|████▋     | 129/274 [01:56<02:11,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  47%|████▋     | 129/274 [01:56<02:11,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  47%|████▋     | 130/274 [01:57<02:10,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  47%|████▋     | 130/274 [01:57<02:10,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  48%|████▊     | 131/274 [01:58<02:09,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  48%|████▊     | 131/274 [01:58<02:09,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  48%|████▊     | 132/274 [01:59<02:08,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  48%|████▊     | 132/274 [01:59<02:08,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  49%|████▊     | 133/274 [02:00<02:07,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  49%|████▊     | 133/274 [02:00<02:07,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  49%|████▉     | 134/274 [02:01<02:06,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  49%|████▉     | 134/274 [02:01<02:06,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  49%|████▉     | 135/274 [02:02<02:05,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  49%|████▉     | 135/274 [02:02<02:05,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  50%|████▉     | 136/274 [02:03<02:04,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  50%|████▉     | 136/274 [02:03<02:04,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  50%|█████     | 137/274 [02:04<02:04,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  50%|█████     | 137/274 [02:04<02:04,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  50%|█████     | 138/274 [02:04<02:03,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  50%|█████     | 138/274 [02:04<02:03,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  51%|█████     | 139/274 [02:05<02:02,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  51%|█████     | 139/274 [02:05<02:02,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  51%|█████     | 140/274 [02:06<02:01,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  51%|█████     | 140/274 [02:06<02:01,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  51%|█████▏    | 141/274 [02:07<02:00,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  51%|█████▏    | 141/274 [02:07<02:00,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  52%|█████▏    | 142/274 [02:08<01:59,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  52%|█████▏    | 142/274 [02:08<01:59,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  52%|█████▏    | 143/274 [02:09<01:58,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  52%|█████▏    | 143/274 [02:09<01:58,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  53%|█████▎    | 144/274 [02:10<01:57,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  53%|█████▎    | 144/274 [02:10<01:57,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  53%|█████▎    | 145/274 [02:11<01:56,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  53%|█████▎    | 145/274 [02:11<01:56,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  53%|█████▎    | 146/274 [02:12<01:55,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  53%|█████▎    | 146/274 [02:12<01:55,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  54%|█████▎    | 147/274 [02:13<01:55,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  54%|█████▎    | 147/274 [02:13<01:55,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  54%|█████▍    | 148/274 [02:14<01:54,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  54%|█████▍    | 148/274 [02:14<01:54,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  54%|█████▍    | 149/274 [02:14<01:53,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  54%|█████▍    | 149/274 [02:14<01:53,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  55%|█████▍    | 150/274 [02:15<01:52,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  55%|█████▍    | 150/274 [02:15<01:52,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  55%|█████▌    | 151/274 [02:16<01:51,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  55%|█████▌    | 151/274 [02:16<01:51,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  55%|█████▌    | 152/274 [02:17<01:50,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  55%|█████▌    | 152/274 [02:17<01:50,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  56%|█████▌    | 153/274 [02:18<01:49,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  56%|█████▌    | 153/274 [02:18<01:49,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  56%|█████▌    | 154/274 [02:19<01:48,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  56%|█████▌    | 154/274 [02:19<01:48,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  57%|█████▋    | 155/274 [02:20<01:47,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  57%|█████▋    | 155/274 [02:20<01:47,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  57%|█████▋    | 156/274 [02:21<01:46,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  57%|█████▋    | 156/274 [02:21<01:46,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  57%|█████▋    | 157/274 [02:22<01:46,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  57%|█████▋    | 157/274 [02:22<01:46,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  58%|█████▊    | 158/274 [02:23<01:45,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  58%|█████▊    | 158/274 [02:23<01:45,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  58%|█████▊    | 159/274 [02:24<01:44,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  58%|█████▊    | 159/274 [02:24<01:44,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  58%|█████▊    | 160/274 [02:24<01:43,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  58%|█████▊    | 160/274 [02:24<01:43,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  59%|█████▉    | 161/274 [02:25<01:42,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  59%|█████▉    | 161/274 [02:25<01:42,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  59%|█████▉    | 162/274 [02:26<01:41,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  59%|█████▉    | 162/274 [02:26<01:41,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  59%|█████▉    | 163/274 [02:27<01:40,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  59%|█████▉    | 163/274 [02:27<01:40,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  60%|█████▉    | 164/274 [02:28<01:39,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  60%|█████▉    | 164/274 [02:28<01:39,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  60%|██████    | 165/274 [02:29<01:38,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  60%|██████    | 165/274 [02:29<01:38,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  61%|██████    | 166/274 [02:30<01:37,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  61%|██████    | 166/274 [02:30<01:37,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  61%|██████    | 167/274 [02:31<01:36,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  61%|██████    | 167/274 [02:31<01:36,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  61%|██████▏   | 168/274 [02:32<01:36,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  61%|██████▏   | 168/274 [02:32<01:36,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  62%|██████▏   | 169/274 [02:33<01:35,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  62%|██████▏   | 169/274 [02:33<01:35,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  62%|██████▏   | 170/274 [02:34<01:34,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  62%|██████▏   | 170/274 [02:34<01:34,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  62%|██████▏   | 171/274 [02:34<01:33,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  62%|██████▏   | 171/274 [02:34<01:33,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  63%|██████▎   | 172/274 [02:35<01:32,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  63%|██████▎   | 172/274 [02:35<01:32,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  63%|██████▎   | 173/274 [02:36<01:31,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  63%|██████▎   | 173/274 [02:36<01:31,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  64%|██████▎   | 174/274 [02:37<01:30,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  64%|██████▍   | 175/274 [02:38<01:29,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  64%|██████▍   | 176/274 [02:39<01:28,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  65%|██████▍   | 177/274 [02:40<01:27,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  65%|██████▍   | 178/274 [02:41<01:27,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  65%|██████▍   | 178/274 [02:41<01:27,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  65%|██████▌   | 179/274 [02:42<01:26,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  66%|██████▌   | 180/274 [02:43<01:25,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  66%|██████▌   | 181/274 [02:44<01:24,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  66%|██████▌   | 181/274 [02:44<01:24,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  66%|██████▋   | 182/274 [02:44<01:23,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  66%|██████▋   | 182/274 [02:44<01:23,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  67%|██████▋   | 183/274 [02:45<01:22,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  67%|██████▋   | 183/274 [02:45<01:22,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  67%|██████▋   | 184/274 [02:46<01:21,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  68%|██████▊   | 185/274 [02:47<01:20,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  68%|██████▊   | 186/274 [02:48<01:19,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  68%|██████▊   | 187/274 [02:49<01:18,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  69%|██████▊   | 188/274 [02:50<01:17,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  69%|██████▊   | 188/274 [02:50<01:17,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  69%|██████▉   | 189/274 [02:51<01:17,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  69%|██████▉   | 190/274 [02:52<01:16,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  70%|██████▉   | 191/274 [02:53<01:15,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  70%|███████   | 192/274 [02:54<01:14,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  70%|███████   | 192/274 [02:54<01:14,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  70%|███████   | 193/274 [02:55<01:13,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  70%|███████   | 193/274 [02:55<01:13,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  71%|███████   | 194/274 [02:55<01:12,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  71%|███████   | 194/274 [02:55<01:12,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  71%|███████   | 195/274 [02:56<01:11,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  72%|███████▏  | 196/274 [02:57<01:10,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  72%|███████▏  | 197/274 [02:58<01:09,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  72%|███████▏  | 198/274 [02:59<01:08,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  73%|███████▎  | 199/274 [03:00<01:08,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  73%|███████▎  | 199/274 [03:00<01:08,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  73%|███████▎  | 200/274 [03:01<01:07,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  73%|███████▎  | 201/274 [03:02<01:06,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  74%|███████▎  | 202/274 [03:03<01:05,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  74%|███████▍  | 203/274 [03:04<01:04,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  74%|███████▍  | 204/274 [03:04<01:03,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  74%|███████▍  | 204/274 [03:04<01:03,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  75%|███████▍  | 205/274 [03:05<01:02,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  75%|███████▍  | 205/274 [03:05<01:02,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  75%|███████▌  | 206/274 [03:06<01:01,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  76%|███████▌  | 207/274 [03:07<01:00,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  76%|███████▌  | 208/274 [03:08<00:59,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  76%|███████▋  | 209/274 [03:09<00:58,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  77%|███████▋  | 210/274 [03:10<00:58,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  77%|███████▋  | 211/274 [03:11<00:57,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  77%|███████▋  | 212/274 [03:12<00:56,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  78%|███████▊  | 213/274 [03:13<00:55,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  78%|███████▊  | 214/274 [03:14<00:54,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  78%|███████▊  | 215/274 [03:14<00:53,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  78%|███████▊  | 215/274 [03:14<00:53,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  79%|███████▉  | 216/274 [03:15<00:52,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  79%|███████▉  | 216/274 [03:15<00:52,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  79%|███████▉  | 217/274 [03:16<00:51,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  80%|███████▉  | 218/274 [03:17<00:50,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  80%|███████▉  | 219/274 [03:18<00:49,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  80%|████████  | 220/274 [03:19<00:48,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  80%|████████  | 220/274 [03:19<00:48,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  81%|████████  | 221/274 [03:20<00:48,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  81%|████████  | 222/274 [03:21<00:47,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  81%|████████▏ | 223/274 [03:22<00:46,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  82%|████████▏ | 224/274 [03:23<00:45,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  82%|████████▏ | 225/274 [03:24<00:44,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  82%|████████▏ | 225/274 [03:24<00:44,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  82%|████████▏ | 226/274 [03:24<00:43,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  83%|████████▎ | 227/274 [03:25<00:42,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  83%|████████▎ | 228/274 [03:26<00:41,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  84%|████████▎ | 229/274 [03:27<00:40,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  84%|████████▍ | 230/274 [03:28<00:39,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  84%|████████▍ | 231/274 [03:29<00:39,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  84%|████████▍ | 231/274 [03:29<00:39,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  85%|████████▍ | 232/274 [03:30<00:38,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  85%|████████▌ | 233/274 [03:31<00:37,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  85%|████████▌ | 234/274 [03:32<00:36,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  86%|████████▌ | 235/274 [03:33<00:35,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  86%|████████▌ | 236/274 [03:34<00:34,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  86%|████████▌ | 236/274 [03:34<00:34,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  86%|████████▋ | 237/274 [03:34<00:33,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  87%|████████▋ | 238/274 [03:35<00:32,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  87%|████████▋ | 239/274 [03:36<00:31,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  88%|████████▊ | 240/274 [03:37<00:30,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  88%|████████▊ | 241/274 [03:38<00:29,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  88%|████████▊ | 242/274 [03:39<00:29,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  89%|████████▊ | 243/274 [03:40<00:28,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  89%|████████▉ | 244/274 [03:41<00:27,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  89%|████████▉ | 245/274 [03:42<00:26,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  90%|████████▉ | 246/274 [03:43<00:25,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  90%|█████████ | 247/274 [03:44<00:24,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  90%|█████████ | 247/274 [03:44<00:24,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  91%|█████████ | 248/274 [03:44<00:23,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  91%|█████████ | 249/274 [03:45<00:22,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  91%|█████████ | 250/274 [03:46<00:21,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  92%|█████████▏| 251/274 [03:47<00:20,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  92%|█████████▏| 252/274 [03:48<00:19,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  92%|█████████▏| 253/274 [03:49<00:19,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  93%|█████████▎| 254/274 [03:50<00:18,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  93%|█████████▎| 255/274 [03:51<00:17,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  93%|█████████▎| 256/274 [03:52<00:16,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  94%|█████████▍| 257/274 [03:53<00:15,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  94%|█████████▍| 258/274 [03:54<00:14,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  94%|█████████▍| 258/274 [03:54<00:14,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  95%|█████████▍| 259/274 [03:55<00:13,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  95%|█████████▍| 259/274 [03:55<00:13,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  95%|█████████▍| 260/274 [03:55<00:12,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  95%|█████████▌| 261/274 [03:56<00:11,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  96%|█████████▌| 262/274 [03:57<00:10,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  96%|█████████▌| 263/274 [03:58<00:09,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  96%|█████████▋| 264/274 [03:59<00:09,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  97%|█████████▋| 265/274 [04:00<00:08,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  97%|█████████▋| 266/274 [04:01<00:07,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  97%|█████████▋| 267/274 [04:02<00:06,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  98%|█████████▊| 268/274 [04:03<00:05,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  98%|█████████▊| 269/274 [04:04<00:04,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  98%|█████████▊| 269/274 [04:04<00:04,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  99%|█████████▊| 270/274 [04:05<00:03,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  99%|█████████▊| 270/274 [04:05<00:03,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  99%|█████████▉| 271/274 [04:05<00:02,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6:  99%|█████████▉| 272/274 [04:06<00:01,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6: 100%|█████████▉| 273/274 [04:07<00:00,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "Epoch 6: 100%|██████████| 274/274 [04:08<00:00,  1.10it/s, v_num=11, val/loss=0.276, val/accuracy=0.926, train/loss=0.0418]\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   2%|▏         | 1/59 [00:00<00:20,  2.86it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   3%|▎         | 2/59 [00:00<00:17,  3.23it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   5%|▌         | 3/59 [00:00<00:16,  3.37it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   7%|▋         | 4/59 [00:01<00:15,  3.45it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   8%|▊         | 5/59 [00:01<00:15,  3.50it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  10%|█         | 6/59 [00:01<00:14,  3.54it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▏        | 7/59 [00:01<00:14,  3.56it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  14%|█▎        | 8/59 [00:02<00:14,  3.58it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  15%|█▌        | 9/59 [00:02<00:13,  3.59it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  17%|█▋        | 10/59 [00:02<00:13,  3.60it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  19%|█▊        | 11/59 [00:03<00:13,  3.61it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  20%|██        | 12/59 [00:03<00:12,  3.62it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  22%|██▏       | 13/59 [00:03<00:12,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  24%|██▎       | 14/59 [00:03<00:12,  3.63it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 15/59 [00:04<00:12,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  27%|██▋       | 16/59 [00:04<00:11,  3.64it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  29%|██▉       | 17/59 [00:04<00:11,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  31%|███       | 18/59 [00:04<00:11,  3.65it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  32%|███▏      | 19/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  34%|███▍      | 20/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  36%|███▌      | 21/59 [00:05<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  37%|███▋      | 22/59 [00:06<00:10,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  39%|███▉      | 23/59 [00:06<00:09,  3.66it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  41%|████      | 24/59 [00:06<00:09,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  42%|████▏     | 25/59 [00:06<00:09,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  44%|████▍     | 26/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  46%|████▌     | 27/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  47%|████▋     | 28/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  49%|████▉     | 29/59 [00:07<00:08,  3.67it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  51%|█████     | 30/59 [00:08<00:07,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  53%|█████▎    | 31/59 [00:08<00:07,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  54%|█████▍    | 32/59 [00:08<00:07,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  56%|█████▌    | 33/59 [00:08<00:07,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  58%|█████▊    | 34/59 [00:09<00:06,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  59%|█████▉    | 35/59 [00:09<00:06,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  61%|██████    | 36/59 [00:09<00:06,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  63%|██████▎   | 37/59 [00:10<00:05,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  64%|██████▍   | 38/59 [00:10<00:05,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  66%|██████▌   | 39/59 [00:10<00:05,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  68%|██████▊   | 40/59 [00:10<00:05,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  69%|██████▉   | 41/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  71%|███████   | 42/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  73%|███████▎  | 43/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▍  | 44/59 [00:11<00:04,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  76%|███████▋  | 45/59 [00:12<00:03,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  78%|███████▊  | 46/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  80%|███████▉  | 47/59 [00:12<00:03,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  81%|████████▏ | 48/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  83%|████████▎ | 49/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  85%|████████▍ | 50/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  86%|████████▋ | 51/59 [00:13<00:02,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 52/59 [00:14<00:01,  3.68it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  90%|████████▉ | 53/59 [00:14<00:01,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  92%|█████████▏| 54/59 [00:14<00:01,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  93%|█████████▎| 55/59 [00:14<00:01,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  95%|█████████▍| 56/59 [00:15<00:00,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  97%|█████████▋| 57/59 [00:15<00:00,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  98%|█████████▊| 58/59 [00:15<00:00,  3.69it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 59/59 [00:15<00:00,  3.71it/s]\u001b[A\n",
      "\n",
      "                                                                        \u001b[A\n",
      "Epoch 6: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.327, val/accuracy=0.913, train/loss=0.0418]\n",
      "Epoch 6: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.327, val/accuracy=0.913, train/loss=0.0335][rank: 1] Monitored metric val/loss did not improve in the last 3 records. Best score: 0.217. Signaling Trainer to stop.\n",
      "[rank: 3] Monitored metric val/loss did not improve in the last 3 records. Best score: 0.217. Signaling Trainer to stop.\n",
      "[rank: 0] Monitored metric val/loss did not improve in the last 3 records. Best score: 0.217. Signaling Trainer to stop.\n",
      "[rank: 2] Monitored metric val/loss did not improve in the last 3 records. Best score: 0.217. Signaling Trainer to stop.\n",
      "Epoch 6, global step 1918: 'val/loss' was not in top 1\n",
      "\n",
      "Epoch 6: 100%|██████████| 274/274 [04:24<00:00,  1.04it/s, v_num=11, val/loss=0.327, val/accuracy=0.913, train/loss=0.0335]\n",
      "Entrenamiento completado!\n",
      "Entrenamiento completado!\n",
      "Entrenamiento completado!\n",
      "Entrenamiento completado!\n",
      "Entrenamiento completado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Ejecuta el script de entrenamiento usando subprocess\n",
    "script_path = \"training.py\"\n",
    "\n",
    "# Verificar que el script existe\n",
    "if not os.path.exists(script_path):\n",
    "    print(f\"Error: No se encontró el archivo {script_path}\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"Iniciando entrenamiento del modelo BERT...\")\n",
    "\n",
    "try:\n",
    "    # Ejecutar el script con subprocess\n",
    "    process = subprocess.Popen(\n",
    "        [sys.executable, script_path],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    # Mostrar la salida en tiempo real\n",
    "    for line in process.stdout:\n",
    "        print(line.rstrip())\n",
    "    \n",
    "    # Esperar a que termine el proceso\n",
    "    process.wait()\n",
    "    \n",
    "    if process.returncode == 0:\n",
    "        print(\"Entrenamiento completado exitosamente!\")\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Error durante el entrenamiento. Código de salida: {process.returncode}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error al ejecutar el script: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado en: ./sentiment_checkpoints/best-checkpoint-epoch=03-val/loss=0.22.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df16208eb8e04d67b8e57e6d8a57ea14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eaguayo/.local/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: TorchMetricsUserWarning: You are trying to use a metric in deterministic mode on GPU that uses `torch.cumsum`, which is currently not supported. The tensor will be copied to the CPU memory to compute it and then copied back to GPU. Expect some slowdowns.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/eaguayo/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:520: You called `self.log('test/loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "/home/eaguayo/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:520: You called `self.log('test/auroc', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "/home/eaguayo/.local/lib/python3.10/site-packages/pytorch_lightning/core/module.py:520: You called `self.log('test/accuracy', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9278666377067566     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.979088544845581     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20653203129768372    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9278666377067566    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.979088544845581    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20653203129768372   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 0.20653203129768372,\n",
       "  'test/auroc': 0.979088544845581,\n",
       "  'test/accuracy': 0.9278666377067566}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluación del modelo en el conjunto de prueba\n",
    "\n",
    "# Cargar el mejor modelo\n",
    "# best_model_path = checkpoint_callback.best_model_path\n",
    "# best_model_path = './sentiment_checkpoints/best-checkpoint-epoch=01-val/loss=0.21.ckpt'\n",
    "# best_model_path = './sentiment_checkpoints/best-checkpoint-epoch=02-val/loss=0.20.ckpt'\n",
    "best_model_path = './sentiment_checkpoints/best-checkpoint-epoch=03-val/loss=0.22.ckpt'\n",
    "print(f\"Mejor modelo guardado en: {best_model_path}\")\n",
    "\n",
    "trained_model = SentimentClassifier.load_from_checkpoint(\n",
    "    best_model_path,\n",
    "    n_warmup_steps=warmup_steps,\n",
    "    n_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "# Determinar dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    accelerator=\"auto\",  # Usa GPU si está disponible\n",
    "    devices=\"auto\",\n",
    "    enable_checkpointing=False,\n",
    ")\n",
    "\n",
    "trainer.test(trained_model, data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo listo para predicciones\n",
      "Predicciones en nuevos textos:\n",
      "--------------------------------------------------------------------------------\n",
      "Text: This movie was absolutely fantastic! Great acting and amazing storyline.\n",
      "Predicted sentiment: NEGATIVE\n",
      "Confidence: 0.9892\n",
      "--------------------------------------------------------------------------------\n",
      "Text: I hated this film. It was boring and poorly made.\n",
      "Predicted sentiment: POSITIVE\n",
      "Confidence: 0.9814\n",
      "--------------------------------------------------------------------------------\n",
      "Text: The movie was okay, nothing special but not terrible either.\n",
      "Predicted sentiment: POSITIVE\n",
      "Confidence: 0.8563\n",
      "--------------------------------------------------------------------------------\n",
      "Text: One of the best movies I've ever seen! Highly recommended!\n",
      "Predicted sentiment: NEGATIVE\n",
      "Confidence: 0.9848\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "trained_model.eval()\n",
    "\n",
    "print(\"Modelo listo para predicciones\")\n",
    "\n",
    "# Función para hacer predicciones en nuevos textos\n",
    "def predict_sentiment(text, model, tokenizer, device, max_length=512):\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        return_token_type_ids=False,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, outputs = model(input_ids, attention_mask)\n",
    "        prediction = torch.sigmoid(outputs).cpu().numpy()[0][0]\n",
    "    \n",
    "    sentiment = \"positive\" if prediction > 0.5 else \"negative\" \n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    \n",
    "    return sentiment, confidence\n",
    "\n",
    "# Ejemplos de predicción\n",
    "test_texts = [\n",
    "    \"This movie was absolutely fantastic! Great acting and amazing storyline.\",\n",
    "    \"I hated this film. It was boring and poorly made.\",\n",
    "    \"The movie was okay, nothing special but not terrible either.\",\n",
    "    \"One of the best movies I've ever seen! Highly recommended!\"\n",
    "]\n",
    "\n",
    "print(\"Predicciones en nuevos textos:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for text in test_texts:\n",
    "    sentiment, confidence = predict_sentiment(text, trained_model, tokenizer, device)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted sentiment: {sentiment.upper()}\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0de9fee8328e49d48625d0645aa64c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b5c47d88a6040b9914073315b0979cb",
      "max": 4867,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ef45960a58b46f1ab4297303510a0c1",
      "value": 4867
     }
    },
    "0eefaf0239474e9290c1cf7aafa34e3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18ec3ca75ef547b08205157cddf65e62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_338af3b5451c402cbaafbb4ddeb8b231",
      "placeholder": "​",
      "style": "IPY_MODEL_0eefaf0239474e9290c1cf7aafa34e3c",
      "value": " 4867/4867 [01:46&lt;00:00, 40.76it/s]"
     }
    },
    "2b5c47d88a6040b9914073315b0979cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "326de4c08b8341d4975bd8a696c2e531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "338af3b5451c402cbaafbb4ddeb8b231": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39e5f3f049014efd99c30830c4bcf017": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ef45960a58b46f1ab4297303510a0c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "44a47c7bdae64bf99dc826b251c16107": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65167eb675ef49d393e8283d19456fe8": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_cd229db92be4474b9a4c6258cfa3aaa9",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 1/9 </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1420/1420</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:09 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.92it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 0.000 train_loss: 0.068    </span>\n                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">val_loss: 0.175                   </span>\n</pre>\n",
         "text/plain": "\u001b[37mEpoch 1/9 \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m1420/1420\u001b[0m \u001b[38;5;245m0:08:09 • 0:00:00\u001b[0m \u001b[38;5;249m2.92it/s\u001b[0m \u001b[37mv_num: 0.000 train_loss: 0.068    \u001b[0m\n                                                                                 \u001b[37mval_loss: 0.175                   \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "6ec47037a37d4903bfb7f9ae80ba4925": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_39e5f3f049014efd99c30830c4bcf017",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 2/9 </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1420/1420</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:09 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.92it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 0.000 train_loss: 0.170    </span>\n                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">val_loss: 0.154                   </span>\n</pre>\n",
         "text/plain": "\u001b[37mEpoch 2/9 \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m1420/1420\u001b[0m \u001b[38;5;245m0:08:09 • 0:00:00\u001b[0m \u001b[38;5;249m2.92it/s\u001b[0m \u001b[37mv_num: 0.000 train_loss: 0.170    \u001b[0m\n                                                                                 \u001b[37mval_loss: 0.154                   \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "8ed03fd78e5048f08fd1371c89a22a86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90e9a1f4ab674337923b01f3677ce420": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af231bb0ad0f4290855525d9131d6bab": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_90e9a1f4ab674337923b01f3677ce420",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 0/9 </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1420/1420</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:08 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.92it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 0.000 train_loss: 0.219</span>\n</pre>\n",
         "text/plain": "\u001b[37mEpoch 0/9 \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m1420/1420\u001b[0m \u001b[38;5;245m0:08:08 • 0:00:00\u001b[0m \u001b[38;5;249m2.92it/s\u001b[0m \u001b[37mv_num: 0.000 train_loss: 0.219\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "cbf5ced9f59247d2808d0b2a76918f29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd229db92be4474b9a4c6258cfa3aaa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6c3bb4f082d41bc8480549613b9ba78": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_326de4c08b8341d4975bd8a696c2e531",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Epoch 3/9 </span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1420/1420</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:08:09 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">2.92it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 0.000 train_loss: 0.055    </span>\n                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">val_loss: 0.161                   </span>\n</pre>\n",
         "text/plain": "\u001b[37mEpoch 3/9 \u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m1420/1420\u001b[0m \u001b[38;5;245m0:08:09 • 0:00:00\u001b[0m \u001b[38;5;249m2.92it/s\u001b[0m \u001b[37mv_num: 0.000 train_loss: 0.055    \u001b[0m\n                                                                                 \u001b[37mval_loss: 0.161                   \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "ff051ddfeb69414cb1acdcc21dc36775": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff7195102aa54cd78fbe3ff3e40b3733",
       "IPY_MODEL_0de9fee8328e49d48625d0645aa64c93",
       "IPY_MODEL_18ec3ca75ef547b08205157cddf65e62"
      ],
      "layout": "IPY_MODEL_8ed03fd78e5048f08fd1371c89a22a86"
     }
    },
    "ff7195102aa54cd78fbe3ff3e40b3733": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbf5ced9f59247d2808d0b2a76918f29",
      "placeholder": "​",
      "style": "IPY_MODEL_44a47c7bdae64bf99dc826b251c16107",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
